# arXiv论文监控报告 - 2026年01月07日

> 本报告由arXiv论文监控Agent自动生成

## 报告概览

- **监控日期**: 2026年01月07日
- **监控分类**: cs.AI, cs.LG, cs.RO, cs.CV
- **关键词**: Vision Language Action , vla, Vision-Language-Action, Multivariate Time Series Forecasting, spatio-temporal prediction, traffic prediction
- **发现论文数**: 10篇

---

## 1. Value Vision-Language-Action Planning & Search

### 基本信息
- **作者**: Ali Salamatian (Steve),  Ke (Steve),  Ren, Kieran Pattison, Cyrus Neary
- **arXiv ID**: [oai:arXiv.org:2601.00969v1](https://arxiv.org/abs/2601.00969)
- **发布日期**: Tue, 06 Jan 2026 00:00:00 -0500
- **分类**: cs.RO, cs.AI
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2601.00969)

            ### 原文摘要
            arXiv:2601.00969v1 Announce Type: cross  Abstract: Vision-Language-Action (VLA) models have emerged as powerful generalist policies for robotic manipulation, yet they remain fundamentally limited by their reliance on behavior cloning, leading to brittleness under distribution shift. While augmenting pretrained models with test-time search algorithms like Monte Carlo Tree Search (MCTS) can mitigate these failures, existing formulations rely solely on the VLA prior for guidance, lacking a grounded estimate of expected future return. Consequently, when the prior is inaccurate, the planner can only correct action selection via the exploration term, which requires extensive simulation to become effective. To address this limitation, we introduce Value Vision-Language-Action Planning and Search (V-VLAPS), a framework that augments MCTS with a lightweight, learnable value function. By training a simple multilayer perceptron (MLP) on the latent representations of a fixed VLA backbone (Octo), we provide the search with an explicit success signal that biases action selection toward high-value regions. We evaluate V-VLAPS on the LIBERO robotic manipulation suite, demonstrating that our value-guided search improves success rates by over 5 percentage points while reducing the average number of MCTS simulations by 5-15 percent compared to baselines that rely only on the VLA prior.


            
### AI分析（基于论文正文）
### **论文概要**

本文针对基于视觉-语言-动作（VLA）模型的机器人操作策略在分布外状态下表现脆弱的局限性，提出了一种名为“价值视觉-语言-动作规划与搜索”（V-VLAPS）的框架。该框架在Neary等人（2025）提出的VLA引导的蒙特卡洛树搜索（VLAPS）基础上，引入了一个轻量级、可学习的价值函数。该价值函数以固定VLA骨干网络（Octo）的潜在表示为输入，预测状态价值，并将其整合到MCTS的节点选择规则中，从而在VLA先验不准确时，为搜索过程提供明确的成功信号，引导其偏向高价值区域。在LIBERO机器人操作任务套件上的实验表明，该方法在提高任务成功率的同时，减少了所需的MCTS模拟次数。

### **研究动机**

论文的研究动机源于解决通用VLA策略在开放世界部署中的可靠性问题。VLA模型（如Octo）通过大规模行为克隆数据训练，能够作为通用策略先验，但其本质是反应式的（见第2.1节）。在面对未见过的场景或长视野任务时，这种缺乏显式规划的纯反应式执行容易失败，且无法从错误中恢复（Gu et al., 2025）。

为了弥补这一缺陷，Neary等人（2025）提出了VLAPS，将预训练的VLA模型嵌入到基于模型的MCTS规划中。VLAPS利用VLA模型提供动作建议和抽象，以引导搜索。然而，作者指出，VLAPS存在一个关键限制：其搜索过程完全依赖于VLA先验和基于访问计数的探索启发式，**缺乏一个对期望未来回报的、有根据的估计（即价值函数）**（见第1节）。这意味着，当VLA先验不准确（例如，对次优动作赋予高概率）时，规划器除了通过大量模拟进行穷举式探索外，没有其他机制来纠正这种偏差。搜索过程依赖于模仿先验，而非底层的奖励结构，这在长视野规划中效率低下且不鲁棒。

因此，本文的核心动机是**为VLA引导的MCTS引入一个显式的价值函数**，以提供缺失的奖励信号。这一动机借鉴了AlphaGo等成功系统中将策略网络与价值网络结合以指导树搜索的思想（见第2.3节）。作者旨在通过一个轻量级的价值头，使搜索能够在VLA先验失效时，主动偏向具有更高期望回报的状态，从而提升规划效率和鲁棒性。

### **核心贡献与创新点**

本文的核心贡献与创新点可归纳为以下三点：

1.  **提出了V-VLAPS框架，首次将可学习的价值函数与VLA引导的MCTS相结合。** 这是本文最核心的概念性创新。与Neary等人（2025）的VLAPS仅依赖VLA先验和搜索统计不同，V-VLAPS引入了一个独立训练的价值头（一个三层MLP），该价值头以冻结的Octo骨干网络的最后一层潜在表示（readout）为输入，输出一个标量价值估计（见第3.2节，图1）。这使得搜索过程具备了评估状态“好坏”的能力，而不仅仅是动作的“可能性”。

2.  **设计了一种基于VLA策略自生成数据训练价值函数的方法。** 为了训练价值头，作者提出了一种无需额外人工标注的数据收集流程（见第3.1节）。具体而言，他们直接在目标任务（LIBERO套件）上运行固定的Octo策略，收集轨迹数据。由于任务奖励是稀疏的（成功为1，失败为0），他们通过折扣回报（公式：\(G_t = \gamma^{T-t}\) if \(R=1\), else \(0\)）为轨迹中的每个决策步状态计算蒙特卡洛价值目标 \(G_t\)。将Octo的readout向量 \(h_t\) 与对应的 \(G_t\) 配对，即构成了训练数据集 \(\{(h_t, G_t)\}\)。这种方法简单有效，利用了现有VLA模型自身的行为来生成监督信号。

3.  **将学习到的价值估计无缝集成到VLAPS的节点选择规则中，形成了新的混合评分函数。** 这是方法上的关键创新。作者修改了VLAPS原有的PUCT风格节点选择评分规则（见第3.3节）。新的评分函数 `SCORE(v, a_i, s')` 由两部分组成：
    *   **价值项（Q部分）**：\(Q(v, a_i) = V_\theta(h)\)，其中 \(V_\theta\) 是训练好的价值头，\(h\) 是执行动作 \(a_i\) 后到达的新状态 \(s'\) 的Octo readout。这部分直接提供了对新状态价值的估计。
    *   **先验与探索项（U部分）**：完全沿用VLAPS的定义，即 \(U(v, a_i) = \psi_{\Phi_v}(a_i | I_t, L_T) \frac{\sqrt{N(v)}}{1+N(v, a_i)}\)，其中包含VLA给出的动作先验概率 \(\psi\) 和基于访问计数 \(N\) 的探索鼓励。
    最终的评分是两项之和：`SCORE = b * V_θ(readout(s‘)) + U部分`（其中b是一个系数）。这一设计使得MCTS在选择节点时，能够同时考虑“该动作有多可能（先验）”、“这个分支被探索得够不够（探索）”以及“执行这个动作后到达的状态有多好（价值）”，从而实现了更智能的搜索引导。

### **方法概述**

V-VLAPS方法包含三个主要阶段：数据收集、价值头训练和价值集成搜索。其运作流程如下：

**第一阶段：数据收集（第3.1节）**
使用固定的、未经规划的Octo VLA策略，在目标环境（LIBERO）中执行任务，收集一系列决策步轨迹。每个决策步 \(t\) 包含观测 \(o_t\)、语言指令 \(g\)、Octo生成的readout向量 \(h_t\) 和执行的动作块 \(c_t\)。轨迹以成功（奖励 \(R=1\)）或失败/超时（\(R=0\)）结束。对于轨迹中每个决策步的状态，通过折扣回报公式计算其蒙特卡洛价值目标 \(G_t\)。最终，收集到大量数据对 \((h_t, G_t)\) 用于训练。

**第二阶段：价值头训练（第3.2节）**
价值头 \(V_\theta\) 被参数化为一个轻量的三层MLP，输入维度与Octo的readout维度 \(d\) 一致，输出一个标量。训练时，**Octo骨干网络的参数被完全冻结**，仅更新价值头的参数 \(\theta\)。训练目标是最小化预测值 \(\hat{v}_t = V_\theta(h_t)\) 与目标值 \(G_t\) 之间的均方误差（MSE）：\(\mathcal{L}(\theta) = \mathbb{E}[(V_\theta(h_t) - G_t)^2]\)。使用Adam优化器进行随机梯度下降。为了解决某些任务成功率极低（如0%）导致的数据不平衡问题，作者采用了类别平衡技术，对失败状态进行随机下采样，使成功与失败的样本数量相等（见第4.1节）。

**第三阶段：价值集成搜索（第3.3节，算法流程）**
在测试时，执行V-VLAPS规划。对于当前状态（MCTS根节点）：
1.  **选择**：从根节点开始，递归地选择子节点，直到到达一个未完全展开的节点。选择的标准是最大化上文所述的混合评分函数 `SCORE(v, a_i, s‘)`。
2.  **扩展与评估**：当到达一个未展开的节点时，使用Octo模型基于当前观测和指令生成一组候选动作块。对于每个候选动作 \(a_i\)，在模拟器中执行，得到新状态 \(s‘\)。然后，将 \(s‘\) 的观测和指令输入**冻结的**Octo模型，得到其readout向量，再输入**训练好的**价值头 \(V_\theta\)，得到该状态的价值估计 \(\hat{v}\)。这个 \(\hat{v}\) 即为该动作-状态对 \((v, a_i, s‘)\) 的Q值估计。
3.  **回传**：将模拟得到的回报（在本文稀疏奖励设定下，通常是0或1）以及新状态的价值估计（可选地加权）沿搜索路径反向传播，更新路径上各节点的访问计数 \(N\) 和平均回报 \(Q\) 统计量。
4.  **决策**：经过预设次数的模拟后，根据根节点下各动作的访问计数，选择访问次数最多的动作作为当前步的实际执行动作。

整个过程将学习到的价值函数作为一个快速、低成本的“直觉”，在每一步扩展时评估状态的好坏，从而在树搜索的早期就避免深入低价值的分支，提高了搜索效率。

### **实验说明**

**评估指标**：主要评估指标为**任务成功率（Success Rate %）**。次要效率指标为**平均MCTS模拟次数（Avg MCTS Simulation）**，即从根节点重新开始搜索的平均次数（见第4.2节，表3）。

**数据集**：实验在**LIBERO**机器人操作仿真套件上进行，包含两个子套件（见第4.1节）：
*   **LIBERO

---

## 2. Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction

### 基本信息
- **作者**: Rui An, Yifeng Zhang, Ziran Liang, Wenqi Fan, Yuxuan Liang, Xuequn Shang, Qing Li
- **arXiv ID**: [oai:arXiv.org:2506.18939v3](https://arxiv.org/abs/2506.18939)
- **发布日期**: Tue, 06 Jan 2026 00:00:00 -0500
- **分类**: cs.CV, cs.AI
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2506.18939)

            ### 原文摘要
            arXiv:2506.18939v3 Announce Type: replace-cross  Abstract: Training urban spatio-temporal foundation models that generalize well across diverse regions and cities is critical for deploying urban services in unseen or data-scarce regions. Recent studies have typically focused on fusing cross-domain spatio-temporal data to train unified Transformer-based models. However, these models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment. Inspired by the efficiency of Mamba, a state space model with linear time complexity, we explore its potential for efficient urban spatio-temporal prediction. However, directly applying Mamba as a spatio-temporal backbone leads to negative transfer and severe performance degradation. This is primarily due to spatio-temporal heterogeneity and the recursive mechanism of Mamba's hidden state updates, which limit cross-domain generalization. To overcome these challenges, we propose Damba-ST, a novel domain-adaptive Mamba-based model for efficient urban spatio-temporal prediction. Damba-ST retains Mamba's linear complexity advantage while significantly enhancing its adaptability to heterogeneous domains. Specifically, we introduce two core innovations: (1) a domain-adaptive state space model that partitions the latent representation space into a shared subspace for learning cross-domain commonalities and independent, domain-specific subspaces for capturing intra-domain discriminative features; (2) three distinct Domain Adapters, which serve as domain-aware proxies to bridge disparate domain distributions and facilitate the alignment of cross-domain commonalities. Extensive experiments demonstrate the generalization and efficiency of Damba-ST. It achieves state-of-the-art performance on prediction tasks and demonstrates strong zero-shot generalization, enabling seamless deployment in new urban environments without extensive retraining or fine-tuning.


            
### AI分析（基于论文正文）
好的，作为一名资深的AI研究分析师，我将根据您提供的论文《Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction》内容，严格按照您的要求生成一份结构清晰、内容详实的论文总结。

***

### **论文总结：Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction**

#### **1. 论文概要**
本论文旨在解决跨城市/区域的时空预测基础模型所面临的计算效率低下与泛化能力不足的双重挑战。现有基于Transformer的模型存在二次计算复杂度问题，而直接应用线性复杂度的Mamba模型则因时空异构性和其递归机制导致跨域性能严重下降。为此，论文提出了Damba-ST，一种基于域自适应状态空间模型的高效城市时空预测框架。该方法通过将表示空间划分为共享子空间和域特定子空间，并引入域适配器作为桥梁，在保持Mamba线性复杂度优势的同时，显著提升了模型对异构域的适应性和零样本泛化能力。实验表明，Damba-ST在多种预测任务上达到了最先进的性能，并能无缝部署于未见过的城市环境。

#### **2. 研究动机**
论文的研究动机源于构建高效且泛化能力强的城市时空基础模型的迫切需求。现有工作存在两个主要不足：
1.  **计算效率瓶颈**：当前主流的时空基础模型（如OpenCity、UniST）普遍采用“Transformer + X”架构（见第I节）。其核心的自注意力机制在处理具有N个节点、T个时间步的时空图时，会产生O(T²)和O(N²)的二次计算复杂度，严重限制了模型在大规模图数据和长序列上的可扩展性及在边缘设备上的实际部署（见第I节）。
2.  **跨域泛化能力弱**：直接应用高效的Mamba模型作为时空主干网络会导致在未见区域上的负迁移和严重的性能退化（见摘要及第I节）。论文深入分析了其原因（见第I节及图1）：
    *   **时空异构性**：城市数据（如交通枢纽与住宅区）在时间和空间上存在固有的分布差异，缺乏像自然语言那样的通用词汇表，导致跨域数据分布差异显著。
    *   **递归漂移限制泛化**：Mamba的隐藏状态递归更新机制会累积并放大训练数据中的域特定特征，这虽然可能优化在已见域上的性能，但会损害模型对未见域的泛化能力。

因此，论文的核心动机是设计一个既能继承Mamba线性计算效率，又能有效应对时空异构性、实现强大跨域泛化的新型模型架构。

#### **3. 核心贡献与创新点**
论文的核心贡献与创新点主要体现在以下三个方面：
1.  **提出了首个面向高效异构时空预测的Mamba主干模型Damba-ST**（见摘要及第I节贡献列表）。这是首次将状态空间模型（SSM）系统地应用于解决城市时空预测中的异构性和计算复杂度问题，探索了SSM在时空上下文中的泛化能力。
2.  **设计了域自适应状态空间模型**（见第III.A节及图1(d)）。这是Damba-ST的核心概念创新。与现有基础模型通过数据融合训练学习单一共享表示空间不同，该方法将Mamba的表示空间显式地划分为两部分（见第I节）：
    *   **共享子空间**：用于学习跨域共性模式。
    *   **独立的域特定子空间**：用于捕获域内判别性特征。
    这种划分通过后续的**判别学习器**和**共性学习器**模块具体实现（见第III.E节），从机制上分离了域特定信息与跨域共享信息，为解决异构性导致的负迁移问题提供了结构基础。
3.  **引入了域适配器作为域感知代理**（见第III.A节）。这是连接和实现上述表示空间划分的关键技术组件。三个视图（空间、时间、时空延迟）的域适配器被初始化为可学习的嵌入向量，并承担双重功能：
    *   **域内代理**：在判别学习器中，作为序列的最后一个令牌，聚合全局域内模式（见公式(16)）。
    *   **跨域桥梁**：在适配器学习器中，所有域的适配器被拼接并经过双向SSM处理，促进高阶跨域知识交换（见公式(17)），最终形成的适配器表示被视为跨域共享模式。
    这一设计灵感来源于ViT/BERT中的[CLS]令牌，但将其扩展为每个域独有的、可通信的代理，专门用于桥接异构域数据并促进共性对齐。

#### **4. 方法概述**
Damba-ST的框架包含三个核心模块：多视图编码、域内扫描和跨域适应。其运作流程如下：
*   **步骤1：多视图编码**（第III.C节）。将输入时空数据分解为三个视图进行编码，并为每个域初始化对应的域适配器。
    *   **空间视图**：基于图拉普拉斯矩阵的特征向量初始化节点表示，并创建空间适配器 `S_i` 作为一个虚拟节点。
    *   **时间视图**：对时间序列进行反向实例归一化和1D卷积分块，创建时间适配器 `T_i` 作为一个可学习的块嵌入。
    *   **时空延迟视图**：通过计算节点间时间序列的最大互相关来估计传播延迟 `τ_ab`（公式(9)），并结合时间戳特征动态调整，创建延迟适配器 `D_i`。
*   **步骤2：域内扫描**（第III.D节）。将三个视图的数据标准化为统一的序列格式，并将对应域适配器附加到序列中。
    *   **空间双向扫描**：通过随机游走生成节点路径，并在路径首尾附加空间适配器，进行双向扫描以消除顺序偏差（公式(10)-(11)）。
    *   **时间扫描**：按时间顺序排列分块，并在序列末尾附加时间适配器（公式(12)）。
    *   **时空延迟扫描**：根据延迟矩阵 `τ_i`，将上游节点的历史时间块传播到下游节点，形成延迟传播序列，并在末尾附加延迟适配器（公式(13)-(14)）。
*   **步骤3：跨域适应**（第III.E节）。这是方法的核心，每个视图对应一个**域自适应状态空间模型**变体（DASSM_S, DASSM_T, DASSM_D）。每个DASSM包含三个学习器（以时间视图为例）：
    1.  **判别学习器**：为每个域 `i` 训练一个独立的SSM_i，处理扫描后的序列 `X_i`，生成域特定判别表示 `R_D^i`（公式(15)）。时间适配器 `T_i` 在此过程中被更新以吸收域内全局模式。
    2.  **适配器学习器**：将所有 `M` 个域的时间适配器拼接为序列 `T`，经过双向SSM处理，实现适配器间的信息交换，输出蕴含跨域共性的适配器 `\hat{T}^i`（公式(17)）。
    3.  **共性学习器**：首先，将判别表示 `R_D^i` 投影到其对应的适配器 `\hat{T}^i` 上，得到去偏后的表示 `R_{D->C}^i`（公式(18)）。然后，使用一个共享状态转移矩阵 `A_cross` 的SSM处理所有域的 `R_{D->C}^i`，生成跨域共性表示 `R_C^i`（公式(19)）。最后，融合判别表示和共性表示，得到最终的域自适应表示 `Y^i`（公式(20)）。
*   **步骤4：融合与预测**（第III.F节）。将三个DASSM变体输出的自适应表示 `Y_S^i`, `Y_T^i`, `Y_D^i` 进行融合（公式(23)），并通过一个线性投影层预测未来 `F` 个时间步的交通指标。
*   **优化**（第IV.A节）：训练目标结合了L1损失、模型差异正则化（公式(25)）和表示差异正则化（公式(26)），以扩大判别学习器与共性学习器之间的分离度。

#### **5. 实验说明**
*   **评估指标**：采用均方绝对误差（MAE）、均方根误差（RMSE）和平均绝对百分比误差（MAPE）。
*   **数据集**：使用大规模、公开的真实世界数据集进行预训练和评估，涵盖交通流量、出租车需求、自行车轨迹、速度等多种指标，涉及纽约、芝加哥、洛杉矶、上海、深圳等多个大都市区。预训练数据集总计包含10,110个区域和352,796个时间点，形成约1.51亿个时空观测值（见第V.A.1节及补充材料）。测试时使用训练中未包含的数据集，具体包括NYC-TAXI, PEMS-BAY, CAD12-2, CAD8-2, CAD8-1（域内预测，表I），以及CAD3, CAD5, PEMS07M, TrafficSH, CHI-TAXI, NYC-BIKE（零样本预测，表II）。
*   **对比基线方法**：
    *   **时空基础模型**：UniST, OpenCity。
    *   **Mamba-based

---

## 3. TimeMosaic: Temporal Heterogeneity Guided Time Series Forecasting via Adaptive Granularity Patch and Segment-wise Decoding

### 基本信息
- **作者**: Kuiye Ding, Fanda Fan, Chunyi Hou, Zheya Wang, Lei Wang, Zhengxin Yang, Jianfeng Zhan
- **arXiv ID**: [oai:arXiv.org:2509.19406v5](https://arxiv.org/abs/2509.19406)
- **发布日期**: Tue, 06 Jan 2026 00:00:00 -0500
- **分类**: cs.LG, cs.AI
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2509.19406)

            ### 原文摘要
            arXiv:2509.19406v5 Announce Type: replace-cross  Abstract: Multivariate time series forecasting is essential in domains such as finance, transportation, climate, and energy. However, existing patch-based methods typically adopt fixed-length segmentation, overlooking the heterogeneity of local temporal dynamics and the decoding heterogeneity of forecasting. Such designs lose details in information-dense regions, introduce redundancy in stable segments, and fail to capture the distinct complexities of short-term and long-term horizons. We propose TimeMosaic, a forecasting framework that aims to address temporal heterogeneity. TimeMosaic employs adaptive patch embedding to dynamically adjust granularity according to local information density, balancing motif reuse with structural clarity while preserving temporal continuity. In addition, it introduces segment-wise decoding that treats each prediction horizon as a related subtask and adapts to horizon-specific difficulty and information requirements, rather than applying a single uniform decoder. Extensive evaluations on benchmark datasets demonstrate that TimeMosaic delivers consistent improvements over existing methods, and our model trained on the large-scale corpus with 321 billion observations achieves performance competitive with state-of-the-art TSFMs.


            
### AI分析（基于论文正文）
好的，作为一名专业的AI研究分析师，我将根据您提供的论文信息和要求，生成一份结构清晰、内容详实的论文总结。

***

### **论文总结：TimeMosaic: Temporal Heterogeneity Guided Time Series Forecasting via Adaptive Granularity Patch and Segment-wise Decoding**

#### **1. 论文概要**
本文针对多元时间序列预测任务，指出现有基于固定长度片段（patch）的方法存在两个核心问题：编码异质性和解码异质性。前者指时间序列局部信息密度不均，固定长度片段无法适应；后者指不同预测步长（horizon）的难度和信息需求不同，单一解码器无法处理。为此，作者提出了TimeMosaic框架，包含两个核心模块：1）**自适应片段嵌入**，根据局部信息密度动态调整片段粒度；2）**分段式提示调优解码**，将不同预测区间视为相关子任务，通过可学习的提示嵌入实现分段专业化预测。在多个基准数据集上的实验表明，TimeMosaic在长期预测任务上取得了优于或可比拟现有方法的性能，并在大规模语料库上训练后，其性能与最先进的时间序列基础模型（TSFMs）相当。

#### **2. 研究动机**
论文的研究动机源于对现有基于片段的时间序列预测方法局限性的深入分析。尽管PatchTST、iTransformer等方法通过将序列划分为固定长度的片段取得了显著成功，但它们隐含地假设了整个序列具有均匀的时间动态和信息密度（见第1节）。然而，现实世界的时间序列数据存在显著的**时间异质性**（见第3节定义）。

具体而言，现有方法存在两个关键不足：
1.  **编码异质性未被建模**：论文指出，时间序列的局部区域在信息密度上存在巨大差异（见第1节，引用Huang et al. 2023; Warren Liao 2005）。信息密集区域（如剧烈波动）需要细粒度建模，而平稳区域则可粗粒度编码。固定长度片段无法适应这种变化，导致在信息密集区域丢失细节，在平稳区域引入冗余计算。此外，论文通过实证分析（见图2）揭示了固定长度片段在**模式复用**（Zipf-like分布）和**结构清晰度**（聚类分离度）之间存在权衡，无法同时优化两者（见第2节）。
2.  **解码异质性被忽视**：论文观察到，不同预测步长的预测任务在难度和信息需求上存在不对称性（见第1、4.1节）。短期预测主要依赖近期局部信息，而长期预测则需要建模更抽象、不确定的长期动态。现有方法通常使用单一的全局解码器处理所有预测步长，忽略了这种异质性，导致模型容量与预测需求不匹配。

因此，论文的核心动机是提出一个统一的框架，同时解决输入侧的**编码异质性**和输出侧的**解码异质性**，以提升时间序列预测的准确性和鲁棒性。

#### **3. 核心贡献与创新点**
本文的核心贡献与创新点可归纳为以下三个方面：

1.  **提出了一个同时建模编码与解码异质性的预测框架**：TimeMosaic是首个明确将时间序列预测中的异质性分解为“编码”和“解码”两个维度，并系统性提出解决方案的框架（见第1节贡献列表）。这为理解时间序列预测的复杂性提供了一个新的视角，并引导了后续的模块设计。

2.  **设计了自适应片段嵌入模块**：该模块的核心创新在于**动态、非重叠地**调整片段粒度（见第4.3节）。与先前多粒度方法（如PathFormer、DualSG）可能产生重叠或乱序片段不同，TimeMosaic确保每个时间步仅属于一个片段，严格保持了时间连续性，这对预测任务至关重要（见第2节对比）。其机制是：先将输入序列划分为固定数量的区域（region），然后通过一个轻量级分类器为每个区域从候选粒度集合中选择最优的片段长度，选择过程通过Gumbel-Softmax实现端到端可微（见公式(2)）。此外，通过**预算损失**（公式(6)）正则化不同粒度的使用比例，防止模型退化到总是选择最细粒度。

3.  **引入了分段式提示调优解码策略**：该策略的创新点在于将**提示调优**技术引入时间序列预测，并用于建模解码异质性（见第4.4节）。具体而言，它将不同的预测区间（segment）视为多任务学习中的子任务，为每个子任务分配一个可学习的提示嵌入（prompt embedding）。在注意力计算中，查询（Query）仅来自数据令牌，而键（Key）和值（Value）则融合了提示嵌入（见公式(11)）。这种“提示掩码注意力”机制允许提示在不修改主干编码器参数的情况下，为不同预测区间注入特定的归纳偏置，实现分段专业化。这与依赖强周期性假设的基重构方法（如TimeBase）或修改解码器参数的方法有本质区别（见第2节）。

#### **4. 方法概述**
TimeMosaic的整体架构遵循Transformer编码器范式，其核心流程如下（结合图3）：

**A. 自适应片段嵌入**
1.  **区域划分与候选集**：给定输入序列 `x ∈ R^(B×C×L)`，首先将其划分为 `R = L / f_max` 个非重叠区域。定义一个候选片段长度集合 `F = {f1, f2, ..., fK}`（见公式(1)）。
2.  **粒度分类**：对于每个区域 `x_r`，使用一个共享的轻量级两层MLP分类器 `G_θ` 预测其最优片段长度的logits `g_r`（见公式(2)）。通过Gumbel-Softmax在训练时进行可微选择，得到选定索引 `θ_r`。
3.  **片段化与对齐**：根据选定的长度 `f_(θ_r)` 将区域 `x_r` 展开为片段，并通过线性层投影到嵌入空间，得到 `z_r ∈ R^(N_r×d)`（见公式(3)）。为了保持所有区域输出形状一致以输入Transformer，使用**复制填充**将每个区域的片段序列上采样到固定长度 `N = f_max / f_min`，得到 `ž_r`（见公式(4)）。此操作优于插值，能保持时间对齐且不引入人造内容。
4.  **拼接与位置编码**：将所有区域的填充后嵌入 `{ž_1, ..., ž_R}` 沿序列维度拼接，并添加位置编码，形成最终的编码器输入 `Z`（见公式(5)）。

**B. 分段式提示调优解码**
1.  **提示注入**：对于第 `k` 个预测区间（子任务），定义其提示嵌入 `φ_k ∈ R^(l×d)`。将其与编码器输入 `X`（即 `Z` 经过若干层Transformer编码后的表示）拼接，得到 `X̃_k`（见公式(10)）。
2.  **提示掩码注意力**：在自注意力层中，执行不对称计算：`Q_k = X W^Q`，`K_k = X̃_k W^K`，`V_k = X̃_k W^V`（见公式(11)）。这使得数据令牌的查询能够与融合了特定任务提示的键和值进行交互，从而让提示引导注意力聚焦于与当前预测区间相关的信息。
3.  **分段预测**：经过共享编码器（参数冻结）处理后，每个预测区间 `k` 使用其专属的预测头 `f_k(·; θ_k)` 进行解码，得到该区间的预测结果 `Ŷ^(k)`（见公式(12)）。

**C. 训练目标**
总损失函数为预测损失和预算损失的加权和：`L_total = L_forecast + λ L_budget`（见公式(8)）。其中 `L_forecast` 为标准均方误差（MSE，公式(9)），`L_budget` 用于约束不同粒度片段的使用比例接近预设分布（公式(6)）。

#### **5. 实验说明**
- **评估指标**：采用均方误差（MSE）和平均绝对误差（MAE）。
- **数据集**：实验涵盖17个真实世界多元时间序列数据集。
    - **长期预测**：ETTh1, ETTh2, ETTm1, ETTm2, Weather, Traffic, Electricity, ExchangeRate, Solar-Energy, Wind (Location1–4)。
    - **短期预测**：PEMS03, PEMS04, PEMS07, PEMS08。
- **对比基线方法**（按类别列出）：
    - **近期SOTA模型**：TimeFilter, SimpleTM, PatchMLP, xPatch, DUET, PathFormer, iTransformer, TimeMixer, PatchTST, FreTS, DLinear, LightTS。
    - **零样本/LLM方法**：GPT4TS, LLMTime。
    - **预训练时间序列基础模型**：TimeMoE, MOIRAI, Chronos, TimesFM, Moment。
- **实验条件**：论文中明确说明所有实验在 **8块A800 GPU** 上使用PyTorch实现（见第5节“Implementation Details”）。训练、微调、推理的具体配置（如batch size

---

## 4. Dichotomous Diffusion Policy Optimization

### 基本信息
- **作者**: Ruiming Liang, Yinan Zheng, Kexin Zheng, Tianyi Tan, Jianxiong Li, Liyuan Mao, Zhihao Wang, Guang Chen, Hangjun Ye, Jingjing Liu, Jinqiao Wang, Xianyuan Zhan
- **arXiv ID**: [oai:arXiv.org:2601.00898v1](https://arxiv.org/abs/2601.00898)
- **发布日期**: Tue, 06 Jan 2026 00:00:00 -0500
- **分类**: cs.LG, cs.RO
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2601.00898)

            ### 原文摘要
            arXiv:2601.00898v1 Announce Type: new  Abstract: Diffusion-based policies have gained growing popularity in solving a wide range of decision-making tasks due to their superior expressiveness and controllable generation during inference. However, effectively training large diffusion policies using reinforcement learning (RL) remains challenging. Existing methods either suffer from unstable training due to directly maximizing value objectives, or face computational issues due to relying on crude Gaussian likelihood approximation, which requires a large amount of sufficiently small denoising steps. In this work, we propose DIPOLE (Dichotomous diffusion Policy improvement), a novel RL algorithm designed for stable and controllable diffusion policy optimization. We begin by revisiting the KL-regularized objective in RL, which offers a desirable weighted regression objective for diffusion policy extraction, but often struggles to balance greediness and stability. We then formulate a greedified policy regularization scheme, which naturally enables decomposing the optimal policy into a pair of stably learned dichotomous policies: one aims at reward maximization, and the other focuses on reward minimization. Under such a design, optimized actions can be generated by linearly combining the scores of dichotomous policies during inference, thereby enabling flexible control over the level of greediness.Evaluations in offline and offline-to-online RL settings on ExORL and OGBench demonstrate the effectiveness of our approach. We also use DIPOLE to train a large vision-language-action (VLA) model for end-to-end autonomous driving (AD) and evaluate it on the large-scale real-world AD benchmark NAVSIM, highlighting its potential for complex real-world applications.


            
### AI分析（基于论文正文）
好的，作为一名专业的AI研究分析师，我将根据您提供的论文《Dichotomous Diffusion Policy Optimization》和所有约束条件，生成一份结构清晰、内容详实的论文总结。

***

### **论文总结：Dichotomous Diffusion Policy Optimization**

#### **1. 论文概要**
本文提出了一种名为DIPOLE（Dichotomous diffusion Policy improvement）的新型强化学习算法，旨在解决扩散策略在强化学习训练中面临的稳定性与贪婪性权衡难题。论文首先分析了基于KL正则化目标的加权回归方法在训练扩散策略时，因指数权重项导致损失爆炸和训练不稳定的问题。为此，作者设计了一种“贪婪化”的策略正则化方案，将最优策略分解为一对稳定学习的“二分策略”：一个专注于奖励最大化，另一个专注于奖励最小化。在推理时，通过线性组合这两个策略的分数函数，可以灵活控制生成动作的贪婪程度。该方法在ExORL和OGBench基准测试的离线和离线到在线强化学习设置中进行了验证，并进一步应用于训练一个大型视觉-语言-动作模型，在真实世界自动驾驶基准NAVSIM上展示了其解决复杂现实任务的能力。

#### **2. 研究动机**
扩散模型因其强大的多模态分布建模能力和推理时的可控生成特性，已成为决策任务中流行的策略表示方法。然而，使用强化学习有效训练大型扩散策略仍然充满挑战（见第1节）。现有方法主要存在两类问题：
1.  **直接价值最大化方法**：通过反向传播梯度直接优化奖励或价值目标（如ReFL、DRaFT），会因多步去噪过程导致梯度噪声大、训练不稳定，且计算成本高昂（第1节）。
2.  **基于似然近似的方法**：将去噪过程建模为多步MDP并使用高斯近似计算对数似然（如DDPO、DPPO），其粗糙的近似仅在采用足够小的去噪步长时才合理，这导致巨大的探索空间和漫长的训练，难以扩展且易累积近似误差（第1节）。

另一条有前景的路径是基于KL正则化目标的加权回归方法（如式(3)所示），它为最优策略提取提供了一个简洁的闭式解。然而，该方法在实践中并未被广泛采用（第3.1节）。作者深入分析了其根本原因：**最优性-稳定性权衡**。当温度参数β设置较大以实现贪婪优化时，指数权重项 `exp(βG(s, a))` 会急剧增长，导致高价值样本的权重极大，引发学习损失爆炸和训练不稳定（见图1及第3.1节）。此外，这还会导致**学习效率低下**，因为损失被少数高质量样本主导，而低质量样本仍具有正权重，可能对策略学习产生负面影响（第3.1节）。因此，论文的核心动机是设计一种既能实现贪婪策略优化，又能保证训练稳定性和高效性的扩散策略强化学习框架。

#### **3. 核心贡献与创新点**
本文的核心贡献在于提出了一套理论严谨且实践有效的扩散策略优化框架DIPOLE，其创新点具体如下：

1.  **提出贪婪化的KL正则化目标**：论文没有直接优化标准的KL正则化目标（式(2)），而是引入了一个经过修改的、更贪婪的目标（式(5)）。该目标将策略π正则化向一个由有界Sigmoid函数 `σ(βG(s, a))` 加权的、价值感知的参考策略。这一设计借鉴了部分离线RL方法的思想，但使用了平滑有界的Sigmoid函数来避免数值不稳定，并引入了一个新的**贪婪因子ω**作为额外的控制接口（第3.2节）。

2.  **理论推导出最优策略的二分分解形式**：基于上述贪婪化目标，论文在**定理1**中推导出其闭式最优解（式(6)）。通过巧妙利用Sigmoid函数的性质（`σ(x) = 1/(1+exp(-x))`），作者进一步将该最优解重写为两个加权参考政策的比值形式（式(7)）。这自然引出了**二分策略**的定义（式(8)）：
    *   **正向策略 π+**：`∝ μ(a|s) · σ(βG(s, a))`，专注于学习高回报样本。
    *   **负向策略 π-**：`∝ μ(a|s) · (1 - σ(βG(s, a)))`，专注于学习低回报样本。
    这一分解是概念上的关键创新，它将原本不稳定的、无界的指数权重问题，转化为两个由有界Sigmoid函数加权的、可独立稳定学习的子问题（第3.2节）。

3.  **实现稳定且高效的策略训练**：基于分解，正向和负向策略可以通过两个扩散模型，分别使用式(9)中的有界加权损失进行训练。这从根本上解决了原始指数加权回归中的损失爆炸问题。同时，由于二分策略明确区分了高、低回报样本的学习目标，能够更充分地利用数据集中的所有样本，提高了学习效率（第3.2节）。

4.  **建立与分类器无引导机制的理论联系，实现可控推理**：论文证明，最优策略的对数梯度（分数函数）可以表示为二分策略分数函数的线性组合（式(10)）：`∇_a log π⋆(a|s) = (1+ω)∇_a log π+(a|s) - ω∇_a log π-(a|s)`。这与扩散模型中广泛使用的**分类器无引导机制**在形式上高度一致。在推理时，只需使用组合后的噪声预测器 `˜ϵ = (1+ω)ϵ+_θ1 - ωϵ-_θ2` 进行反向采样，即可生成动作。贪婪因子ω在此直接控制了策略的贪婪程度，实现了完美的可控性（第3.2节）。这与缺乏理论支撑且性能次优的CFGRL方法形成了鲜明对比。

#### **4. 方法概述**
DIPOLE方法的核心流程可分为目标重构、策略分解、训练与推理三个阶段，其技术细节如下：

**第一阶段：目标重构与理论推导**
1.  **问题设定**：在标准的MDP框架下，拥有一个由行为策略（离线）或上一轮策略（在线）收集的数据集D，以及一个预训练的扩散参考策略μ（噪声预测器为 `ϵ_θ`）。
2.  **提出新目标**：放弃标准KL目标（式(2)），采用贪婪化目标（式(5)），其中参考策略被替换为 `μ(a|s)·σ(βG(s, a))/Z(s)`。这里G(s, a)通常为优势函数A(s, a)。
3.  **求解最优解**：通过求解式(5)的约束优化问题，得到定理1中的最优解形式（式(6)）。

**第二阶段：策略分解与损失函数设计**
1.  **数学变换**：利用Sigmoid函数与指数函数的关系 `exp(ωx) = [σ(x)/(1-σ(x))]^ω`，将式(6)重写为式(7)的比值形式。
2.  **定义二分策略**：根据式(7)分子分母的结构，自然定义出正向策略π+和负向策略π-（式(8)）。
3.  **设计训练损失**：根据引理1（将加权回归应用于扩散损失），为两个策略分别设计训练目标（式(9)）：
    *   `L_ϵ+_θ1 = E[... σ(βG(s, a)) · ||ϵ - ϵ+_θ1(a_t, s, t)||^2 ]`
    *   `L_ϵ-_θ2 = E[... (1-σ(βG(s, a))) · ||ϵ - ϵ-_θ2(a_t, s, t)||^2 ]`
    这两个损失函数中的权重项 `σ(βG(s, a))` 和 `1-σ(βG(s, a))` 均被限制在(0,1)区间，确保了训练的稳定性。

**第三阶段：模型实现与推理**
1.  **模型架构**：训练两个独立的扩散模型网络 `ϵ+_θ1` 和 `ϵ-_θ2`，分别用上述损失进行优化。在实践中，可以采用共享主干网络加独立输出头或LoRA等参数高效微调方式（第3.3节，附录E）。
2.  **可控推理**：在动作生成阶段，不直接使用 `ϵ+_θ1` 或 `ϵ-_θ2`，而是构造引导后的噪声预测器：`˜ϵ (a_t, s, t) = (1 + ω)ϵ+_θ1 (a_t, s, t) - ωϵ-_θ2 (a_t, s, t)`。将此 `˜ϵ` 代入标准扩散模型的反向采样过程（如DDIM），即可生成来自近似最优策略 `π⋆` 的动作。通过调节ω，可以连续控制策略的贪婪程度：ω=0时退化为π+；ω增大时，策略更贪婪地追求高回报。

**应用扩展**：论文还将DIPOLE应用于大规模视觉-语言-动作模型的训练（第3.3节）。使用Florence-2作为视觉语言编码器，扩散模型作为动作解码

---

## 5. Spectral-Window Hybrid (SWH)

### 基本信息
- **作者**: Vladimer Khasia
- **arXiv ID**: [oai:arXiv.org:2601.01313v1](https://arxiv.org/abs/2601.01313)
- **发布日期**: Tue, 06 Jan 2026 00:00:00 -0500
- **分类**: cs.LG
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2601.01313)
- **源码地址**: [查看源码](https://github.com/vladimerkhasia/swh)

            ### 原文摘要
            arXiv:2601.01313v1 Announce Type: new  Abstract: Scaling sequence modeling to extreme contexts requires balancing computational efficiency with representational expressivity. While Transformers provide precise retrieval via the attention mechanism, their quadratic $\mathcal{O}(T^2)$ complexity limits their application to long-horizon tasks. In this work, we propose the \textbf{Spectral-Window Hybrid (SWH)}, an architecture that decouples sequence modeling into two \textit{parallel} streams: a global branch utilizing the Convolution Theorem to model long-range decay dynamics in $\mathcal{O}(T \log T)$ time, and a local branch employing sliding-window attention for token interactions within a bounded context. By aggregating these representations, SWH avoids the computational bottleneck of global attention while retaining local precision. We demonstrate that SWH matches the perplexity of standard Transformers on short contexts while enabling efficient linear scaling to extended sequences. The code is available at https://github.com/VladimerKhasia/SWH


            
### AI分析（基于论文正文）
### **论文概要**

本文提出了一种名为谱窗混合（Spectral-Window Hybrid, SWH）的新型序列建模架构，旨在解决标准Transformer模型在处理超长序列时面临的二次方计算复杂度瓶颈。SWH将序列建模解耦为两个并行分支：一个利用卷积定理在频域进行因果卷积的全局分支，以对数线性复杂度建模长程衰减动态；另一个采用分块滑动窗口注意力机制的局部分支，以线性复杂度处理有界上下文内的细粒度令牌交互。通过聚合这两个分支的输出，SWH在避免全局注意力计算瓶颈的同时，保留了局部建模的精确性。实验表明，在短上下文任务上，SWH与标准Transformer的困惑度相当，并能高效地线性扩展到更长的序列。

### **研究动机**

序列建模是现代人工智能，尤其是大型语言模型（LLMs）的核心。Transformer架构因其自注意力机制在建模密集的成对依赖关系方面的有效性而成为标准。然而，标准的全局自注意力在时间和内存上均具有O(T²)的计算成本（第1节）。尽管像FlashAttention这样的硬件感知优化降低了激活内存的复杂度，但渐进的二次方计算缩放对于跨越数百万令牌的上下文长度仍然是一个根本性瓶颈（第1节）。

为了应对这一挑战，研究者们探索了结构化状态空间模型（SSMs）。早期的线性时不变（LTI）系统，如S4，利用连续时间系统的卷积表示来实现线性缩放。最近，像Mamba这样的选择性SSM引入了输入依赖的动态机制，以解决LTI系统在内容依赖推理和上下文学习方面的局限性（第1节）。基于这些进展，近期架构开始转向混合模型，将循环的效率与注意力的精确性相结合。例如，Jamba采用顺序混合方法，交替堆叠Mamba层和全局注意力层；Griffin则结合了循环块（RG-LRU）和局部滑动窗口注意力，完全避免全局注意力以保持固定大小的推理状态（第1节）。

尽管这些混合模型取得了进展，但作者认为它们主要采用**顺序**的混合策略（如Jamba的层间交替）。本文的研究动机在于探索一种**并行解耦**的替代方案。具体而言，作者旨在设计一种架构，能够同时、独立地处理序列的全局长程模式和局部细粒度交互，从而更高效地结合卷积的全局建模能力和注意力的局部精确性，以应对极端长上下文序列建模的挑战（第1节）。这种动机在引言末尾被明确表述为“探索这些顺序混合模型的替代安排”，并提出“利用全局卷积和局部注意力的并行解耦方法”（第1节）。

### **核心贡献与创新点**

本文的核心贡献在于提出并验证了SWH这一新颖的并行混合架构，其创新点具体体现在以下几个方面：

1.  **并行解耦的全局-局部建模范式**：与Jamba、Griffin等将不同机制（如SSM与注意力）在层间或块间**顺序**堆叠的混合模型不同，SWH在**同一层内**将序列建模任务解耦为两个**并行**处理流（第1、2节）。全局分支负责捕获长程的、具有衰减特性的依赖关系，而局部分支专注于有界窗口内的精确令牌交互。这种设计允许两个分支独立优化其擅长处理的模式，并通过简单的求和与投影进行融合（公式(1)），在概念上提供了一种更灵活和高效的混合策略。

2.  **基于卷积定理的因果谱卷积全局分支**：全局分支的创新在于设计了一种参数化的因果卷积核，并利用卷积定理实现高效计算。
    *   **参数化衰减卷积核**：卷积核K被参数化为阻尼谐振子的脉冲响应（公式(2)）。对于每个通道c，核在时间步t的值由可学习的衰减参数α_c和频率参数ω_c决定：`K_{t,c} = exp(-|α_c|·t) cos(ω_c·t)`。这种设计显式地编码了长程依赖中常见的指数衰减先验，为模型提供了结构化的归纳偏置（第2.1节）。
    *   **基于FFT的O(T log T)高效实现**：直接计算深度因果卷积（公式(3)）是O(T²)的。SWH利用卷积定理，通过快速傅里叶变换（FFT）在频域执行逐元素乘法，将复杂度降至O(T log T)。为确保因果性并防止离散傅里叶变换固有的循环混叠，输入和核需在时间维度上零填充至长度L ≥ 2T（公式(4)）。计算在FP32精度下进行以确保数值稳定性（第2.1.1节，算法1第1-5行）。这提供了一种与输入内容无关的、确定性的长程建模机制。

3.  **结合全局位置编码的分块滑动窗口注意力局部分支**：局部分支的创新在于将滑动窗口注意力重新表述为“分块注意力”，并巧妙地集成全局位置信息。
    *   **分块注意力与上下文管理**：将输入序列划分为大小为W的非重叠块（第2.2节）。对于第n个块，其键值上下文由前一个块的缓存（K^(n-1), V^(n-1)）与当前块（K^(n), V^(n)）拼接而成，形成一个大小为2W的有效感受野（公式(6)）。这种分块化优化了内存访问模式。
    *   **全局RoPE与块因果掩码**：在分块**之前**，对全局的查询和键序列应用旋转位置编码（RoPE）（公式(5)），确保了整个序列中相对位置信息的连贯性（第2.2.1节）。随后，设计了一种块因果掩码（公式(7), (8)），用于处理分块带来的边界问题：对于第一个块，需要屏蔽无效的“前一个上下文”区域；对于后续块，前一个块完全可见，当前块内部则实施标准的因果掩码（第2.2.2节，算法1第13-23行）。这使得局部注意力在享受线性复杂度O(T·W·D)的同时，能够感知全局的绝对位置。

4.  **理论上的复杂度优势与实证效率验证**：如表1所示，SWH的总时间复杂度为O(T(log T + W)D)，空间复杂度为O(TD)，彻底消除了标准注意力的O(T²)瓶颈（第2.4节）。论文通过系统的基准测试（第3.3节，图3）验证了这一点，显示SWH在长序列推理时具有近线性的延迟和内存增长，显著优于呈二次方增长的Transformer基线。

### **方法概述**

SWH架构以前向传播过程（算法1）为核心，其输入为`X ∈ R^{B×T×D}`，输出为`Y ∈ R^{B×T×D}`。方法流程如下：

**1. 全局谱卷积分支：**
   首先，输入X通过一个线性投影`W_conv`得到`U`（算法1第1行）。根据公式(2)，利用可学习的参数α和ω生成因果卷积核K（第2行）。为实现基于FFT的线性卷积，将U和K在时间维度上零填充至长度2T，得到`Û`和`Ķ`（第3行）。随后在频域执行计算：分别对`Û`和`Ķ`进行实值FFT（rFFT），在频域进行逐元素乘法（Hadamard积），再进行逆FFT（irFFT）变换回时域，得到`H_spec`（第4行）。最后，裁剪`H_spec`的前T个时间步，得到谱分支输出`Y_spec`（第5行）。整个过程如公式(4)所述，确保了操作的因果性和高效性。

**2. 局部滑动窗口注意力分支：**
   a) **投影与全局位置注入**：输入X分别通过线性投影得到查询Q、键K、值V（算法1第6行）。紧接着，在**分块之前**，对全局的Q和K应用RoPE，注入绝对位置信息（第7行）。
   b) **序列分块与填充**：若序列长度T不能被窗口大小W整除，则对Q、K、V进行右端零填充（第8-9行）。然后将它们均匀分割成N个大小为W的块（第10行）。
   c) **分块循环计算**：初始化前一块的键值缓存`K_prev`, `V_prev`为零（第11行）。对于第n个块（从1到N）：
      *   将前一块缓存`K_prev`, `V_prev`与当前块的`K^(n)`, `V^(n)`拼接，形成当前块的上下文`K_ctx`, `V_ctx`（第14行）。
      *   计算注意力分数`A^(n)`（公式(7)），并应用块因果掩码`M^(n)`（公式(8)）。特别地，对于第一个块（n=1），需要将代表无效上下文的区域（索引0:W）屏蔽为负无穷（第17-19行）。
      *   对掩码后的分数进行Softmax，并与`V_ctx`加权求和，得到当前块的输出`O^(n)`，将其加入结果列表（第20-21行）。
      *   更新缓存：`K_prev

---

## 6. Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation

### 基本信息
- **作者**: Huajie Tan, Peterson Co, Yijie Xu, Shanyu Rong, Yuheng Ji, Cheng Chi, Xiansheng Chen, Qiongyu Zhang, Zhongxia Zhao, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang
- **arXiv ID**: [oai:arXiv.org:2601.01618v1](https://arxiv.org/abs/2601.01618)
- **发布日期**: Tue, 06 Jan 2026 00:00:00 -0500
- **分类**: cs.RO
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2601.01618)

            ### 原文摘要
            arXiv:2601.01618v1 Announce Type: new  Abstract: Long-horizon robotic manipulation is increasingly important for real-world deployment, requiring spatial disambiguation in complex layouts and temporal resilience under dynamic interaction. However, existing end-to-end and hierarchical Vision-Language-Action (VLA) policies often rely on text-only cues while keeping plan intent latent, which undermines referential grounding in cluttered or underspecified scenes, impedes effective task decomposition of long-horizon goals with close-loop interaction, and limits causal explanation by obscuring the rationale behind action choices. To address these issues, we first introduce Visual Sketch, an implausible visual intermediate that renders points, boxes, arrows, and typed relations in the robot's current views to externalize spatial intent, connect language to scene geometry. Building on Visual Sketch, we present Action-Sketcher, a VLA framework that operates in a cyclic See-Think-Sketch-Act workflow coordinated by adaptive token-gated strategy for reasoning triggers, sketch revision, and action issuance, thereby supporting reactive corrections and human interaction while preserving real-time action prediction. To enable scalable training and evaluation, we curate diverse corpus with interleaved images, text, Visual Sketch supervision, and action sequences, and train Action-Sketcher with a multi-stage curriculum recipe that combines interleaved sequence alignment for modality unification, language-to-sketch consistency for precise linguistic grounding, and imitation learning augmented with sketch-to-action reinforcement for robustness. Extensive experiments on cluttered scenes and multi-object tasks, in simulation and on real-world tasks, show improved long-horizon success, stronger robustness to dynamic scene changes, and enhanced interpretability via editable sketches and step-wise plans. Project website: https://action-sketcher.github.io


            
### AI分析（基于论文正文）
好的，作为一名专业的AI研究分析师，我将根据您提供的论文信息，生成一份符合顶级会议风格的详细论文总结。

***

### **论文总结：Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation**

#### **1. 论文概要**
本文针对长视野机器人操作任务中存在的空间歧义性和时序脆弱性问题，提出了一种名为“Action-Sketcher”的视觉-语言-动作（VLA）框架。该框架的核心创新是引入了“视觉草图”（Visual Sketch）这一显式的空间意图表示，它由叠加在机器人当前视角图像上的点、边界框和箭头等几何基元构成。Action-Sketcher采用“观察-思考-草图-执行”（See-Think-Sketch-Act）的循环工作流程，通过自适应令牌门控策略在推理模式（生成草图和子任务规划）与动作模式（基于草图生成连续动作）间切换。实验表明，该方法在模拟和真实世界的复杂、长视野任务中，相比现有VLA基线模型，在任务成功率、对动态场景变化的鲁棒性以及人机交互可解释性方面均有显著提升。

#### **2. 研究动机**
长视野机器人操作在真实世界部署中至关重要，但面临两大核心挑战（见第1节引言）。**首先，在空间层面，语言到动作的映射是脆弱的**。自然语言指令在复杂场景中往往存在歧义（例如，“把茶倒进杯子里”面对多个杯子时）或定义不明确（例如，“把书放在马克杯左边”，未指定精确目标位姿）。现有端到端VLA模型（如[9, 30]）将规划意图隐含在潜在表示中，导致在杂乱或定义不清的场景中难以进行指称消歧和任务分解。**其次，在时序层面，人机协同能力薄弱**。实时交互有限，且可解释的规划过程很少暴露，使得小错误容易传播。现有的分层VLA方法（如[61, 65]）虽然引入了规划器，但其推理通常是瞬时或局部的，缺乏对全局意图（如演变的人类目标、新出现的错误）的持续建模，且对指称消歧的支持有限。

作者进一步指出，近期“先思考后行动”的VLA变体（如EO-1 [62], OneTwoVLA [44]）虽然集成了显式推理，但其中间证据仍仅为文本形式，导致动作背后的空间指称（接触点、接近方向、物体关系）保持隐含（见第2节相关工作）。这阻碍了人类验证，并剥夺了控制器获得低熵几何指导的机会。因此，论文的核心动机是**在语言与控制接口之间，通过引入一种显式的、可验证的视觉中间表示来外化空间意图**，从而解决上述空间歧义和时序协同问题，实现更可靠、可解释的长视野操作。

#### **3. 核心贡献与创新点**
本文的核心贡献与创新点可归纳为以下三个方面：

1.  **形式化“视觉草图”作为显式空间意图接口**：本文首次系统性地提出并形式化了“视觉草图”这一概念，将其定义为一种共接地的、显式的空间意图接口（见第3.1节）。视觉草图由渲染在机器人自我视角图像平面上的稀疏几何基元（边界框 `Bt`、关键点 `Pt`、箭头 `At`）组成（公式(1)）。其创新性在于：a) **显式性与可解释性**：它将隐含的空间意图（如“抓取哪里”、“如何移动”）转化为人类可直接阅读、验证和修改的视觉表示，充当了高层推理与底层控制之间的“可验证契约”（见第1节）。b) **结构化语义**：不同于以往粗略的轨迹草图[22]或非可编辑的潜在计划[25]，本文的草图具有精细的结构化语义：边界框用于物体级指称消歧（公式(2)），关键点指定精确的交互位置（公式(3)），箭头则进一步分解为编码末端执行器轨迹的**平移箭头**（公式(4)）和编码绕规范轴旋转的**旋转箭头**（公式(5)-(6)），从而能表达更丰富、精确的动作基元。

2.  **提出基于令牌门控的“观察-思考-草图-执行”循环框架**：本文提出了Action-Sketcher框架，其核心创新在于一个由事件驱动、自适应切换的双模式推理-执行循环（见第3.2.1节及图2）。该框架通过特殊的控制令牌（如 `<BOR>` 开始推理，`<BOA>` 开始动作）来协调工作流。当需要重新规划或遇到错误时，模型进入**推理模式**，进行时序（决定下一个子任务）和空间（生成对应视觉草图）推理，并以 `<EOR>` 结束。在常规执行阶段，模型进入**动作模式**，基于当前草图通过流匹配（Flow-Matching）生成动作块。这种设计使得模型能够**在单个统一架构内**，动态平衡深思熟虑的规划需求与实时执行的要求，并天然支持基于草图的人为中断和修正。

3.  **设计了用于对齐多模态与训练鲁棒策略的课程学习方案**：为了有效训练该框架，作者设计了一个三阶段课程学习策略（见第3.2.3节）。**阶段一**（基础时空学习）利用大规模数据预训练模型的基础时空理解和指令跟随能力。**阶段二**（推理到草图增强）使用真实世界收集的长视野任务数据，微调模型完整的推理模式流程，即根据任务指令和执行历史生成下一个子任务及其文本描述草图。**阶段三**（草图到动作与模式适应）是关键创新，它**联合训练动作策略和模式切换机制**。此阶段引入了针对视觉草图的随机扰动增强（如对边界框和关键点施加噪声），以提高动作专家对草图生成误差的鲁棒性。同时，采用模式平衡采样策略（公式(7)）解决动作模式样本远多于推理模式样本的数据不平衡问题，防止模型产生模式选择偏差。

#### **4. 方法概述**
Action-Sketcher方法的核心是实现“观察-思考-草图-执行”的循环。其技术方案详细流程如下：

**输入与表示**：在每一步 `t`，模型的输入上下文是一个令牌序列，包括多视角图像（如左腕、右腕、基座摄像头）、任务指令、已完成子任务的历史、当前子任务以及视觉草图图像（见图2）。视觉草图 `St` 被形式化为一个三元组 `(Bt, Pt, At)`，其中包含边界框、关键点和箭头集。

**双模式自适应循环**：
*   **推理模式触发与执行**：当模型判断需要推理时（如子任务完成、检测到错误、人为干预），它生成 `<BOR>` 令牌。随后，模型自回归地进行：1) **时序推理**：分析当前场景、总体任务和已完成历史，推断出下一个逻辑子任务。2) **空间推理**：基于新的子任务，对场景中的物体布局和关系进行推理，生成文本形式的视觉草图描述（例如，`{“bbox”: [x1,y1,x2,y2], “arrow”: [[x_start, y_start], [x_end, y_end]]}`）。此过程以 `<EOR>` 结束。生成的文本草图被渲染到当前参考视角上，形成图像格式的视觉草图，并更新输入上下文。
*   **动作模式触发与执行**：当场景稳定、无需重新规划时，模型生成 `<BOA>` 令牌，触发**动作专家**。动作专家以当前观察（图像）和视觉草图为条件，通过**流匹配**（Flow-Matching）技术[45]预测一段连续的动作块（`∆T, ∆R` 等）。动作生成是自回归的，直到子任务完成或模式被切换。

**模型架构与训练**：框架是模型无关的，本文实例化时采用 `π0` [9] 作为骨干模型（见第3.2.2节）。模型被训练为能够自回归生成文本推理链和结构化草图描述，同时优化流匹配损失以预测连续动作。训练遵循第3.2.3节的三阶段课程：
1.  **阶段一**：在大规模时空数据集（340万空间样本，87万时序序列）上进行预训练，其中20%的时序数据通过GPT-4o[27]标注了详细文本推理链，以培养显式推理能力。
2.  **阶段二**：使用从真实世界（2.6k幕）和现有数据集（如LIBERO[46]）中收集和标注的长视野任务数据（共21k样本），微调模型完整的“推理模式”能力，即从指令和历史生成子任务和草图。
3.  **阶段三**：使用包含模式切换标签和动作标签的数据，**联合优化动作预测和模式选择**。关键技巧包括：对真实草图进行扰动增强以提高动作策略的鲁棒性；采用公式(7)的模式平衡采样来避免模型偏向频繁的 `<BOA>` 模式。

#### **5. 实验说明**
*   **评估指标**：主要评估指标为**任务成功率**（模拟环境）和**子任务完成率**（真实世界）。在失败分析中，对错误模式（

---

## 7. CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding

### 基本信息
- **作者**: Chenyang Ma, Guangyu Yang, Kai Lu, Shitong Xu, Bill Byrne, Niki Trigoni, Andrew Markham
- **arXiv ID**: [oai:arXiv.org:2601.02295v1](https://arxiv.org/abs/2601.02295)
- **发布日期**: Tue, 06 Jan 2026 00:00:00 -0500
- **分类**: cs.RO
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2601.02295)

            ### 原文摘要
            arXiv:2601.02295v1 Announce Type: new  Abstract: Current work on robot failure detection and correction typically operate in a post hoc manner, analyzing errors and applying corrections only after failures occur. This work introduces CycleVLA, a system that equips Vision-Language-Action models (VLAs) with proactive self-correction, the capability to anticipate incipient failures and recover before they fully manifest during execution. CycleVLA achieves this by integrating a progress-aware VLA that flags critical subtask transition points where failures most frequently occur, a VLM-based failure predictor and planner that triggers subtask backtracking upon predicted failure, and a test-time scaling strategy based on Minimum Bayes Risk (MBR) decoding to improve retry success after backtracking. Extensive experiments show that CycleVLA improves performance for both well-trained and under-trained VLAs, and that MBR serves as an effective zero-shot test-time scaling strategy for VLAs. Project Page: https://dannymcy.github.io/cyclevla/


            
### AI分析（基于论文正文）
好的，作为一名专业的AI研究分析师，我将根据您提供的论文信息和要求，生成一份结构清晰、内容详实的论文总结。

***

### **论文总结：CycleVLA**

#### **1. 论文概要**
本文提出了一种名为CycleVLA的系统，旨在为视觉-语言-动作模型（VLA）赋予**主动自校正**能力，使其能够在执行过程中预测即将发生的失败，并在失败完全显现之前进行恢复。该系统通过三个核心组件实现：1）一个经过微调的、具备子任务进度感知能力的VLA；2）一个基于视觉语言模型（VLM）的失败预测与规划器，用于在关键子任务转换点触发回溯；3）一种基于最小贝叶斯风险（MBR）解码的零样本测试时缩放策略，用于提高回溯后重试的成功率。实验表明，CycleVLA能有效提升VLA在长视野机器人任务中的成功率，尤其对训练不足的模型效果显著。

#### **2. 研究动机**
当前机器人失败检测与校正的研究大多采用**事后处理**模式，即在失败发生后才进行分析和纠正（如文献[2]-[8]）。这种模式存在根本性缺陷：一旦失败完全发生（如物体掉落、碰撞），恢复机会可能已丧失，且事后应用残差策略（文献[9]-[12]）效率低下。人类则具备**主动自校正**能力，能在错误完全发生前（如杯子滑落前）感知并调整动作。

作者观察到，机器人任务失败常发生在**子任务转换点**（文献[16]-[20]），且接近子任务完成时的进度为预测此类失败提供了强有力线索（例如，在插入卡住前就能判断销钉是否对齐）。然而，现有的通用VLA模型（如OpenVLA）缺乏显式的停止或进度估计机制（文献[19]），无法在推理时判断何时应安全地过渡到下一个子任务，或何时应干预以避免失败。因此，本文的研究动机是：**如何为VLA模型赋予类似人类的主动自校正能力，使其能够利用子任务进度信息，在失败发生前进行预测和恢复，从而超越现有的事后校正范式。**

#### **3. 核心贡献与创新点**
本文的核心贡献与创新点体现在以下三个方面，均超越了现有工作：

1.  **提出了首个集成主动自校正能力的VLA系统（CycleVLA）**：这是本文最核心的概念性创新。CycleVLA将进度感知、VLM引导的失败预测/规划与MBR测试时缩放无缝整合到一个闭环系统中（见图1和图3）。这与仅进行事后失败检测（文献[2]-[8]）或仅使用世界模型进行状态预测（文献[45]-[48]）的工作有本质区别。它使通用VLA具备了在单次执行周期内自主预测、回溯和重试的能力。

2.  **设计了一种轻量级的VLA微调流程，使其具备子任务停止与进度预测能力**：这是对现有VLA架构的关键功能拓展。具体创新在于：
    *   **扩展动作维度**：将标准的7维末端执行器动作 `at` 扩展为9维，新增了停止信号 `st` 和进度信号 `pt`（见第IV-A节，公式未编号）。这种设计无需改变模型架构，仅需加宽输出层。
    *   **基于LLM的子任务分解数据构建流程**：提出了一套自动化流程（见图2），利用大语言模型（LLM）分解任务指令，并结合机器人本体感知（夹爪状态、运动基元）来精确对齐子任务的起止时间戳，从而构建用于微调的数据集。这解决了VLA训练中缺乏标准数据增强策略的问题（第II-B节）。

3.  **首次将最小贝叶斯风险（MBR）解码作为一种零样本测试时缩放策略应用于VLA**：这是方法上的重要创新。受MBR在大型语言模型中成功应用的启发（文献[34]-[36]），本文将其适配到连续动作空间。其核心思想是：从随机策略中采样多个动作序列假设，并选择在特定距离度量下（如L2范数）**预期风险最小**的假设（即与其他假设最“一致”的那个）（见第IV-B节，公式(1)-(4)）。这与需要额外训练验证器（如RoboMonkey [32]）或奖励模型（如Rover [33]）的测试时缩放方法不同，MBR是一种无需训练、基于共识选择的零样本方法。

#### **4. 方法概述**
CycleVLA的工作流程分为训练和推理两个阶段，其核心机制设计如下：

**A. 训练阶段：构建进度感知VLA（对应图3a）**
1.  **数据准备**：对于每个示范轨迹，使用LLM（如GPT-4.1）将任务指令 `g` 分解为原子子任务序列 `(g1, ..., gK)`。同时，从机器人本体数据中提取夹爪状态段（开、关、空闲）和运动基元序列。
2.  **时间戳对齐**：若LLM提议的子任务数量与夹爪状态段数量匹配，则直接对齐；否则，使用LLM根据下采样的运动基元序列推断子任务边界（见附录B）。
3.  **模型微调**：使用构建好的子任务分解数据集，对基础VLA（如OpenVLA）进行微调。模型输出被扩展为9维动作 `at = [Δxt, Δyt, Δzt, Δut, Δvt, Δwt, γt, st, pt]⊤`。训练时，对每个子任务的最后一个动作步进行过采样，以强化终止检测。

**B. 推理阶段：主动自校正循环（对应算法1及图3b, c）**
推理过程是一个在“监控”和“完成”两个阶段间循环的自动化流程：
1.  **进度监控与失败预测**：在执行当前子任务 `gk` 时，持续监测VLA预测的进度 `pt`。当 `pt` 达到预设阈值 `τp`（如0.9）时，系统进入**关键决策点**。此时，同步的第三人称和腕部相机图像、当前子任务指令 `gk` 及整个子任务列表 `G` 被输入给一个现成的VLM（如GPT-5.2）。
2.  **VLM决策与回溯**：VLM扮演零样本失败预测器和规划器的角色，输出两种决策之一：“transit”（继续到下一子任务）或“backtrack”（回溯）。若决策为回溯，VLM还需指定应回溯到哪个子任务 `gj`（通常是能恢复缺失前提条件的最早子任务）。系统随后通过反向执行记录的动作，将机器人状态恢复到子任务 `gj` 的起始点（文献[23]）。
3.  **MBR重试**：在回溯后的起始状态，系统从VLA策略 `πθ` 中采样 `N` 个动作块假设 `A = {a(1)_t:t+H-1, ..., a(N)_t:t+H-1}`。然后，应用MBR解码选择共识动作：计算每对假设在轨迹特征空间（累积的位移和旋转）的L2距离，构建 `N×N` 距离矩阵，并选择具有最小平均成对距离的假设（公式(4)）。该动作块将被执行。
4.  **循环**：此“监控-预测-回溯-重试”循环持续进行，直到任务成功或达到最大重试次数/超时。

#### **5. 实验说明**
*   **评估指标**：主要评估指标为**任务成功率**，即在多次 rollout 中成功完成任务的比率。
*   **数据集**：在模拟环境 **LIBERO** 基准上进行评估，该基准包含四个任务套件：Spatial（空间）、Object（物体）、Goal（目标）和 **Long（长视野）**。每个套件包含10个任务。
*   **对比基线方法**：论文与多种先进方法进行了对比，包括：
    *   **非VLA方法**：Diffusion Policy [73], Octo-Base [74]。
    *   **VLA方法**：OpenVLA [13], TraceVLA [69], SpatialVLA [75], ThinkAct [70], CoT-VLA [46], FPC-VLA [71], GR00T N1 [15]。
*   **实验条件**：
    *   **训练**：使用4块 NVIDIA A100 GPU（40GB VRAM）进行模型微调。
    *   **推理/评估**：使用1块 NVIDIA A10 GPU（24GB VRAM）进行评估。VLM（GPT-5.2）通过API调用。MBR解码使用 `N=8` 个假设，距离度量为L2。

#### **6. 改进建议和未来研究方向**
基于论文内容，可提出以下改进建议和未来方向：

1.  **系统局限性及改进**：
    *   **可逆性假设**：当前回溯机制依赖于**状态可逆**的假设（通过反向执行动作）。这在高度动态或不可逆的环境（如涉及流体、变形物体或一旦触发即不可逆的机关）中可能失效。未来工作可探索基于模型的或学习式的状态恢复策略。


---

## 8. Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future

### 基本信息
- **作者**: Tianshuai Hu, Xiaolu Liu, Song Wang, Yiyao Zhu, Ao Liang, Lingdong Kong, Guoyang Zhao, Zeying Gong, Jun Cen, Zhiyu Huang, Xiaoshuai Hao, Linfeng Li, Hang Song, Xiangtai Li, Jun Ma, Shaojie Shen, Jianke Zhu, Dacheng Tao, Ziwei Liu, Junwei Liang
- **arXiv ID**: [oai:arXiv.org:2512.16760v2](https://arxiv.org/abs/2512.16760)
- **发布日期**: Tue, 06 Jan 2026 00:00:00 -0500
- **分类**: cs.RO
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2512.16760)

            ### 原文摘要
            arXiv:2512.16760v2 Announce Type: replace  Abstract: Autonomous driving has long relied on modular "Perception-Decision-Action" pipelines, where hand-crafted interfaces and rule-based components often break down in complex or long-tailed scenarios. Their cascaded design further propagates perception errors, degrading downstream planning and control. Vision-Action (VA) models address some limitations by learning direct mappings from visual inputs to actions, but they remain opaque, sensitive to distribution shifts, and lack structured reasoning or instruction-following capabilities. Recent progress in Large Language Models (LLMs) and multimodal learning has motivated the emergence of Vision-Language-Action (VLA) frameworks, which integrate perception with language-grounded decision making. By unifying visual understanding, linguistic reasoning, and actionable outputs, VLAs offer a pathway toward more interpretable, generalizable, and human-aligned driving policies. This work provides a structured characterization of the emerging VLA landscape for autonomous driving. We trace the evolution from early VA approaches to modern VLA frameworks and organize existing methods into two principal paradigms: End-to-End VLA, which integrates perception, reasoning, and planning within a single model, and Dual-System VLA, which separates slow deliberation (via VLMs) from fast, safety-critical execution (via planners). Within these paradigms, we further distinguish subclasses such as textual vs. numerical action generators and explicit vs. implicit guidance mechanisms. We also summarize representative datasets and benchmarks for evaluating VLA-based driving systems and highlight key challenges and open directions, including robustness, interpretability, and instruction fidelity. Overall, this work aims to establish a coherent foundation for advancing human-compatible autonomous driving systems.


            
### AI分析（基于论文正文）
好的，作为一名专业的AI研究分析师，我将根据您提供的论文节选内容，为您生成一份符合要求的、详实的论文总结。

***

### **论文总结：Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future**

#### **1. 论文概要**
本文是一篇关于自动驾驶领域新兴范式——视觉-语言-动作（VLA）模型的系统性综述。论文旨在为VLA研究建立一个结构化的基础，通过“过去-现在-未来”的叙事框架，梳理了从早期视觉-动作（VA）模型到现代VLA框架的演进脉络。文章提出了一个细粒度的分类法，将VLA架构划分为端到端和双系统两大范式，并进一步区分了文本与数值动作生成器、显式与隐式指导机制等子类。此外，论文还总结了用于评估VLA系统的代表性数据集与基准，并重点讨论了该领域在鲁棒性、可解释性和指令遵循等方面面临的挑战与未来研究方向。

#### **2. 研究动机**
自动驾驶系统长期以来依赖于模块化的“感知-决策-动作”流水线（如引言第1段所述）。这种设计虽然在结构化环境中表现良好，但其依赖手工设计的接口和规则，在复杂、动态和长尾场景中适应性受限（引言第1段）。更重要的是，其级联设计容易导致跨阶段错误传播，即感知噪声会被下游的推理和控制模块放大，从而损害系统的稳定性和安全性（引言第1段）。

为了缓解这些问题，研究逐渐转向端到端自动驾驶，即VA模型通过模仿学习和强化学习，直接将原始传感器输入映射到控制命令或轨迹点（引言第2段）。然而，VA模型存在根本性局限（引言第3段）：1) **“黑箱”特性**：在安全关键场景中可解释性有限；2) **泛化能力脆弱**：对训练数据中未充分代表的罕见或长尾场景适应性差；3) **缺乏结构化推理**：由于直接从感知映射到低级动作，缺乏思维链（CoT）推理和上下文深思熟虑的能力，难以解决模糊或多阶段的交互；4) **人机交互鸿沟**：专注于视觉输入，无法融入高级规划或自然语言的人类指令。

大型语言模型（LLMs）和多模态大模型（LMMs）的兴起催生了VLA新范式（引言第4段）。VLA模型将视觉语言模型（VLM）主干与动作预测头相结合，实现了从多模态输入（视觉+语言）到可执行驾驶动作的直接映射。通过联合建模感知、语言理解和决策，VLA框架有望提供类人推理、可解释性和指令遵循能力。鉴于该领域的快速发展，有必要整合其概念基础、厘清架构趋势，并对新兴方向进行结构化分析（引言第5段）。本文的动机正是为了满足这一需求，提供一个针对自动驾驶领域的、具有历史深度和结构化架构分析的全面综述。

#### **3. 核心贡献与创新点**
本文的核心贡献并非提出新的算法或模型，而是在于对自动驾驶VLA领域进行了一次系统性的**概念梳理、分类归纳和路线图绘制**。其创新点主要体现在以下三个方面：

1.  **领域聚焦与历史连续性分析**：与涵盖机器人或具身智能的更广泛分析不同（见“Scope”部分第1点），本文**专门聚焦于自动驾驶领域**，允许对驾驶特有的挑战、数据集特征和安全要求进行细粒度分析。同时，论文采用了“过去-现在-未来”的叙事框架（见“Scope”部分第2点），清晰地追溯了从早期VA模型到现代VLA框架的技术演进路径，强调了将语言基础融入感知与控制背后的动机和技术谱系。

2.  **细粒度的VLA架构分类法**：本文提出了一个**层次化的VLA架构分类法**（见“Scope”部分第3点及图1、图2），这是其核心的组织性创新。该分类法首先将VLA架构划分为两大主要范式：
    *   **端到端VLA**（第4.1节）：将感知、推理和规划集成在单一模型中，VLM直接生成动作（见第2.2.1节）。
    *   **双系统VLA**（第4.2节）：将慢速深思（通过VLM）与快速、安全关键的执行（通过规划器）分离，VLM作为高级推理模块产生中间指导（见第2.2.2节）。
    在此之上，论文进一步根据动作头的输出形式（第2.3节）细分为：**语言头（LH）**、**回归（REG）**、**轨迹选择（SEL）** 和**轨迹生成（GEN）**。这种分类超越了以往的高层概述，为理解和比较不同VLA方法如何组织感知、推理和控制提供了清晰的框架。

3.  **对VA模型演进的系统性回顾与整合**：论文并未孤立地讨论VLA，而是将其置于更广阔的技术演进背景中。**第3章系统性地回顾了作为VLA前身的VA模型**，并将其分为端到端模型和世界模型两大类。其中，端到端模型又细分为仅动作模型和感知-动作模型（见图3及第3.1节）；世界模型则按预测模态细分为基于图像、基于占据栅格和基于潜在表示的模型（见图4及第3.2节）。这种整合性的回顾，使得读者能够理解VLA范式解决VA模型哪些固有缺陷，从而更深刻地把握其创新价值。

#### **4. 方法概述**
本文作为一篇综述，并未提出单一的具体方法，而是对VLA模型的一般性框架和组件进行了形式化定义和详细拆解（第2章）。其“方法概述”体现在对VLA系统核心构成的解析上。

一个典型的VLA框架可以形式化为公式(1)：`a_t = H(F(x|θ))`。其中，`x` 表示时间戳 `t` 的多模态输入，`F(·)` 是参数为 `θ` 的VLM主干，`H(·)` 是动作生成头。论文详细阐述了这三个核心组件：

*   **输入模态（x）**（第2.1节）：包括四类：
    1.  **传感器输入**：原始或预处理的多视角RGB图像 `x_img` 和LiDAR点云 `x_lidar`。
    2.  **潜在场景表示**：中间空间表示，如鸟瞰图特征 `x_bev` 和3D占据栅格 `x_occ`。
    3.  **语言输入**：高级文本指令或任务描述 `x_lang`。
    4.  **车辆状态信息**：描述自车动态状态（速度、加速度等）的专有信息 `x_state`。

*   **VLM主干（F）**（第2.2节）：作为系统的核心推理引擎，通常是一个大型视觉语言模型。它由一个视觉编码器（如ViT）、一个LLM解码器以及一个用于对齐视觉特征与语言嵌入的桥接网络或统一多模态令牌建模机制组成。根据其在架构中的角色，可分为：
    *   **用于直接动作生成的VLM（单系统）**：VLM通过其语言头或附加的小型头部直接发出动作，实现完全端到端的设计。
    *   **用于指导生成的VLM（双系统）**：VLM作为高级推理模块，产生中间指导（如文本原理或结构化潜在意图），再由下游规划器转换为低级动作。这是一种“慢思考+快执行”的架构。

*   **动作预测头（H）**（第2.3节）：负责将VLM的潜在表示转换为动作输出。论文根据输出形式和生成机制将其分为四类：
    1.  **语言头（LH）**：直接利用VLM固有的文本生成能力，在语言空间中产生动作（如“左转”或离散化的动作令牌序列）。
    2.  **回归（REG）**：使用解码器结构后接回归器（如MLP），直接预测转向角、油门/刹车值或轨迹点等连续数值。
    3.  **轨迹选择（SEL）**：评估一组候选轨迹，并基于学习的成本函数或评分机制选择最优轨迹。
    4.  **轨迹生成（GEN）**：通过概率建模（如扩散模型或变分自编码器）合成动作，能够捕捉未来分布的多模态性和不确定性。

此外，论文还定义了自动驾驶中的动作空间表示（第2.4节），包括离散轨迹表示（公式(2)）、连续轨迹表示（公式(3)）、直接控制表示（公式(4)）和语言表示（公式(5)），为理解不同VLA方法的输出提供了基础。

#### **5. 实验说明**
由于本文是一篇综述性论文，并未进行具体的模型训练和对比实验。因此，不存在传统意义上的实验设置、基线对比或硬件配置说明。

*   **评估指标与数据集**：论文在第5章（“Datasets and Benchmarks”）中系统性地总结了用于评估VLA驱动系统的数据集和基准。这些被分为**开环评估**（如nuScenes, nuPlan, Bench2Drive, NAVSIM）和**闭环评估**（如CARLA, MetaDrive, LGSVL, AD-Meta）两大类。论文详细列举了这些数据集的模态（相机、LiDAR、语言指令等）、场景类型和主要评估任务，为读者提供了全面的评估资源概览

---

## 9. SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling

### 基本信息
- **作者**: Yufan He, Pengfei Guo, Mengya Xu, Zhaoshuo Li, Andriy Myronenko, Dillan Imans, Bingjie Liu, Dongren Yang, Mingxue Gu, Yongnan Ji, Yueming Jin, Ren Zhao, Baiyong Shen, Daguang Xu
- **arXiv ID**: [oai:arXiv.org:2512.23162v3](https://arxiv.org/abs/2512.23162)
- **发布日期**: Tue, 06 Jan 2026 00:00:00 -0500
- **分类**: cs.RO, cs.CV
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2512.23162)

            ### 原文摘要
            arXiv:2512.23162v3 Announce Type: replace  Abstract: Data scarcity remains a fundamental barrier to achieving fully autonomous surgical robots. While large scale vision language action (VLA) models have shown impressive generalization in household and industrial manipulation by leveraging paired video action data from diverse domains, surgical robotics suffers from the paucity of datasets that include both visual observations and accurate robot kinematics. In contrast, vast corpora of surgical videos exist, but they lack corresponding action labels, preventing direct application of imitation learning or VLA training. In this work, we aim to alleviate this problem by learning policy models from SurgWorld, a world model designed for surgical physical AI. We curated the Surgical Action Text Alignment (SATA) dataset with detailed action description specifically for surgical robots. Then we built SurgeWorld based on the most advanced physical AI world model and SATA. It's able to generate diverse, generalizable and realistic surgery videos. We are also the first to use an inverse dynamics model to infer pseudokinematics from synthetic surgical videos, producing synthetic paired video action data. We demonstrate that a surgical VLA policy trained with these augmented data significantly outperforms models trained only on real demonstrations on a real surgical robot platform. Our approach offers a scalable path toward autonomous surgical skill acquisition by leveraging the abundance of unlabeled surgical video and generative world modeling, thus opening the door to generalizable and data efficient surgical robot policies.


            
### AI分析（基于论文正文）
好的，作为一名资深论文总结者，我将根据您提供的论文《SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling》全文，生成一份符合要求的详细总结。

***

### **论文总结：SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling**

#### **1. 论文概要**
本文旨在解决手术机器人领域因数据稀缺而难以训练自主策略的核心瓶颈。现有的大量手术视频缺乏同步的机器人动作标签，无法直接用于模仿学习或视觉-语言-动作（VLA）模型训练。为此，作者提出了SurgWorld框架，通过构建一个手术世界模型来生成逼真的合成手术视频，并首次结合逆动力学模型从这些视频中推断伪动作标签，从而合成配对的视频-动作数据。实验表明，使用这些增强数据训练的VLA策略，在真实手术机器人平台上执行“针拾取与交接”任务时，其轨迹预测误差显著低于仅使用真实演示数据训练的模型。该方法为利用海量无标签手术视频实现可扩展的自主手术技能学习开辟了新路径。

#### **2. 研究动机**
手术机器人自动化面临的根本挑战是数据稀缺（第1节）。具体而言，训练鲁棒的VLA模型或模仿学习策略需要大规模、多样化的配对数据集，其中包含高保真视觉观察（如内窥镜视频）和同步的机器人运动学或控制指令。然而，在手术领域收集此类数据成本极高，受到手术室准入、患者安全和法规限制的严重制约（第1节）。尽管存在大量手术视频，但它们缺乏对应的动作标签，无法直接用于策略学习。

现有工作试图弥合这一差距，但各有局限。基于物理的合成仿真器（如Surgical Gym, Surrol）存在显著的视觉和动力学领域偏移，且缺乏软组织模拟，限制了策略迁移（第1节）。近期在手术世界模型和视频生成方面的研究（如GAS, SurgWM, Suturing World Model）虽取得进展，但大多局限于单一任务或视觉预测，缺乏与文本对齐和显式运动学生成的整合（第1节）。同时，在通用机器人领域，已有工作（如DreamGen）探索了基于世界模型和逆动力学的合成数据生成，但其模型并未针对手术领域独特的视觉复杂性（如组织镜面反射、内窥镜遮挡、受限工具运动）进行优化（第1节）。

因此，本文的研究动机是：**如何利用海量无标签手术视频，通过生成式世界建模技术，为手术机器人策略学习创造可扩展的、高质量的合成数据源，从而克服真实配对数据稀缺的瓶颈**。论文明确指出，这是首个将大规模文本对齐的手术视频建模与用于具身策略学习的伪运动学生成相结合的工作（第1节）。

#### **3. 核心贡献与创新点**
本文的核心贡献与创新点具体如下：

1.  **构建了面向物理AI的手术动作-文本对齐（SATA）数据集**：这是首个为支持物理AI模型开发而设计的大规模手术视频-文本语料库（第2节）。它包含2,447个专家标注的视频片段（超过30万帧），覆盖8种手术类型中的4个核心动作（针抓取、针穿刺、缝线牵拉、打结）（第3.1节）。其创新性在于标注的细粒度：每个片段都配有详细文本描述，精确捕捉工具-组织交互和空间关系（例如，“左针持穿刺患者背侧静脉丛的右侧”），这与现有侧重于语义推理的手术VLM数据集（如SurgVLM-DB）有本质区别（第3.1节）。该数据集为训练能够理解手术物理交互的世界模型提供了关键基础。

2.  **开发了首个基于先进物理AI世界模型的手术世界模型（SurgWorld）**：本文创新性地将最先进的通用视频世界模型Cosmos-Predict2.5适配到手术领域（第3.2节）。其创新点在于采用**参数高效的微调策略**：通过插入LoRA（Low-Rank Adaptation）模块到Transformer的注意力层和前馈层，在保留模型通用视频建模能力的同时，高效地使其适应手术领域独特的视觉动态（如内窥镜视野下的器械运动、组织交互）（第3.2节）。该模型在SATA数据集上微调后，展现出强大的文本-视频对齐能力、高视频质量和逼真的动力学特性，能够根据文本提示生成多样化且符合解剖学 plausible 的手术行为序列（见图5）。

3.  **首次将手术世界模型与机器人学习连接，通过逆动力学模型合成视频-动作数据**：这是本文最核心的方法论创新（第1、3节）。具体流程是：首先用SurgWorld生成合成手术视频，然后训练一个针对特定手术机器人 embodiment 的逆动力学模型，该模型能够根据视频中连续两帧（间隔T=16帧）推断出其间每一帧对应的机器人伪动作（第3.3节，图3）。这一创新点**首次实现了从纯粹的无标签手术视频到可用于VLA策略训练的配对视频-动作数据的完整闭环**。它区别于之前仅生成视频或仅预测轨迹的工作，明确地为生成的内容赋予了可执行的机器人控制信号。

4.  **实证验证了合成数据对提升手术机器人策略性能的有效性**：通过系统的机器人策略实验（第4.2节），论文证明，在使用少量（5，10，20条）真实轨迹微调VLA策略（GR00T N1.5）的基础上，**引入由SurgWorld和IDM生成的合成数据（56条或560条）进行预训练，能够显著降低策略在40条测试轨迹上的动作预测均方误差（MSE）**（见图8）。这一贡献不仅验证了框架的有效性，也为数据高效的手术机器人学习提供了可复现的范例。

#### **4. 方法概述**
SurgWorld框架的整体工作流程分为四个步骤（见图2）：

**步骤1：在SATA数据集上训练SurgWorld。** 以Cosmos-Predict2.5为基础模型，这是一个基于扩散的潜在视频预测模型，使用Transformer主干进行高保真时空动态模拟（第3.2节）。采用**流匹配（Flow Matching）** 公式进行训练（第3.2节）。关键操作是使用**LoRA**对模型进行参数高效的领域自适应。给定初始帧 \(I_0\)，世界模型预测未来帧序列 \(\hat{I}_{1:T} = \mathcal{W}_{\theta}(I_0)\)，其中 \(\mathcal{W}_{\theta}\) 代表注入LoRA适配器后的Cosmos-Predict2.5模型（第3.2节）。

**步骤2：在下游数据上微调SurgWorld并训练逆动力学模型（IDM）。** 针对特定的下游任务（如特定机器人的针拾取交接），使用少量（5，10，20条）该任务的真实机器人演示视频对SurgWorld进行进一步微调，使其适应具体的机器人 embodiment 和场景。同时，为同一机器人训练一个IDM。IDM架构基于DreamGen的设计（第3.3节），与VLA策略模型（GR00T N1.5）共享相似的扩散Transformer（DIT）和流匹配头，但输入不同：IDM的输入是同一视频中相隔T帧的两帧图像，输出是这两帧之间每一帧对应的机器人动作（第3.3节，图3）。动作空间定义为20维连续向量，包含左右器械末端执行器相对于内窥镜坐标系的3D平移偏移、6D旋转表示和钳口开合角度（第3.1节）。

**步骤3：生成合成视频和伪运动学。** 使用微调后的SurgWorld，以任务相关的初始帧和文本提示为条件，生成合成视频序列。随后，使用训练好的IDM对这些合成视频进行分析，为每一帧推断出对应的伪机器人动作（\(a_t\)），从而得到合成的配对（视频，动作）数据集。

**步骤4：使用真实和合成数据训练VLA策略。** 采用GR00T N1.5作为基础VLA策略模型。训练分两阶段：首先，使用大量合成数据（56或560条视频-动作对）对预训练的GR00T模型进行预训练（400步）；然后，再用少量真实任务数据（5，10，20条）进行微调（200步）。策略模型的输入是当前帧、文本提示和机器人状态，输出是未来16帧的动作序列（第3.3节，图3）。通过比较“仅用真实数据”和“真实+合成数据”两种训练方式下策略的测试性能，验证合成数据的有效性。

#### **5. 实验说明**
- **评估指标**：
    - **世界模型评估**：Fréchet视频距离（FVD）、VBench指标（动态程度DD、成像质量IQ、整体一致性OC）、任务成功率（SR）、人类专家评分（文本-视频对齐、工具一致性、解剖结构，1-3分制）（第4.1节）。
    - **策略评估**：动作预测的均方误差（MSE），按笛卡尔坐标、旋转和钳口开合维度分别计算（第4.2节，图8）。

- **数据集**：
    1.  **SATA数据集**：自建数据集，2,447个片段，300k+帧，涵盖8种手术的4个核心动作，来自YouTube及多个公开数据集（GraSP, SAR-RARP50等）（第3.

---

## 10. Dream-VL & Dream-VLA: Open Vision-Language and Vision-Language-Action Models with Diffusion Language Model Backbone

### 基本信息
- **作者**: Jiacheng Ye, Shansan Gong, Jiahui Gao, Junming Fan, Shuang Wu, Wei Bi, Haoli Bai, Lifeng Shang, Lingpeng Kong
- **arXiv ID**: [oai:arXiv.org:2512.22615v2](https://arxiv.org/abs/2512.22615)
- **发布日期**: Tue, 06 Jan 2026 00:00:00 -0500
- **分类**: cs.CV, cs.CL
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2512.22615)

            ### 原文摘要
            arXiv:2512.22615v2 Announce Type: replace  Abstract: While autoregressive Large Vision-Language Models (VLMs) have achieved remarkable success, their sequential generation often limits their efficacy in complex visual planning and dynamic robotic control. In this work, we investigate the potential of constructing Vision-Language Models upon diffusion-based large language models (dLLMs) to overcome these limitations. We introduce Dream-VL, an open diffusion-based VLM (dVLM) that achieves state-of-the-art performance among previous dVLMs. Dream-VL is comparable to top-tier AR-based VLMs trained on open data on various benchmarks but exhibits superior potential when applied to visual planning tasks. Building upon Dream-VL, we introduce Dream-VLA, a dLLM-based Vision-Language-Action model (dVLA) developed through continuous pre-training on open robotic datasets. We demonstrate that the natively bidirectional nature of this diffusion backbone serves as a superior foundation for VLA tasks, inherently suited for action chunking and parallel generation, leading to significantly faster convergence in downstream fine-tuning. Dream-VLA achieves top-tier performance of 97.2% average success rate on LIBERO, 71.4% overall average on SimplerEnv-Bridge, and 60.5% overall average on SimplerEnv-Fractal, surpassing leading models such as $\pi_0$ and GR00T-N1. We also validate that dVLMs surpass AR baselines on downstream tasks across different training objectives. We release both Dream-VL and Dream-VLA to facilitate further research in the community.


            
### AI分析（基于论文正文）
好的，作为一名熟悉顶级机器学习/人工智能会议风格的资深论文总结者，我将根据您提供的论文节选内容，为您生成一份结构清晰、内容详实的论文总结。

***

### **论文概要**

本文旨在探索基于扩散的大语言模型作为视觉-语言与视觉-语言-动作模型主干架构的潜力，以克服自回归模型在复杂视觉规划和动态机器人控制中的局限性。论文提出了Dream-VL，一个在开放数据上训练、性能达到当前扩散视觉-语言模型最佳水平的模型。在此基础上，通过大规模机器人数据持续预训练，构建了Dream-VLA，这是首个基于扩散主干进行预训练的视觉-语言-动作模型。实验表明，Dream-VL在视觉规划任务上优于自回归基线，而Dream-VLA在多个机器人操作基准测试中达到了顶尖性能，并展现出更快的下游任务收敛速度。

### **研究动机**

当前，视觉-语言模型及其在具身智能领域的延伸——视觉-语言-动作模型，主要依赖于自回归大语言模型作为其主干（见第1节引言）。然而，这种架构选择存在根本性瓶颈。首先，自回归范式基于下一个词元预测进行训练，在处理需要长程规划和全局推理的任务时存在困难（Bachmann and Nagarajan, 2024; Ye et al., 2025a）。其次，其顺序生成特性在推理过程中容易导致错误累积，进一步阻碍了全局推理能力（Zhang et al., 2023a; Rohatgi et al., 2025）。这些限制在需要多步视觉规划和连贯动作序列生成的复杂应用（如科学实验步骤分析、手术机器人操作、家庭机器人任务执行）中尤为突出。

与此同时，扩散大语言模型展现出了解决这些挑战的潜力（Inception Labs, 2025; Nie et al., 2025）。与自回归模型不同，扩散模型通过迭代去噪过程学习将噪声序列细化为连贯输出，这一过程天然鼓励全局一致性，使其特别适合长程依赖和面向目标的规划任务（Ye et al., 2025c）。此外，扩散语言模型的并行解码能力在推理时提供了计算优势（DeepMind, 2025; Wang et al., 2025b）。

基于此，论文的核心研究动机是：**探究扩散语言模型在视觉-语言任务中的优势是否能够延续，特别是在那些规划和连贯推理至关重要的场景中**（见第1节末尾）。作者旨在系统性地验证，将视觉模态与扩散语言主干结合，能否构建出在通用视觉理解、尤其是视觉规划任务上超越或媲美自回归模型的系统，并进一步将其扩展为高效的机器人策略模型。

### **核心贡献与创新点**

本文的核心贡献与创新点主要体现在以下三个方面：

1.  **首个基于扩散主干进行大规模开放数据预训练的先进视觉-语言模型（Dream-VL）**：论文并非简单地将视觉编码器与现有扩散模型拼接，而是采用了一个精心设计的三阶段训练范式（见第3.1节，表1）。该范式从少量高质量数据（LCS）的投影器对齐开始，到大规模单图像数据（SI）的全参数训练，再到多图像/视频数据的进一步微调。这种渐进式训练策略确保了视觉与语言模态的有效对齐。Dream-VL在多项视觉理解基准测试（如MMMU、DocVQA、ChartQA）上达到了与顶级开放数据自回归VLM（如MAmmoTH-VL）相当的性能，并显著超越了所有先前的扩散VLM（如LLaDA-V、Dimple）（见第3.2节，表2-4）。这证明了扩散主干在通用视觉理解任务上具备竞争力。

2.  **首次系统论证并验证了扩散VLM在视觉规划任务上的固有优势**：论文通过可控实验，深入分析了Dream-VL在两类规划任务上的表现。**在高层次符号规划（ViPlan基准）** 中，在与训练数据和流程相似的自回归基线（MAmmoTH-VL-7B）对比时，Dream-VL在大多数场景下取得了更高的准确率（见第3.3.1节，图4），这归因于其从基础Dream模型继承的文本规划能力。**在低层次连续动作规划（LIBERO基准）** 中，Dream-VL在未经机器人预训练的情况下，仅通过指令微调，其成功率（LIBERO-Long: 59.0%）就大幅超过了强大的自回归VLM基线（Qwen2.5-VL: 34.0%），甚至超过了经过机器人预训练的OpenVLA（见第3.3.2节，表5）。关键发现是，Dream-VL能够利用更大的动作块（chunk size）进行并行生成而不会像自回归模型那样因错误累积导致性能下降，且仅需一个扩散步即可达到良好性能，实现高达27倍的推理加速（见第3.3.2节，图5）。

3.  **提出并发布了首个基于扩散主干进行大规模机器人预训练的通用视觉-语言-动作模型（Dream-VLA）**：这是本文最具突破性的贡献。Dream-VLA并非简单的任务特定微调，而是在Dream-VL基础上，使用Open-X Embodiment数据集中的97万条机器人轨迹进行持续预训练得到的通用策略模型（见第4.1节）。其创新性在于：**a）架构统一**：无需像π0或GR00T等模型那样引入独立的自回归“动作专家”模块（见第4.1节，图6），利用扩散主干天然的**双向注意力**机制和**并行解码**能力统一处理语言、视觉和连续动作。**b）训练目标灵活**：下游微调时，可兼容多种损失函数（如L1回归、连续扩散、流匹配），而无需改变模型架构（见第4.1节）。实验证明，Dream-VLA在LIBERO（平均成功率97.2%）、SimplerEnv–Bridge（71.4%）和SimplerEnv–Fractal（60.5%）等基准上均达到了顶尖水平，超越了π0和GR00T-N1等领先模型（见第4.2节，表6），并展现出比自回归基线（OpenVLA-OFT）更快的收敛速度。

### **方法概述**

本文的方法核心是构建一个以扩散大语言模型（具体为Dream-7B）为统一主干的多模态模型家族。其技术方案围绕视觉对齐、训练目标和机器人动作建模展开。

**1. Dream-VL的构建（第3.1节）：**
   - **视觉编码与输入表示**：采用Qwen2ViT作为视觉编码器，将输入图像编码为一系列视觉特征。这些特征通过一个可训练的投影层（Stage-1训练25.7M参数）映射到与文本词嵌入相同的维度，然后与文本词嵌入在序列维度上进行拼接，形成多模态输入序列。
   - **训练目标与流程**：模型沿用Dream-7B的**离散扩散损失**进行训练。训练分为三个阶段：
     - **Stage-1（对齐阶段）**：使用55.8万高质量样本，仅训练投影器参数，冻结视觉编码器和LLM主干，实现视觉到语言空间的初步对齐。
     - **Stage-2（主训练阶段）**：使用1000万单图像样本，解冻并训练全部模型参数（共8.3B），进行大规模多模态指令微调。
     - **Stage-3（多图像/视频增强阶段）**：使用200万多图像和视频样本进行进一步微调，提升复杂场景理解能力。

**2. Dream-VLA的构建（第4.1节）：**
   - **机器人动作表示**：对于连续机器人动作（如7维末端执行器位姿变化），采用与RT-2类似的方法，将每个维度离散化为256个区间，转化为离散词元。这些动作词元与视觉、文本词元以相同的方式拼接输入模型。
   - **持续预训练**：在预训练好的Dream-VL基础上，使用Open-X Embodiment的97万条机器人演示轨迹进行持续预训练。训练时采用与主干相同的离散扩散损失，**动作块大小**设置为8，即模型一次接收并预测未来8个时间步的动作序列。这利用了扩散模型并行生成序列的能力。
   - **灵活的下游微调**：得益于扩散主干的通用性，在下游任务微调时，作者展示了其可适配不同训练目标的灵活性。在主要实验中，他们采用了**流匹配损失**（类似于π0），直接对连续动作空间进行建模，从而避免离散化带来的量化误差，实现更精细的控制。微调时使用LoRA技术，高效适配新任务。

**3. 核心机制结合创新点**：
   - **双向注意力与信息融合**：扩散主干（如Dream）在去噪过程中使用全注意力，使得视觉特征、历史文本、未来动作词元之间能进行充分的双向交互，这被认为是其规划能力优于因果注意力自回归模型的关键。
   - **并行生成与动作分块**：模型在训练时即以固定的动作块（如8个时间步）为单位进行学习，在推理时可一次性并行生成整个动作块。这与自回归模型必须逐词生成形成对比，不仅加速推理，也减少了长序列生成中的错误传播。
   - **从噪声到规划的映射**：扩散训练目标要求模型从随机噪声中迭代恢复出合理的多模态序列（文本+动作）。这一过程迫使

---


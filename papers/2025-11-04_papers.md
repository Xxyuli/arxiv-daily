# arXiv论文监控报告 - 2025年11月04日

> 本报告由arXiv论文监控Agent自动生成

## 报告概览

- **监控日期**: 2025年11月04日
- **监控分类**: cs.AI, cs.LG, cs.RO, cs.CV
- **关键词**: Vision Language Action , vla, Vision-Language-Action, Multivariate Time Series Forecasting, spatio-temporal prediction, traffic prediction
- **发现论文数**: 2篇

---

## 1. EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities

### 基本信息
- **作者**: Travis Davies, Yiqi Huang, Alexi Gladstone, Yunxin Liu, Xiang Chen, Heng Ji, Huxian Liu, Luhui Hu
- **arXiv ID**: [oai:arXiv.org:2510.27545v1](https://arxiv.org/abs/2510.27545)
- **发布日期**: Mon, 03 Nov 2025 00:00:00 -0500
- **分类**: cs.RO, cs.AI
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2510.27545)

            ### 原文摘要
            arXiv:2510.27545v1 Announce Type: cross  Abstract: Implicit policies parameterized by generative models, such as Diffusion Policy, have become the standard for policy learning and Vision-Language-Action (VLA) models in robotics. However, these approaches often suffer from high computational cost, exposure bias, and unstable inference dynamics, which lead to divergence under distribution shifts. Energy-Based Models (EBMs) address these issues by learning energy landscapes end-to-end and modeling equilibrium dynamics, offering improved robustness and reduced exposure bias. Yet, policies parameterized by EBMs have historically struggled to scale effectively. Recent work on Energy-Based Transformers (EBTs) demonstrates the scalability of EBMs to high-dimensional spaces, but their potential for solving core challenges in physically embodied models remains underexplored. We introduce a new energy-based architecture, EBT-Policy, that solves core issues in robotic and real-world settings. Across simulated and real-world tasks, EBT-Policy consistently outperforms diffusion-based policies, while requiring less training and inference computation. Remarkably, on some tasks it converges within just two inference steps, a 50x reduction compared to Diffusion Policy's 100. Moreover, EBT-Policy exhibits emergent capabilities not seen in prior models, such as zero-shot recovery from failed action sequences using only behavior cloning and without explicit retry training. By leveraging its scalar energy for uncertainty-aware inference and dynamic compute allocation, EBT-Policy offers a promising path toward robust, generalizable robot behavior under distribution shifts.


            
### AI分析（基于论文正文）
以下是针对论文《EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities》的详细总结，严格遵循指定的六个标题结构：

---

**1. 论文概要**  
本文提出了一种基于能量变换器（Energy-Based Transformer, EBT）的机器人策略模型EBT-Policy，用于解决扩散策略（Diffusion Policy）在机器人控制中面临的高计算成本、暴露偏差和不稳定推理动态等问题。EBT-Policy通过端到端学习能量景观，建模平衡动态，实现了更高的鲁棒性和更低的暴露偏差。在模拟和真实世界任务中，EBT-Policy在训练和推理效率上均优于扩散策略，并在仅使用行为克隆的情况下，展现出零样本恢复失败动作序列等涌现能力。

---

**2. 研究动机**  
当前，基于生成模型（如扩散策略）的隐式策略已成为机器人策略学习和视觉-语言-动作模型的标准方法。然而，这些方法存在以下不足：  
- **高计算成本与推理效率低**：扩散策略依赖外部定义的噪声调度器，导致需要大量去噪步骤（如100步）才能完成推理，计算负担重（见第1节及参考文献[5, 32, 43, 57]）。  
- **暴露偏差与误差累积**：扩散策略的链式生成过程在训练与推理阶段存在差异，早期阶段的误差会在后续步骤中传播和放大，导致在分布偏移下性能下降（见第1节及参考文献[29, 31, 40]）。  
- **能量模型的可扩展性问题**：尽管能量模型理论上能通过平衡动态减少误差累积，但传统能量策略在可扩展性和训练稳定性上面临挑战（见第1节及参考文献[11, 12]）。  
基于能量变换器（EBT）的最新进展[18]证明了能量模型在高维空间中的可扩展性，但其在物理实体模型中的潜力尚未充分探索。因此，本文旨在利用EBT构建一种新型策略模型，以解决上述问题。

---

**3. 核心贡献与创新点**  
本文的核心贡献与创新点包括：  
- **新型能量架构EBT-Policy**：提出了一种基于EBT的隐式策略模型，通过端到端学习能量景观，替代扩散策略中的噪声调度和去噪过程（见第3.1节及图1）。该模型直接学习能量函数 \(E_\theta(\ell, o_t, a)\)，其负梯度等价于扩散策略中的得分函数 \(\nabla_a \log p(a | \ell, o_t)\)（见第3.3节及公式推导）。  
- **动态推理与不确定性建模**：EBT-Policy通过能量标量实现不确定性感知推理，动态分配计算资源。推理步骤数根据能量梯度范数自适应调整，困难状态获得更多梯度步骤，简单状态则快速收敛（见第3.4节及算法2）。  
- **涌现物理推理能力**：在未接受显式重试训练的情况下，EBT-Policy展现出零样本恢复失败动作序列的涌现能力（见第6节及图6）。该能力归因于能量函数的平衡动态，使模型能在分布外状态下重新规划动作。  
- **训练稳定性与多模态探索机制**：引入随机化MCMC步数、缩放朗之万动力学、步长随机化、Nesterov加速梯度等技术，增强对多模态动作分布的探索（见第3.6.1节及公式(1)）。同时，通过能量缩放步长、预采样归一化和梯度裁剪等技术提升训练稳定性（见第3.6.2节及公式(2)）。  
与现有工作相比，EBT-Policy在可扩展性、推理效率和鲁棒性上显著优于传统能量策略，并在不确定性建模和涌现能力上超越了扩散策略。

---

**4. 方法概述**  
EBT-Policy的技术方案基于能量变换器（EBT），其核心是通过能量最小化过程生成动作轨迹。具体流程如下：  
- **能量函数定义**：模型学习一个能量函数 \(E_\theta(\ell, o_t, a)\)，其中 \(\ell\) 为语言指令，\(o_t\) 为多模态观测（包括RGB图像和本体感知状态），\(a\) 为动作序列。能量函数通过Transformer架构实现，输出标量能量值（见第3.1节）。  
- **训练过程**：采用正则化损失训练EBM，避免传统对比损失的不稳定性。训练时，目标轨迹初始化为噪声，通过随机化MCMC步骤进行迭代优化。每一步中，轨迹经过归一化（RMSNorm）并注入朗之万动力学噪声，噪声标准差按余弦调度从 \(\sigma_{\text{max}}\) 衰减至 \(\sigma_{\text{min}}\)（公式(1)）。损失函数为均方误差（MSE），比较去噪轨迹与真实演示（见算法1）。  
- **推理过程**：推理时，从噪声初始化动作轨迹，通过梯度下降迭代更新：  
  \[
  \hat{y}_{i+1} = \hat{y}_i - \alpha_i \nabla_{\hat{y}} E_\theta(z, \hat{y}_i)
  \]
  其中步长 \(\alpha_i\) 根据能量值缩放（公式(2)）。推理动态终止，当能量梯度范数低于阈值 \(\tau\) 或达到最大步数 \(N\)（见算法2）。  
- **稳定性与多模态增强**：  
  - **步长随机化**：初始步长采样自 \(\eta \sim \mathcal{N}(\eta_b/c, \eta_b \cdot c)\)，促进多样采样轨迹。  
  - **Nesterov加速**：帮助逃离局部极小值。  
  - **梯度裁剪**：限制全局梯度范数不超过1.0，防止梯度爆炸。  
这些机制共同确保了EBT-Policy在高效推理的同时，保持对多模态动作分布的覆盖和训练稳定性。

---

**5. 实验说明**  
- **评估指标**：任务成功率（%），基于模拟和真实世界任务的回合测试。  
- **数据集**：  
  - 模拟任务：robomimic基准套件[38]，包括Lift、Can、Square和Tool Hang四个任务（图4）。  
  - 真实任务：自定义双臂机器人任务，包括Fold Towel、Place Pan和Pick And Place（图3）。  
- **对比基线方法**：  
  - **扩散策略（Diffusion Policy, DP）**[5]：作为主要基线，包括10步和100步推理变体。  
  - **EBT-Policy变体**：  
    - EBT-Policy-S（约30M参数）：用于模拟任务，与DP架构一致。  
    - EBT-Policy-R（约100M参数）：用于真实任务，集成T5-S语言编码器和DINOv3-S视觉编码器（表2）。  
- **实验条件**：  
  - 模拟实验使用robomimic环境，每任务测试50回合。  
  - 真实实验使用双臂机器人平台，配备4个RGB相机。  
  - 训练使用相同数据集，超参数见表1（如基步长 \(\eta_b = 1000\)，最大MCMC推理步数20）。  
  - GPU配置：论文中未明确说明训练和推理的具体GPU数量和型号。

---

**6. 改进建议和未来研究方向**  
- **已提及的局限性**：  
  - **训练稳定性与多模态采样**：EBT-Policy在高度多模态动作分布下的采样仍不如扩散策略稳定（见第6节）。  
  - **超参数敏感性**：模拟任务中的成功率略低于原扩散策略报告结果，可能源于超参数差异（见第6节）。  
- **未提及的潜在局限性**：  
  - **可扩展性限制**：当前EBT-Policy最大参数量为100M，对于更复杂任务（如长时程规划）可能需进一步扩展模型规模。  
  - **能量景观优化**：能量函数可能陷入非理想局部极小，影响在动态环境中的适应性。  
- **改进建议**：  
  - **优化稳定性与模式覆盖**：结合更先进的MCMC采样技术（如哈密顿蒙特卡洛）或混合能量模型，以提升多模态探索能力。  
  - **自适应超参数调度**：引入元学习或强化学习动态调整超参数（如步长和噪声调度），减少人工调优需求。  
- **未来研究方向**：  
  - **跨领域知识融合**：将EBT-Policy与符号推理或物理引擎结合，增强在复杂物理场景中的推理能力（如结合[13, 15]中的能量最小化推理框架）。  
  - **大规模预训练与迁移**：在更大规模、多任务数据集上预训练EBT-Policy，验证其作为通用机器人策略基座的潜力。  
  - **实时推理优化**：研究模型压缩或蒸馏技术，进一步降低推理延迟，满足实时控制需求。

---

---

## 2. Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model

### 基本信息
- **作者**: John Won, Kyungmin Lee, Huiwon Jang, Dongyoung Kim, Jinwoo Shin
- **arXiv ID**: [oai:arXiv.org:2510.27607v1](https://arxiv.org/abs/2510.27607)
- **发布日期**: Mon, 03 Nov 2025 00:00:00 -0500
- **分类**: cs.CV, cs.RO
- **论文链接**: [arXiv链接](https://arxiv.org/abs/2510.27607)

            ### 原文摘要
            arXiv:2510.27607v1 Announce Type: cross  Abstract: Recently, augmenting Vision-Language-Action models (VLAs) with world modeling has shown promise in improving robotic policy learning. However, it remains challenging to jointly predict next-state observations and action sequences because of the inherent difference between the two modalities. To address this, we propose DUal-STream diffusion (DUST), a world-model augmented VLA framework that handles the modality conflict and enhances the performance of VLAs across diverse tasks. Specifically, we propose a multimodal diffusion transformer architecture that explicitly maintains separate modality streams while still enabling cross-modal knowledge sharing. In addition, we introduce independent noise perturbations for each modality and a decoupled flow-matching loss. This design enables the model to learn the joint distribution in a bidirectional manner while avoiding the need for a unified latent space. Based on the decoupling of modalities during training, we also introduce a joint sampling method that supports test-time scaling, where action and vision tokens evolve asynchronously at different rates. Through experiments on simulated benchmarks such as RoboCasa and GR-1, DUST achieves up to 6% gains over baseline methods, while our test-time scaling approach provides an additional 2-5% boost. On real-world tasks with the Franka Research 3, DUST improves success rates by 13%, confirming its effectiveness beyond simulation. Furthermore, pre-training on action-free videos from BridgeV2 yields significant transfer gains on RoboCasa, underscoring DUST's potential for large-scale VLA pretraining.


            
### AI分析（基于论文正文）
### 论文概要
本文提出DUal-STream Diffusion (DUST)，一种面向世界模型增强的视觉-语言-动作模型框架，旨在解决动作序列与未来状态观测因模态差异导致的联合建模冲突。该方法通过双流扩散架构分离动作与视觉模态的处理路径，同时利用共享注意力机制实现跨模态知识交互。核心设计包括：独立噪声调度的解耦训练算法、支持异步采样的推理时缩放策略。实验表明，DUST在RoboCasa和GR-1模拟任务中相较基线方法提升最高6%，在Franka机械臂真实任务中成功率提升13%，且能通过无动作视频预训练实现高效知识迁移。

---

### 研究动机
现有世界模型增强的VLA方法存在两类典型架构缺陷（见论文第1节及图1）。第一类方法（如PAD、EnerVerse）采用统一联合扩散模型（图1a），将动作与视觉模态拼接至同一潜在空间进行建模。然而，动作轨迹需低维时序平滑输出，而未来视觉观测需高维空间结构化输出，二者统计特性差异显著，强制统一优化会导致模态冲突（第1节："the model must jointly optimize two fundamentally different objectives"）。第二类方法（如Video Policy）采用因果扩散模型（图1b），通过单向条件连接分离模态，但限制了双向知识传递（第1节："limits information flow to a single direction"）。  
论文进一步指出，现有方法在表征未来状态时存在效率问题：直接预测RGB像素（如PAD、PIDM）会引入无关控制的高频细节，而嵌入预测方法（如FLARE）虽避免此问题，但依赖隐式对齐（第2节）。DUST的动机源于调和上述矛盾：既需保留模态特异性，又需实现双向因果依赖建模。此动机由上下文推断，论文未在引言中明确声明，但通过第1-2节对现有工作的系统性批判及第4节方法设计逻辑可合理推导。

---

### 核心贡献与创新点
1. **双流多模态扩散Transformer架构（MMDiT）**  
   - 创新点：设计分离的动作与视觉令牌流，通过共享跨模态注意力层实现交互，避免统一潜在空间的强假设（第4.1节；图2）。具体地，输入三元组 $(o^s_t, A^\tau_t, \tilde{o}^\tau_{t+k})$ 在MMDiT块中分别处理，仅在各块内通过拼接-注意力-分离流程交互（第4.1节："concatenated only temporarily during the shared cross-modal attention layer"）。  
   - 依据：相较统一联合扩散（图1a），DUST通过路径分离保留模态特异性；相较因果扩散（图1b），其双向注意力机制支持动作→状态与状态→动作的双向推理（第4.2节）。

2. **解耦扩散训练算法**  
   - 创新点：引入模态独立噪声扰动（$\tau_A$ 与 $\tau_o$）与解耦流匹配损失（公式3）。该设计使模型能学习任意噪声组合下的双向因果依赖（第4.2节："forces it to learn the inverse relationship"）。  
   - 依据：基于Diffusion Forcing理论扩展至模态级别，通过独立采样 $\tau_A, \tau_o \in [0,1]$ 构造噪声输入 $A^{\tau_A}_t = \tau_A A_t + (1-\tau_A)\epsilon_A$ 与 $\tilde{o}^{\tau_o}_{t+k} = \tau_o \tilde{o}_{t+k} + (1-\tau_o)\epsilon_o$，联合损失为 $L_{\text{Joint}} = L_A + \lambda_{\text{WM}} L_{\text{WM}}$（公式4）。

3. **异步联合采样与推理时缩放**  
   - 创新点：提出动作与视觉令牌异步去噪策略，视觉令牌步数 $N_o = q \times N_A$，动作令牌每 $q$ 步更新一次（第4.3节；公式5；图3）。  
   - 依据：针对视觉嵌入高维特性需更多细化步骤，而动作低维特性可快速收敛的矛盾（第5.3节），通过调节 $q$ 实现精度与效率的权衡（表5）。

---

### 方法概述
DUST框架包含VLM骨干与扩散模块 $\pi_\theta$（图2）。VLM（Eagle-2）提取当前观测与指令的语义特征 $\Phi_t$，扩散模块输入为 $(o^s_t, A^\tau_t, \tilde{o}^\tau_{t+k})$。  
**架构流程**（第4.1节）：  
1. 输入令牌分动作流（16令牌）与视觉流（64令牌，经2×2池化后的SIGLIP-2嵌入）并行进入MMDiT块。  
2. 各MMDiT块内：  
   - 动作/视觉流通过独立线性层投影。  
   - 拼接后输入共享注意力层计算跨模态交互。  
   - 分离回原流后经AdaLN（注入模态特定时间步嵌入）与MLP处理。  
3. 输出经12层MMDiT后，分流至4层模态特定DiT块进行精细化去噪。  

**训练算法**（第4.2节）：  
1. 独立采样 $\tau_A, \tau_o \sim \text{Beta}(1.5,1.0)$ 构造噪声样本。  
2. 速度网络 $V_\theta = [V^A_\theta, V^o_\theta]$ 预测各模态速度场，损失函数为：
   $$L_A = \mathbb{E} \left[ \| V^A_\theta - (A_t - \epsilon_A) \|^2 \right], \quad L_{\text{WM}} = \mathbb{E} \left[ \| V^o_\theta - (\tilde{o}_{t+k} - \epsilon_o) \|^2 \right]$$
3. 联合优化 $L_{\text{Joint}} = L_A + \lambda_{\text{WM}} L_{\text{WM}}$（$\lambda_{\text{WM}}=1.0$）。  

**推理流程**（第4.3节）：  
1. 初始化 $A^0_t \sim \mathcal{N}(0,I_A)$, $\tilde{o}^0_{t+k} \sim \mathcal{N}(0,I_o)$。  
2. 设定 $N_A=4$, $N_o=q \times N_A$，全局步长 $\Delta\tau_o = 1/N_o$。  
3. 迭代更新（公式5）：  
   - 视觉令牌每步更新：$\tilde{o}^{\tau_o+\Delta\tau_o}_{t+k} = \tilde{o}^{\tau_o}_{t+k} + V^o_\theta \Delta\tau_o$  
   - 动作令牌每 $q$ 步更新：$A^{\tau_A+\Delta\tau_A}_t = A^{\tau_A}_t + V^A_\theta \Delta\tau_A$（当 $\tau_A N_o \mod q = 0$）

---

### 实验说明
**评估指标**：任务成功率（%）。  
**数据集**：  
- 模拟环境：RoboCasa（24任务，含抓放、开关操作）、GR-1（24任务，含抓放与关节控制）。  
- 真实环境：Franka Research 3（4类抓放任务，每任务4种物体）。  
- 迁移学习：BridgeV2（无动作视频）预训练后微调至RoboCasa。  

**基线方法**：  
- 类别1（原生VLA）：GR00T-N1.5（扩散动作专家）。  
- 类别2（世界模型增强）：GR00T-N1.5 + FLARE（隐式世界建模，复现实现）。  

**实验条件**：  
- 训练：冻结VLM（Eagle-2），扩散模块随机初始化。超参数 $\lambda_{\text{WM}}=1.0$，MMDiT层数12，DiT层数4。  
- 硬件配置：论文未明确说明GPU数量与型号。  
- 推理：默认 $N_A=N_o=4$，测试时缩放实验 $N_o \in \{16,32,64\}$。

---

### 改进建议和未来研究方向
**已声明的局限性**：  
1. 测试时缩放虽提升性能，但增加推理时间（第5.3节）。  
2. 预训练依赖特定嵌入空间（SIGLIP-2），可能限制泛化性（第5节）。  

**未明确的潜在局限**：  
1. **模态交互强度依赖启发式设计**：MMDiT中注意力权重的模态均衡性未定量分析，可能存在主导模态抑制。  
2. **长时序推理能力未验证**：实验限于单步动作-状态预测，未扩展至多步滚动预测。  

**改进建议**：  
1. 引入可学习的模态交互门控机制，动态调整跨注意力权重（可行性高，需增加轻量参数）。  
2. 结合分层强化学习，将DUST扩展为多步世界模型，通过时序抽象减少累积误差（可行性

---


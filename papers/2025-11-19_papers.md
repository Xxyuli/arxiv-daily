# arXivè®ºæ–‡ç›‘æ§æŠ¥å‘Š - 2025å¹´11æœˆ19æ—¥

> æœ¬æŠ¥å‘Šç”±arXivè®ºæ–‡ç›‘æ§Agentè‡ªåŠ¨ç”Ÿæˆ

## æŠ¥å‘Šæ¦‚è§ˆ

- **ç›‘æ§æ—¥æœŸ**: 2025å¹´11æœˆ19æ—¥
- **ç›‘æ§åˆ†ç±»**: cs.AI, cs.LG, cs.RO, cs.CV
- **å…³é”®è¯**: Vision Language Action , vla, Vision-Language-Action, Multivariate Time Series Forecasting, spatio-temporal prediction, traffic prediction
- **å‘ç°è®ºæ–‡æ•°**: 10ç¯‡

---

## 1. Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation

### åŸºæœ¬ä¿¡æ¯
- **ä½œè€…**: Yihao Zhang, Yuankai Qi, Xi Zheng
- **arXiv ID**: [oai:arXiv.org:2511.11298v1](https://arxiv.org/abs/2511.11298)
- **å‘å¸ƒæ—¥æœŸ**: Tue, 18 Nov 2025 00:00:00 -0500
- **åˆ†ç±»**: cs.RO, cs.AI
- **è®ºæ–‡é“¾æ¥**: [arXivé“¾æ¥](https://arxiv.org/abs/2511.11298)

            ### åŸæ–‡æ‘˜è¦
            arXiv:2511.11298v1 Announce Type: cross  Abstract: Foundation models applied in robotics, particularly \textbf{Vision--Language--Action (VLA)} models, hold great promise for achieving general-purpose manipulation. Yet, systematic real-world evaluations and cross-model comparisons remain scarce. This paper reports our \textbf{empirical experiences} from benchmarking four representative VLAs -- \textbf{ACT}, \textbf{OpenVLA--OFT}, \textbf{RDT-1B}, and \boldmath{$\pi_0$} -- across four manipulation tasks conducted in both simulation and on the \textbf{ALOHA Mobile} platform. We establish a \textbf{standardized evaluation framework} that measures performance along three key dimensions: (1) \textit{accuracy and efficiency} (success rate and time-to-success), (2) \textit{adaptability} across in-distribution, spatial out-of-distribution, and instance-plus-spatial out-of-distribution settings, and (3) \textit{language instruction-following accuracy}. Through this process, we observe that \boldmath{$\pi_0$} demonstrates superior adaptability in out-of-distribution scenarios, while \textbf{ACT} provides the highest stability in-distribution. Further analysis highlights differences in computational demands, data-scaling behavior, and recurring failure modes such as near-miss grasps, premature releases, and long-horizon state drift. These findings reveal practical trade-offs among VLA model architectures in balancing precision, generalization, and deployment cost, offering actionable insights for selecting and deploying VLAs in real-world robotic manipulation tasks.


            
### AIåˆ†æï¼ˆåŸºäºè®ºæ–‡æ­£æ–‡ï¼‰
æ ¹æ®æä¾›çš„è®ºæ–‡ä¿¡æ¯ï¼Œä»¥ä¸‹æ˜¯æŒ‰ç…§è¦æ±‚æ ¼å¼æ’°å†™çš„è®ºæ–‡æ€»ç»“ï¼š

### 1. è®ºæ–‡æ¦‚è¦
æœ¬è®ºæ–‡ç³»ç»Ÿè¯„ä¼°äº†å››ç§ä»£è¡¨æ€§è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼ˆACTã€OpenVLA-OFTã€RDT-1Bã€Ï€0ï¼‰åœ¨åŒæ‰‹æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚ç ”ç©¶å»ºç«‹äº†æ ‡å‡†åŒ–è¯„ä¼°æ¡†æ¶ï¼Œåœ¨æ¨¡æ‹Ÿç¯å¢ƒå’ŒALOHA Mobileå¹³å°ä¸Šæµ‹è¯•äº†å››ä¸ªæ“ä½œä»»åŠ¡ï¼Œä»å‡†ç¡®æ€§ã€æ•ˆç‡ã€é€‚åº”æ€§å’Œè¯­è¨€æŒ‡ä»¤éµå¾ªèƒ½åŠ›ä¸‰ä¸ªç»´åº¦è¿›è¡Œç»¼åˆæ¯”è¾ƒã€‚ç ”ç©¶å‘ç°Ï€0åœ¨åˆ†å¸ƒå¤–åœºæ™¯ä¸­è¡¨ç°å‡ºæœ€å¼ºçš„é€‚åº”æ€§ï¼Œè€ŒACTåœ¨åˆ†å¸ƒå†…åœºæ™¯ä¸­ç¨³å®šæ€§æœ€é«˜ï¼Œæ­ç¤ºäº†ä¸åŒVLAæ¶æ„åœ¨ç²¾åº¦ã€æ³›åŒ–èƒ½åŠ›å’Œéƒ¨ç½²æˆæœ¬ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚

### 2. ç ”ç©¶åŠ¨æœº
å½“å‰æœºå™¨äººæ“ä½œé¢†åŸŸé¢ä¸´çš„æ ¸å¿ƒé—®é¢˜æ˜¯ï¼šè™½ç„¶åŸºç¡€æ¨¡å‹ç‰¹åˆ«æ˜¯è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨å®ç°é€šç”¨æ“ä½œæ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†ç³»ç»Ÿçš„çœŸå®ä¸–ç•Œè¯„ä¼°å’Œè·¨æ¨¡å‹æ¯”è¾ƒä»ç„¶åŒ®ä¹ï¼ˆè§ç¬¬1èŠ‚å¼•è¨€ï¼‰ã€‚ç°æœ‰ç ”ç©¶å­˜åœ¨ä¸‰ä¸ªä¸»è¦ä¸è¶³ï¼šé¦–å…ˆï¼Œå¤§å¤šæ•°æœ€å…ˆè¿›è¯„ä¼°ä»…é’ˆå¯¹å•è‡‚ã€çº¯ä»¿çœŸè®¾ç½®ï¼Œç¼ºä¹å¯¹çœŸå®ä¸–ç•Œå¯é æ€§çš„éªŒè¯ï¼ˆç¬¬1èŠ‚å¼•ç”¨[20,38]ï¼‰ï¼›å…¶æ¬¡ï¼Œç°æœ‰å·¥ä½œåœ¨åˆ†å¸ƒåç§»ä¸‹çš„é²æ£’æ€§è¡¨ç°å‚å·®ä¸é½ï¼Œåœ¨æ–°ç‰©ä½“ã€å¸ƒå±€æˆ–è§†è§’å˜åŒ–ä¸‹æ€§èƒ½ä¸‹é™è¾¾20%-70%ï¼›ç¬¬ä¸‰ï¼Œç¼ºä¹å¯¹è¯­è¨€æŒ‡ä»¤éµå¾ªå’Œç©ºé—´æ³›åŒ–èƒ½åŠ›çš„ç³»ç»Ÿè¯„ä¼°ã€‚

è®ºæ–‡é€šè¿‡åˆ†æç°æœ‰VLAæ¨¡å‹é¢ä¸´çš„æŒ‘æˆ˜æŒ‡å‡ºï¼šé«˜å®¹é‡VLAéœ€è¦å¤§è§„æ¨¡å¤šæ ·åŒ–æ•°æ®é›†ï¼Œå¦‚RT-1æ”¶é›†äº†13å°æœºå™¨äºº17ä¸ªæœˆçš„130,000æ¬¡æ¼”ç¤ºï¼ˆç¬¬1èŠ‚å¼•ç”¨[40]ï¼‰ï¼›å¤§å‹è§†è§‰ç¼–ç å™¨å’Œè‡ªå›å½’è§£ç å¸¦æ¥çš„å»¶è¿Ÿé—®é¢˜å¯¹10-50Hzæ§åˆ¶é¢„ç®—é€ æˆå‹åŠ›ï¼ˆç¬¬1èŠ‚å¼•ç”¨[4,16,17]ï¼‰ï¼›å°½ç®¡æœ‰ä»¤ç‰Œç¼“å­˜ã€ä½ç§©é€‚åº”å’Œé‡åŒ–ç­‰ä¼˜åŒ–æ–¹æ³•ï¼Œä½†æ¿è½½çº¦æŸé—®é¢˜ä»æœªå®Œå…¨è§£å†³ï¼ˆç¬¬1èŠ‚å¼•ç”¨[6,39]ï¼‰ã€‚è¿™äº›å±€é™æ€§ä¿ƒä½¿ä½œè€…å»ºç«‹ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°åŸºå‡†ï¼Œç›´æ¥æ¯”è¾ƒä»£è¡¨æ€§æ¨¡å‹åœ¨ç›¸åŒè®¾ç½®ä¸‹çš„è¡¨ç°ã€‚

### 3. æ ¸å¿ƒè´¡çŒ®ä¸åˆ›æ–°ç‚¹
æœ¬è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®ä½“ç°åœ¨ä¸‰ä¸ªæ–¹é¢ï¼š

**ç»Ÿä¸€åŸºå‡†æ¡†æ¶**ï¼šè®ºæ–‡é¦–æ¬¡å»ºç«‹äº†é’ˆå¯¹åŒè‡‚æ“ä½œçš„ç»Ÿä¸€è¯„ä¼°åŸºå‡†ï¼Œæ˜ç¡®å®šä¹‰äº†åˆ†å¸ƒå†…å’Œåˆ†å¸ƒå¤–è¯„ä¼°è®¾ç½®ï¼ˆç¬¬4.1.2èŠ‚ï¼‰ã€‚è¯¥åŸºå‡†åŒ…å«å››ä¸ªå®¶åº­åœºæ™¯å¯å‘çš„æ“ä½œä»»åŠ¡ï¼ˆæ¸…æ´ç›˜å­ã€å°†æµ·ç»µæ”¾å…¥é”…ä¸­ã€æ‰“å¼€æ‹‰é“¾åŒ…ã€æŠ˜å çŸ­è£¤ï¼‰ï¼Œé›†æˆäº†å·¥å…·ä½¿ç”¨ã€å¯å˜å½¢ç‰©ä½“æ§åˆ¶ã€ç©ºé—´æ¨ç†å’Œè¯­è¨€ç†è§£èƒ½åŠ›ã€‚åŸºå‡†å‘å¸ƒäº†æ ‡å‡†åŒ–çš„å¯å¤ç°è¯„ä¼°æµç¨‹ï¼Œé‡‡ç”¨ç»Ÿä¸€æŒ‡æ ‡è¿›è¡Œå…¬å¹³çš„è·¨æ¨¡å‹æ¯”è¾ƒï¼ˆè§è´¡çŒ®éƒ¨åˆ†ï¼‰ã€‚

**å¤±è´¥æ¨¡å¼åˆ†ç±»å’Œè¯Šæ–­åˆ†æ**ï¼šç ”ç©¶å¼€å‘äº†ç»“æ„åŒ–çš„å¤±è´¥åˆ†ç±»æ³•ï¼Œæ•è·äº†å¸¸è§é”™è¯¯æ¨¡å¼ï¼ŒåŒ…æ‹¬æ—¶é—´æ¼‚ç§»ã€ç¬¦å·æ¥åœ°å¤±è´¥å’Œæ‰§è¡Œå¤±è¯¯ç­‰ï¼ˆç¬¬5.5èŠ‚ï¼‰ã€‚é€šè¿‡å…·ä½“æ¡ˆä¾‹ç ”ç©¶ï¼ˆå›¾4a-hï¼‰ï¼Œè¯¥åˆ†ç±»æ³•æ­ç¤ºäº†ä¸åŒæ¶æ„çš„æ¨¡å‹ç‰¹å®šå¼±ç‚¹ï¼Œå¦‚ACTä¸»è¦å—è½¨è¿¹/çŠ¶æ€æ¼‚ç§»å½±å“ï¼Œè€ŒÏ€0åˆ™è¡¨ç°å‡ºå¶å°”çš„æ·±åº¦æ„ŸçŸ¥å¼•èµ·çš„æ”¾ç½®é”™è¯¯ã€‚

**é²æ£’æ€§å’Œæ•°æ®æ‰©å±•çš„å®è¯è§è§£**ï¼šé€šè¿‡å¯¹ç…§å®éªŒï¼Œè®ºæ–‡æ­ç¤ºäº† specialist imitation æ¨¡å‹å’Œ generalist VLA æ¨¡å‹ä¹‹é—´æ¸…æ™°çš„é²æ£’æ€§-ç²¾åº¦æƒè¡¡ï¼ˆç¬¬5.1-5.4èŠ‚ï¼‰ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨é•¿è§†é‡ã€å¯å˜å½¢ç‰©ä½“ä»»åŠ¡ä¸­ï¼Œæ€§èƒ½éšç€æœ‰é™æ¼”ç¤ºæ‰©å±•è€Œé¥±å’Œï¼Œç‰¹åˆ«æ˜¯åœ¨æŠ˜å çŸ­è£¤ä»»åŠ¡ä¸­ï¼Œæ‰€æœ‰æ¨¡å‹åœ¨100æ¬¡æ¼”ç¤ºè®­ç»ƒä¸‹æˆåŠŸç‡å‡ä¸º0%ï¼Œè€ŒÏ€0åœ¨200æ¬¡æ¼”ç¤ºä¸‹è¾¾åˆ°52%æˆåŠŸç‡ï¼ˆè¡¨3ï¼‰ã€‚

### 4. æ–¹æ³•æ¦‚è¿°
è®ºæ–‡çš„æŠ€æœ¯æ–¹æ¡ˆå›´ç»•æ ‡å‡†åŒ–è¯„ä¼°æ¡†æ¶æ„å»ºï¼Œå…·ä½“å®ç°ç»†èŠ‚å¦‚ä¸‹ï¼š

**è¯„ä¼°æ¡†æ¶è®¾è®¡**ï¼šç ”ç©¶é‡‡ç”¨ä¸‰æ‘„åƒå¤´æ„ŸçŸ¥ç³»ç»Ÿï¼ˆä¸€ä¸ªé¡¶éƒ¨å®‰è£…æ‘„åƒå¤´å’Œä¸¤ä¸ªè…•éƒ¨å®‰è£…æ‘„åƒå¤´ï¼‰ï¼Œåˆ†è¾¨ç‡640Ã—480ï¼Œå¸§ç‡30Hzï¼ˆç¬¬4.1.1èŠ‚ï¼‰ã€‚è®¡ç®—é…ç½®ä½¿ç”¨NVIDIA RTX 5090 GPUï¼Œå•æ­¥æ§åˆ¶æ—¶é—´é¢„ç®—ä¸º40msï¼ˆ25Hzï¼‰ã€‚æ‰€æœ‰æ¨¡å‹åœ¨ç›¸åŒç¡¬ä»¶è®¾ç½®ä¸‹è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿ç»“æœå¯æ¯”æ€§ã€‚

**ä»»åŠ¡è®¾è®¡å’ŒæŒ‡æ ‡**ï¼šå››ä¸ªæ ¸å¿ƒä»»åŠ¡è®¾è®¡æ¶µç›–ä¸åŒå¤æ‚åº¦ï¼ˆç¬¬4.1.2èŠ‚ï¼‰ï¼š
- æ¸…æ´ç›˜å­ï¼šæµ‹è¯•ç²¾ç¡®åŠ›æ§åˆ¶å’ŒåŒæ‰‹åè°ƒ
- å°†æµ·ç»µæ”¾å…¥é”…ä¸­ï¼šè¯„ä¼°ç‰©ä½“é€‰æ‹©å’Œç©ºé—´ç†è§£
- æ‰“å¼€æ‹‰é“¾åŒ…ï¼šæ¶‰åŠå¯å˜å½¢ç‰©ä½“æ“ä½œå’Œç²¾ç¡®æ“ä½œ
- æŠ˜å çŸ­è£¤ï¼šè¯„ä¼°å¯å˜å½¢ç‰©ä½“ä¸Šçš„åŒæ‰‹åè°ƒ

**è¯„ä¼°åè®®**ï¼šé‡‡ç”¨ä¸‰é‡è¯„ä¼°è®¾ç½®ï¼šåˆ†å¸ƒå†…ï¼ˆIDï¼‰ã€ç©ºé—´åˆ†å¸ƒå¤–ï¼ˆç›¸åŒå®ä¾‹æ–°æ”¾ç½®ï¼‰å’Œå®ä¾‹+ç©ºé—´åˆ†å¸ƒå¤–ï¼ˆæ–°ç‰©ä½“å®ä¾‹å’Œæ–°ç©ºé—´é…ç½®ï¼‰ï¼ˆç¬¬4.1.2èŠ‚ï¼‰ã€‚æ¯ä¸ªï¼ˆä»»åŠ¡ã€æ¨¡å‹ã€è®¾ç½®ï¼‰ç»„åˆè¿›è¡Œn=50æ¬¡è¯•éªŒï¼Œä½¿ç”¨å…±äº«éšæœºç§å­å’Œå¾ªç¯è¯„ä¼°é¡ºåºç¡®ä¿å…¬å¹³æ€§ã€‚

**æ€§èƒ½æŒ‡æ ‡**ï¼šé‡‡ç”¨ä¸‰ä¸ªæ ¸å¿ƒæŒ‡æ ‡ï¼ˆç¬¬4.1.2èŠ‚ï¼‰ï¼š
1. ä»»åŠ¡æˆåŠŸç‡ï¼ˆSRï¼‰ï¼šå®ç°ä»»åŠ¡ç›®æ ‡çš„è¯•éªŒç™¾åˆ†æ¯”
2. æˆåŠŸæ—¶é—´ï¼ˆTTSï¼‰ï¼šä»ç¬¬ä¸€ä¸ªåŠ¨ä½œåˆ°ä»»åŠ¡å®Œæˆçš„æ—¶é—´
3. æŒ‡ä»¤éµå¾ªå‡†ç¡®ç‡ï¼ˆIAAï¼‰ï¼šè¯­è¨€æŒ‡å®šç›®æ ‡çš„ç›®æ ‡å’Œå…³ç³»æ¥åœ°æ­£ç¡®æ€§

ä»¿çœŸåŸºå‡†è¡¥å……äº†çœŸå®æœºå™¨äººè¯„ä¼°ï¼Œä½¿ç”¨MuJoCoæ¡Œé¢ç¯å¢ƒæµ‹è¯•é›¶æ ·æœ¬è¯­è¨€æ¥åœ°å’Œç©ºé—´æ¨ç†èƒ½åŠ›ï¼ˆç¬¬4.2èŠ‚ï¼‰ã€‚

### 5. å®éªŒè¯´æ˜
**è¯„ä¼°æŒ‡æ ‡**ï¼šè®ºæ–‡é‡‡ç”¨ä¸‰ä¸ªä¸»è¦è¯„ä¼°æŒ‡æ ‡ï¼šä»»åŠ¡æˆåŠŸç‡ï¼ˆSRï¼‰ã€æˆåŠŸæ—¶é—´ï¼ˆTTSï¼‰å’ŒæŒ‡ä»¤éµå¾ªå‡†ç¡®ç‡ï¼ˆIAAï¼‰ã€‚æ‰€æœ‰æŒ‡æ ‡åœ¨åˆ†å¸ƒå†…ï¼ˆIDï¼‰ã€ç©ºé—´åˆ†å¸ƒå¤–å’Œå®ä¾‹+ç©ºé—´åˆ†å¸ƒå¤–ä¸‰ç§è®¾ç½®ä¸‹è¿›è¡Œè¯„ä¼°ï¼ˆç¬¬4.1.2èŠ‚ï¼‰ã€‚

**æ•°æ®é›†**ï¼šç ”ç©¶ä½¿ç”¨äº†ä»ALOHA Mobileå¹³å°æ”¶é›†çš„æ•°æ®é›†ï¼Œå…·ä½“åŒ…æ‹¬ï¼š
- æ¸…æ´ç›˜å­ä»»åŠ¡ï¼š100æ¬¡æ¼”ç¤º
- å°†æµ·ç»µæ”¾å…¥é”…ä¸­ä»»åŠ¡ï¼š100æ¬¡æ¼”ç¤º  
- æ‰“å¼€æ‹‰é“¾åŒ…ä»»åŠ¡ï¼š100æ¬¡æ¼”ç¤º
- æŠ˜å çŸ­è£¤ä»»åŠ¡ï¼š100æ¬¡å’Œ200æ¬¡æ¼”ç¤ºä¸¤ä¸ªç‰ˆæœ¬
æ‰€æœ‰è®­ç»ƒæ•°æ®é€šè¿‡é¥æ“ä½œæ”¶é›†ï¼Œè¦†ç›–ä¸åŒçš„åˆå§‹ç‰©ä½“ä½ç½®å’Œæ–¹å‘ï¼Œè¯­è¨€æŒ‡ä»¤è¡¨è¿°ä¹Ÿè¿›è¡Œäº†å¤šæ ·åŒ–ï¼ˆç¬¬4.1.2èŠ‚ï¼‰ã€‚

**å¯¹æ¯”åŸºçº¿æ–¹æ³•**ï¼šè®ºæ–‡è¯„ä¼°äº†å››ç±»ä»£è¡¨æ€§æ¨¡å‹ï¼š
- Specialist imitationæ¨¡å‹ï¼šACTï¼ˆAction Chunking Transformerï¼‰
- Generalist VLAæ¨¡å‹ï¼šOpenVLA-OFTï¼ˆ7Bå‚æ•°ï¼‰ã€RDT-1Bï¼ˆ1Bå‚æ•°æ‰©æ•£æ¨¡å‹ï¼‰ã€Ï€0ï¼ˆ3Bå‚æ•°PaliGemmaåŸºç¡€ï¼‰

**å®éªŒæ¡ä»¶**ï¼š
- è®­ç»ƒç¡¬ä»¶ï¼šOpenVLA-OFTå’ŒRDT-1Båœ¨åŒA6000 GPUä¸Šå¾®è°ƒï¼Œè®­ç»ƒæ—¶é—´çº¦21å¤©ï¼›ACTå’ŒÏ€0åœ¨RTX 5090 GPUä¸Šè®­ç»ƒï¼Œåˆ†åˆ«éœ€çº¦2å°æ—¶å’Œ24å°æ—¶ï¼ˆç¬¬4.1.1èŠ‚ï¼Œè¡¨1ï¼‰
- æ¨ç†ç¡¬ä»¶ï¼šæ‰€æœ‰æµ‹è¯•åœ¨NVIDIA RTX 5090 GPUä¸Šè¿›è¡Œ
- æ§åˆ¶é¢‘ç‡ï¼šOpenVLA-OFTç¨³å®šè¿è¡Œåœ¨25Hzï¼ŒÏ€0æ”¯æŒæœ€é«˜50Hzï¼ŒACTæ§åˆ¶å™¨è¿è¡Œåœ¨50Hzï¼ˆç¬¬4.1.1èŠ‚ï¼‰
- æ‰¹é‡å¤§å°å’Œå­¦ä¹ ç‡ï¼šå„æ¨¡å‹é‡‡ç”¨ä¸åŒé…ç½®ï¼ˆè¡¨1è¯¦ç»†è¯´æ˜ï¼‰

### 6. æ”¹è¿›å»ºè®®å’Œæœªæ¥ç ”ç©¶æ–¹å‘
**å·²è¯†åˆ«çš„å±€é™æ€§**ï¼šè®ºæ–‡æ˜ç¡®æ‰¿è®¤äº†å‡ ä¸ªå…³é”®é™åˆ¶ã€‚é¦–å…ˆï¼Œæ‰€æœ‰æ¨¡å‹åœ¨å¯å˜å½¢ç‰©ä½“å’Œé•¿è§†é‡ä»»åŠ¡ä¸­è¡¨ç°å—é™ï¼Œç‰¹åˆ«æ˜¯åœ¨æŠ˜å çŸ­è£¤ä»»åŠ¡ä¸­ï¼Œå³ä½¿å¢åŠ æ¼”ç¤ºæ•°æ®ï¼Œæ€§èƒ½æå‡ä¹Ÿæœ‰é™ï¼ˆç¬¬5.2èŠ‚ï¼‰ã€‚å…¶æ¬¡ï¼Œæ¨¡å‹åœ¨ç²¾ç¡®æŠ“å–å’Œæ”¾ç½®æ–¹é¢å­˜åœ¨ç³»ç»Ÿæ€§å›°éš¾ï¼Œå¦‚å­å˜ç±³çº§çš„XY/Zåç§»å’Œæ‰‹è…•æ»šåŠ¨é”™ä½ï¼ˆç¬¬5.5èŠ‚ï¼‰ã€‚ç¬¬ä¸‰ï¼ŒæŒ‡ä»¤éµå¾ªåœ¨å¤æ‚å¤šæ­¥å‘½ä»¤ä¸­æ€§èƒ½ä¸‹é™ï¼Œå¦‚ä»¿çœŸä¸­å¤šæ­¥å †å ä»»åŠ¡æˆåŠŸç‡å‡ä¸º0%ï¼ˆè¡¨6ï¼‰ã€‚

**æ½œåœ¨æœªæåŠçš„å±€é™æ€§**ï¼šä»æ–¹æ³•å’Œç»“æœä¸­å¯ä»¥æ¨æ–­å‡ºå…¶ä»–é™åˆ¶ï¼šæ¨¡å‹å¯¹æ„ŸçŸ¥å™ªå£°æ•æ„Ÿï¼Œç‰¹åˆ«æ˜¯æ·±åº¦æ„ŸçŸ¥è¯¯å·®ï¼›æ§åˆ¶å»¶è¿Ÿå’Œæ—¶é—´ä¸€è‡´æ€§åœ¨æ¥è§¦å¯†é›†å‹ä»»åŠ¡ä¸­æ„æˆæŒ‘æˆ˜ï¼›å½“å‰åŸºå‡†è™½ç„¶å…¨é¢ï¼Œä½†ä»»åŠ¡å¤šæ ·æ€§ä»æœ‰é™ï¼Œå¯èƒ½æ— æ³•å®Œå…¨ä»£è¡¨ç°å®ä¸–ç•Œåº”ç”¨çš„å¤æ‚æ€§ã€‚

**å…·ä½“æ”¹è¿›å»ºè®®**ï¼š
1. å¢å¼ºæ„ŸçŸ¥é²æ£’æ€§ï¼šé›†æˆå¤šæ¨¡æ€ä¼ æ„Ÿå™¨èåˆå’Œåœ¨çº¿æ ¡å‡†æœºåˆ¶ï¼Œå‡å°‘æ·±åº¦æ„ŸçŸ¥è¯¯å·®å¼•èµ·çš„æ”¾ç½®é”™è¯¯ï¼ˆåŸºäºç¬¬5.5èŠ‚è§‚å¯Ÿï¼‰
2. æ”¹è¿›æ§åˆ¶ç­–ç•¥ï¼šé’ˆå¯¹æ¥è§¦å¯†é›†å‹ä»»åŠ¡å¼€å‘ä¸“é—¨çš„è½¨è¿¹ä¼˜åŒ–å’ŒåŠ›æ§åˆ¶æ¨¡å—ï¼Œè§£å†³ç²¾ç¡®å¯¹é½å’Œè½»æŸ”é‡Šæ”¾é—®é¢˜ï¼ˆåŸºäºä»¿çœŸç»“æœåˆ†æï¼‰
3. æ‰©å±•è¯­è¨€ç†è§£ï¼šå¢å¼ºæ¨¡å‹å¯¹å¤æ‚å¤šæ­¥æŒ‡ä»¤çš„è§£æå’Œæ‰§è¡Œèƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯æ¶‰åŠç©ºé—´å…³ç³»å’Œæ—¶åºçº¦æŸçš„ä»»åŠ¡

**è·¨é¢†åŸŸèåˆçš„æœªæ¥æ–¹å‘**ï¼š
1. ç»“åˆè§¦è§‰æ„ŸçŸ¥ï¼šé›†æˆè§¦è§‰ä¼ æ„Ÿå™¨æ•°æ®å¯èƒ½æ˜¾è‘—æ”¹å–„æŠ“å–æˆåŠŸç‡å’ŒåŠ›æ§åˆ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨å¯å˜å½¢ç‰©ä½“æ“ä½œä¸­
2. èåˆå¼ºåŒ–å­¦ä¹ ï¼šå°†æ¨¡ä»¿å­¦ä¹ ä¸å¼ºåŒ–å­¦ä¹ ç»“åˆï¼Œé€šè¿‡ç¯å¢ƒäº¤äº’è¿›ä¸€æ­¥ä¼˜åŒ–ç­–ç•¥ï¼Œå‡å°‘å¯¹æ¼”ç¤ºæ•°æ®çš„ä¾èµ–
3. è‡ªé€‚åº”è®¡ç®—ï¼šå¼€å‘åŠ¨æ€è®¡ç®—åˆ†é…æœºåˆ¶ï¼Œæ ¹æ®ä»»åŠ¡å¤æ‚åº¦è°ƒæ•´æ¨¡å‹æ¨ç†ç²¾åº¦ï¼Œå¹³è¡¡æ€§èƒ½ä¸å®æ—¶æ€§è¦æ±‚
è¿™äº›æ–¹å‘åœ¨æŠ€æœ¯ä¸Šå¯è¡Œï¼Œä¸”ä¸å½“å‰æœºå™¨äººå­¦ä¹ çš„å‘å±•è¶‹åŠ¿ä¸€è‡´ï¼Œæœ‰æœ›åœ¨ç°æœ‰å·¥ä½œåŸºç¡€ä¸Šå®ç°å®è´¨æ€§è¿›å±•ã€‚

---

## 2. Strada-LLM: Graph LLM for traffic prediction

### åŸºæœ¬ä¿¡æ¯
- **ä½œè€…**: Seyed Mohamad Moghadas, Bruno Cornelis, Alexandre Alahi, Adrian Munteanu
- **arXiv ID**: [oai:arXiv.org:2410.20856v3](https://arxiv.org/abs/2410.20856)
- **å‘å¸ƒæ—¥æœŸ**: Tue, 18 Nov 2025 00:00:00 -0500
- **åˆ†ç±»**: cs.LG, cs.AI
- **è®ºæ–‡é“¾æ¥**: [arXivé“¾æ¥](https://arxiv.org/abs/2410.20856)

            ### åŸæ–‡æ‘˜è¦
            arXiv:2410.20856v3 Announce Type: replace-cross  Abstract: Traffic forecasting is pivotal for intelligent transportation systems, where accurate and interpretable predictions can significantly enhance operational efficiency and safety. A key challenge stems from the heterogeneity of traffic conditions across diverse locations, leading to highly varied traffic data distributions. Large language models (LLMs) show exceptional promise for few-shot learning in such dynamic and data-sparse scenarios. However, existing LLM-based solutions often rely on prompt-tuning, which can struggle to fully capture complex graph relationships and spatiotemporal dependencies-thereby limiting adaptability and interpretability in real-world traffic networks. We address these gaps by introducing Strada-LLM, a novel multivariate probabilistic forecasting LLM that explicitly models both temporal and spatial traffic patterns. By incorporating proximal traffic information as covariates, Strada-LLM more effectively captures local variations and outperforms prompt-based existing LLMs. To further enhance adaptability, we propose a lightweight distribution-derived strategy for domain adaptation, enabling parameter-efficient model updates when encountering new data distributions or altered network topologies-even under few-shot constraints. Empirical evaluations on spatio-temporal transportation datasets demonstrate that Strada-LLM consistently surpasses state-of-the-art LLM-driven and traditional GNN-based predictors. Specifically, it improves long-term forecasting by 17% in RMSE error and 16% more efficiency. Moreover, it maintains robust performance across different LLM backbones with minimal degradation, making it a versatile and powerful solution for real-world traffic prediction tasks.


            
### AIåˆ†æï¼ˆåŸºäºè®ºæ–‡æ­£æ–‡ï¼‰
### è®ºæ–‡æ¦‚è¦
æœ¬è®ºæ–‡æå‡ºStrada-LLMï¼Œä¸€ç§åŸºäºå›¾ç»“æ„çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œç”¨äºè§£å†³äº¤é€šé¢„æµ‹ä¸­çš„å¤šå˜é‡æ¦‚ç‡é¢„æµ‹é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ†å±‚ç‰¹å¾æå–å™¨æ˜¾å¼å»ºæ¨¡æ—¶ç©ºä¾èµ–å…³ç³»ï¼Œç»“åˆä½ç§©è‡ªé€‚åº”æŠ€æœ¯å®ç°è·¨åŸŸè¿ç§»ã€‚ç ”ç©¶èŒƒå›´æ¶µç›–çŸ­é•¿æœŸé¢„æµ‹ã€é›¶æ ·æœ¬å­¦ä¹ å’Œæ¦‚ç‡é¢„æµ‹ï¼Œåœ¨8ä¸ªçœŸå®äº¤é€šæ•°æ®é›†ä¸ŠéªŒè¯äº†æ¨¡å‹åœ¨RMSEæŒ‡æ ‡ä¸Šç›¸æ¯”åŸºçº¿æ–¹æ³•æå‡5%-18%çš„æ€§èƒ½ï¼ˆè§ç¬¬4.3èŠ‚ï¼‰ã€‚

### ç ”ç©¶åŠ¨æœº
äº¤é€šé¢„æµ‹é¢ä¸´çš„æ ¸å¿ƒæŒ‘æˆ˜æºäºæ—¶ç©ºä¾èµ–çš„å¤æ‚æ€§å’Œæ•°æ®åˆ†å¸ƒçš„å¼‚æ„æ€§ï¼ˆç¬¬1èŠ‚ï¼‰ã€‚ç°æœ‰åŸºäºæç¤ºè°ƒä¼˜çš„LLMæ–¹æ³•ï¼ˆå¦‚UrbanGPT[15]ã€UniST[34]ï¼‰å­˜åœ¨ä¸‰æ–¹é¢ä¸è¶³ï¼š1ï¼‰æç¤ºæ„é€ ä¼šä¸¢å¤±å…¨å±€æ‹“æ‰‘ä¿¡æ¯ï¼ˆç¬¬1èŠ‚æŒ‡å‡º"prompting operation loses the global topological information"ï¼‰ï¼›2ï¼‰è®°å¿†ç½‘ç»œæ¶æ„ä¼šå¯¼è‡´è¯¯å·®æŒ‡æ•°ä¼ æ’­ï¼ˆç¬¬1èŠ‚å¼•ç”¨[3]è¯æ˜ï¼‰ï¼›3ï¼‰å‚æ•°æ•ˆç‡ä½ï¼Œåœ¨ç™¾ä¸‡èŠ‚ç‚¹å›¾ä¸­å—ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ï¼ˆç¬¬1èŠ‚ï¼‰ã€‚ä¼ ç»Ÿå›¾ç¥ç»ç½‘ç»œè™½èƒ½æ•æ‰ç©ºé—´ä¾èµ–ï¼Œä½†ç¼ºä¹è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚ä½œè€…é€šè¿‡åˆ†æç°æœ‰æ–¹æ³•åœ¨METR-LAå’ŒPeMS-Bayæ•°æ®é›†ä¸Šçš„æ€§èƒ½å·®è·ï¼ˆè¡¨2-3ï¼‰ï¼ŒæŒ‡å‡ºéœ€è¦ä¸€ç§æ—¢èƒ½ä¿æŒå›¾ç»“æ„åˆèƒ½é«˜æ•ˆè‡ªé€‚åº”çš„æ–°èŒƒå¼ã€‚

### æ ¸å¿ƒè´¡çŒ®ä¸åˆ›æ–°ç‚¹
1. **éæç¤ºé©±åŠ¨çš„å›¾æ„ŸçŸ¥LLMæ¶æ„**ï¼šé¦–æ¬¡æå‡ºæ— éœ€æç¤ºå³å¯éšå¼ç¼–ç å›¾ç»“æ„çš„LLMï¼Œé€šè¿‡æ‹‰æ™®æ‹‰æ–¯ä½ç½®ç¼–ç ï¼ˆç¬¬3.1.2èŠ‚ï¼‰å’Œkè·³å­å›¾æå–å™¨ï¼ˆå…¬å¼1ï¼‰ä¿æŒå…¨å±€æ‹“æ‰‘ï¼Œè§£å†³äº†æç¤ºæ–¹æ³•çš„ä¿¡æ¯ä¸¢å¤±é—®é¢˜ï¼ˆå¯¹æ¯”å›¾3(a)(b)ï¼‰ã€‚
   
2. **åˆ†å±‚ç‰¹å¾æå–æœºåˆ¶**ï¼šè®¾è®¡åŒ…å«å±€éƒ¨å­å›¾ç‰¹å¾ï¼ˆç¬¬3.1.1èŠ‚ï¼‰ä¸å…¨å±€å›¾åµŒå…¥ï¼ˆç¬¬3.1.2èŠ‚ï¼‰çš„æ··åˆè¡¨ç¤ºï¼Œé€šè¿‡æ»åç‰¹å¾æå–å™¨ï¼ˆç¬¬3.1.3èŠ‚ï¼‰ç”Ÿæˆç»´åº¦ä¸º$R^{CÃ—(1+M)Ã—|H|Ã—(F+F')}$çš„æ—¶ç©ºä»¤ç‰Œï¼Œæ¯”UniST[34]çš„çº¯æç¤ºæ–¹æ³•å¤šä¿ç•™$F'$ç»´å…¨å±€ç‰¹å¾ã€‚

3. **åŸºäºtåˆ†å¸ƒçš„æ¦‚ç‡é¢„æµ‹å¤´**ï¼šå¼•å…¥å«è‡ªç”±åº¦ã€å‡å€¼ã€å°ºåº¦ä¸‰ä¸ªå¯å­¦ä¹ å‚æ•°çš„åˆ†å¸ƒå¤´ï¼ˆç¬¬3èŠ‚ï¼‰ï¼Œé€šè¿‡è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ï¼ˆå…¬å¼5ï¼‰å®ç°æ¦‚ç‡é¢„æµ‹ï¼Œç›¸æ¯”Lag-Llama[22]çš„ç‚¹é¢„æµ‹åœ¨CRPSæŒ‡æ ‡ä¸Šæå‡23%ï¼ˆè¡¨6ï¼‰ã€‚

4. **åˆ†å¸ƒå¯¹é½çš„åŸŸè‡ªé€‚åº”æ–¹æ³•**ï¼šæå‡ºç»“åˆä½ç§©è‡ªé€‚åº”ï¼ˆLoRAï¼‰å’ŒKLæ•£åº¦å¯¹é½çš„è¿ç§»æœºåˆ¶ï¼ˆç¬¬3.3èŠ‚ï¼‰ï¼Œåœ¨å…¬å¼3ä¸­é€šè¿‡ä½ç§©çŸ©é˜µ$B_qA_q$æ›´æ–°æ³¨æ„åŠ›å‚æ•°ï¼Œä»…éœ€è®­ç»ƒ0.52Må‚æ•°ï¼ˆè¡¨9ï¼‰å³å¯å®ç°è·¨åŸå¸‚é€‚é…ã€‚

### æ–¹æ³•æ¦‚è¿°
æ¨¡å‹æ¶æ„åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼ˆå›¾2ï¼‰ï¼š
1. **åˆ†å±‚ç‰¹å¾æå–å™¨**ï¼š
   - kè·³å­å›¾æå–å™¨é€šè¿‡å…¬å¼$N_k(v) = {uâˆˆV|d(u,v)â‰¤k}$å®šä¹‰é‚»åŸŸï¼Œç”Ÿæˆ$NÃ—TÃ—(MÃ—F)$ç‰¹å¾å›¾ï¼ˆç¬¬3.1.1èŠ‚ï¼‰
   - å…¨å±€å›¾åµŒå…¥è®¡ç®—å½’ä¸€åŒ–æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ$L_{norm}=D^{-1/2}LD^{-1/2}=U\Lambda U^T$çš„ç‰¹å¾å‘é‡ï¼ˆç¬¬3.1.2èŠ‚ï¼‰
   - æ»åæå–å™¨å®šä¹‰æ˜ å°„$x_tâ†¦\lambda_tâˆˆR^{|H|Ã—F}$ï¼Œå…¶ä¸­$\lambda_t[j]=x_{t-H[j]}$ï¼ˆç¬¬3.1.3èŠ‚ï¼‰

2. **LLMéª¨å¹²ç½‘ç»œ**ï¼š
   - åŸºäºMistral[12]çš„decoder-onlyæ¶æ„ï¼Œé‡‡ç”¨RMSNorm[37]å’ŒRoPE[25]ä½ç½®ç¼–ç ï¼ˆç¬¬3.2èŠ‚ï¼‰
   - é€šè¿‡Flash-Attention-2[7]å®ç°å› æœæ©ç æ³¨æ„åŠ›ï¼Œè¾“å‡ºåˆ†å¸ƒå‚æ•°$\phi$

3. **åŸŸè‡ªé€‚åº”æ¨¡å—**ï¼š
   - å¯¹æŸ¥è¯¢ã€é”®ã€å€¼çŸ©é˜µåº”ç”¨LoRAæ›´æ–°ï¼š$q=W_qh+B_qA_qh$ï¼ˆå…¬å¼3ï¼‰
   - é€šè¿‡å…¬å¼4çš„KLæ•£åº¦$L_{alignment}$å¯¹é½æºåŸŸä¸ç›®æ ‡åŸŸçš„tåˆ†å¸ƒå‚æ•°
   - æ€»æŸå¤±å‡½æ•°ä¸º$L_{total}=\lambda_1 NLL+(1-\lambda_1)L_{alignment}$ï¼ˆå…¬å¼5ï¼‰

### å®éªŒè¯´æ˜
**è¯„ä¼°æŒ‡æ ‡**ï¼šé‡‡ç”¨MAEã€RMSEã€MAPEï¼ˆç¬¬4.2èŠ‚ï¼‰å’ŒCRPSï¼ˆç”¨äºæ¦‚ç‡è¯„ä¼°ï¼‰ã€‚

**æ•°æ®é›†**ï¼š
- é¢„è®­ç»ƒï¼šPeMS03/04/07/08ï¼ˆ26,208æ—¶é—´æ­¥ï¼‰
- å°‘æ ·æœ¬ï¼šMETR-LAï¼ˆ34,272æ­¥ï¼‰ã€PEMS-Bayï¼ˆ52,116æ­¥ï¼‰
- é›¶æ ·æœ¬ï¼šCrowdï¼ˆ9,420æ­¥ï¼‰ã€Brusselsï¼ˆ12,672æ­¥ï¼‰
ï¼ˆè¯¦è§è¡¨1ï¼‰

**åŸºçº¿æ–¹æ³•**ï¼š
- ç›‘ç£å­¦ä¹ ï¼šGMAN[35]ã€MTGNN[31]ã€GTS[23]ã€STEP[24]
- LLMæ–¹æ³•ï¼šFlashST[16]ã€UniST[34]ã€Lag-Llama[22]

**å®éªŒé…ç½®**ï¼š
è®ºæ–‡æœªæ˜ç¡®è¯´æ˜GPUé…ç½®ï¼Œä½†æåŠé‡‡ç”¨æ‰¹é‡å¤§å°64ï¼ˆè¡¨9ï¼‰ï¼Œä½¿ç”¨Mistral[12]å’ŒLlama2[22]ä½œä¸ºéª¨å¹²ç½‘ç»œï¼ˆè¡¨12ï¼‰ï¼Œåœ¨åŸŸé€‚åº”å®éªŒä¸­é‡‡ç”¨$râ‰ªmin(d,k)$çš„ç§©è¶…å‚æ•°ï¼ˆç¬¬3.3.1èŠ‚ï¼‰ã€‚

### æ”¹è¿›å»ºè®®å’Œæœªæ¥ç ”ç©¶æ–¹å‘
**å·²æ‰¿è®¤çš„å±€é™æ€§**ï¼š
1. kè·³å­å›¾æå–å™¨å­˜åœ¨ç²¾åº¦ä¸é‚»åŸŸå¤§å°çš„æƒè¡¡ï¼ˆè¡¨10ï¼‰ï¼Œè¿‡å¤§$k$å€¼å¯èƒ½å¼•å…¥å™ªå£°
2. åŸŸé€‚åº”æ€§èƒ½å—æº-ç›®æ ‡åŸŸåˆ†å¸ƒå·®å¼‚å½±å“ï¼Œå¦‚PeMS04â†’PEMS-Bayçš„é€‚åº”æ•ˆæœæ¯”METR-LAâ†’PEMS-Bayé«˜14%ï¼ˆè¡¨8ï¼‰

**æ½œåœ¨æ”¹è¿›æ–¹å‘**ï¼š
1. **åŠ¨æ€å›¾ç»“æ„å»ºæ¨¡**ï¼šå½“å‰å‡è®¾é™æ€æ‹“æ‰‘ï¼ˆç¬¬2èŠ‚ï¼‰ï¼Œå¯å¼•å…¥åŠ¨æ€é‚»æ¥çŸ©é˜µé€‚åº”é“è·¯ç½‘ç»œå˜åŒ–ï¼Œç»“åˆæ—¶ç©ºå›¾æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¯è¡Œæ€§è¾ƒé«˜
   
2. **å¤šæ¨¡æ€èåˆ**ï¼šä»…ä½¿ç”¨äº¤é€šé€Ÿåº¦æŒ‡æ ‡ï¼ˆç¬¬4.1èŠ‚ï¼‰ï¼Œå¯èåˆå¤©æ°”ã€äº‹ä»¶ç­‰å¤–éƒ¨å› å­ï¼Œé€šè¿‡è·¨æ¨¡æ€å¯¹é½æŸå¤±å¢å¼ºæ³›åŒ–æ€§

3. **è®¡ç®—æ•ˆç‡ä¼˜åŒ–**ï¼šè™½å‚æ•°é‡ä»…1.32%ï¼ˆè¡¨9ï¼‰ï¼Œä½†å¯æ¢ç´¢ç¥ç»æ¶æ„æœç´¢è‡ªåŠ¨ç¡®å®šæœ€ä¼˜$k$å€¼å’ŒLoRAç§©ï¼Œå¹³è¡¡è®¡ç®—æˆæœ¬ä¸é¢„æµ‹ç²¾åº¦

4. **åˆ†å¸ƒå¤´è¡¨è¾¾èƒ½åŠ›**ï¼šä½œè€…å»ºè®®æœªæ¥ç ”ç©¶å¯è¯„ä¼°tåˆ†å¸ƒå¤´çš„è¡¨è¾¾æé™ï¼ˆç¬¬5èŠ‚ï¼‰ï¼Œè€ƒè™‘æ··åˆå¯†åº¦ç½‘ç»œæˆ–å½’ä¸€åŒ–æµå¢å¼ºåˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›

---

## 3. Zero-Shot Temporal Interaction Localization for Egocentric Videos

### åŸºæœ¬ä¿¡æ¯
- **ä½œè€…**: Erhang Zhang, Junyi Ma, Yin-Dong Zheng, Yixuan Zhou, Hesheng Wang
- **arXiv ID**: [oai:arXiv.org:2506.03662v4](https://arxiv.org/abs/2506.03662)
- **å‘å¸ƒæ—¥æœŸ**: Tue, 18 Nov 2025 00:00:00 -0500
- **åˆ†ç±»**: cs.CV, cs.AI, cs.RO
- **è®ºæ–‡é“¾æ¥**: [arXivé“¾æ¥](https://arxiv.org/abs/2506.03662)
- **æºç åœ°å€**: [æŸ¥çœ‹æºç ](https://github.com/irmvlab/egoloc.)

            ### åŸæ–‡æ‘˜è¦
            arXiv:2506.03662v4 Announce Type: replace-cross  Abstract: Locating human-object interaction (HOI) actions within video serves as the foundation for multiple downstream tasks, such as human behavior analysis and human-robot skill transfer. Current temporal action localization methods typically rely on annotated action and object categories of interactions for optimization, which leads to domain bias and low deployment efficiency. Although some recent works have achieved zero-shot temporal action localization (ZS-TAL) with large vision-language models (VLMs), their coarse-grained estimations and open-loop pipelines hinder further performance improvements for temporal interaction localization (TIL). To address these issues, we propose a novel zero-shot TIL approach dubbed EgoLoc to locate the timings of grasp actions for human-object interaction in egocentric videos. EgoLoc introduces a self-adaptive sampling strategy to generate reasonable visual prompts for VLM reasoning. By absorbing both 2D and 3D observations, it directly samples high-quality initial guesses around the possible contact/separation timestamps of HOI according to 3D hand velocities, leading to high inference accuracy and efficiency. In addition, EgoLoc generates closed-loop feedback from visual and dynamic cues to further refine the localization results. Comprehensive experiments on the publicly available dataset and our newly proposed benchmark demonstrate that EgoLoc achieves better temporal interaction localization for egocentric videos compared to state-of-the-art baselines. We have released our code and relevant data as open-source at https://github.com/IRMVLab/EgoLoc.


            
### AIåˆ†æï¼ˆåŸºäºè®ºæ–‡æ­£æ–‡ï¼‰
### è®ºæ–‡æ¦‚è¦
æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºEgoLocçš„é›¶æ ·æœ¬æ—¶åºäº¤äº’å®šä½æ–¹æ³•ï¼Œä¸“æ³¨äºåœ¨ç¬¬ä¸€äººç§°è§†è§’è§†é¢‘ä¸­å®šä½äººæ‰‹ä¸ç‰©ä½“æ¥è§¦å’Œåˆ†ç¦»çš„æ—¶é—´æˆ³ã€‚è¯¥æ–¹æ³•é€šè¿‡èåˆ2D RGBå›¾åƒå’Œ3Dæ·±åº¦è§‚æµ‹æ•°æ®æå–3Dæ‰‹éƒ¨é€Ÿåº¦ï¼Œè®¾è®¡äº†è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ç”Ÿæˆé«˜è´¨é‡åˆå§‹å€™é€‰å¸§ï¼Œå¹¶å¼•å…¥åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„é—­ç¯åé¦ˆæœºåˆ¶ä¼˜åŒ–å®šä½ç»“æœã€‚å®éªŒåœ¨å…¬å¼€æ•°æ®é›†EgoPAT3D-DTå’Œè‡ªå»ºåŸºå‡†DeskTILä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•åœ¨å®šä½ç²¾åº¦å’Œæ¨ç†æ•ˆç‡ä¸Šçš„ä¼˜åŠ¿ã€‚

---

### ç ”ç©¶åŠ¨æœº
ç°æœ‰æ—¶åºåŠ¨ä½œå®šä½æ–¹æ³•ä¸»è¦å­˜åœ¨å››æ–¹é¢å±€é™æ€§ï¼ˆç¬¬IèŠ‚ï¼‰ï¼š  
1. **ç²’åº¦ä¸è¶³**ï¼šä¼ ç»ŸTALæ–¹æ³•å…³æ³¨åŠ¨ä½œè¾¹ç•Œè€Œéç»†ç²’åº¦çš„æ‰‹-ç‰©æ¥è§¦çŠ¶æ€ï¼Œæ— æ³•ç²¾ç¡®å®šä½æ¥è§¦/åˆ†ç¦»æ—¶åˆ»ï¼ˆå›¾Iå¯¹æ¯”ï¼‰ã€‚  
2. **æ³›åŒ–èƒ½åŠ›å¼±**ï¼šå¤šæ•°æ–¹æ³•éœ€ä¾èµ–åŠ¨ä½œ-ç‰©ä½“ç±»åˆ«æ ‡æ³¨è¿›è¡Œè®­ç»ƒï¼Œè€Œé›¶æ ·æœ¬TALæ–¹æ³•ï¼ˆå¦‚T-PIVOTï¼‰ä»å—é™äºæ–‡æœ¬æç¤ºä¸­çš„é¢„å®šä¹‰ç±»åˆ«ï¼ˆç¬¬II-AèŠ‚å¼•ç”¨[7][8]ï¼‰ã€‚  
3. **æ„ŸçŸ¥ç»´åº¦å•ä¸€**ï¼šä»…ä½¿ç”¨2D RGBå›¾åƒï¼Œå¿½ç•¥äº†3Dç©ºé—´è¿åŠ¨ä¿¡æ¯å¯¹äº¤äº’ç†è§£çš„å¢å¼ºä½œç”¨ï¼ˆç¬¬IèŠ‚æŒ‡å‡º3Dè§‚æµ‹å¯æä¾›ç»å¯¹å°ºåº¦ä¿¡æ¯ï¼‰ã€‚  
4. **å¼€ç¯æ¶æ„ç¼ºé™·**ï¼šç°æœ‰æ–¹æ³•å¤šä¸ºç«¯åˆ°ç«¯å¼€ç¯æ¡†æ¶ï¼Œç¼ºä¹å¯¹å®šä½ç»“æœçš„è‡ªæˆ‘è¯„ä¼°ä¸ä¿®æ­£æœºåˆ¶ï¼ˆç¬¬IèŠ‚å¼ºè°ƒé—­ç¯è®¾è®¡å¯é™ä½ä¸ç¡®å®šæ€§ï¼‰ã€‚  

é’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºå°†æ—¶åºäº¤äº’å®šä½ä½œä¸ºTALçš„ç»†ç²’åº¦æ‰©å±•ä»»åŠ¡ï¼Œé‡ç‚¹è§£å†³ä»¥æŠ“å–åŠ¨ä½œä¸ºä»£è¡¨çš„HOIè¿‡ç¨‹çš„ä¸‰é˜¶æ®µåˆ’åˆ†ï¼ˆæ¥è§¦å‰ã€æ¥è§¦ä¸­ã€æ¥è§¦åï¼‰çš„ç²¾ç¡®æ—¶é—´å®šä½éœ€æ±‚ã€‚

---

### æ ¸å¿ƒè´¡çŒ®ä¸åˆ›æ–°ç‚¹
1. **é›¶æ ·æœ¬æ—¶åºäº¤äº’å®šä½èŒƒå¼**  
   - æå‡ºé¦–ä¸ªèåˆ2D-3Dæ„ŸçŸ¥çš„é›¶æ ·æœ¬TILæ¡†æ¶EgoLocï¼Œä½¿ç”¨é€šç”¨æ–‡æœ¬æç¤ºå®ç°æ— éœ€åŠ¨ä½œ-ç‰©ä½“ç‰¹å®šæè¿°çš„è®­ç»ƒä¸æ¨ç†ï¼ˆç¬¬III-BèŠ‚ï¼‰ã€‚åŒºåˆ«äºOVTAL[8]ç­‰ä¾èµ–ç±»åˆ«æè¿°çš„æ–¹æ³•ï¼ŒEgoLocé€šè¿‡ç»Ÿä¸€æç¤ºâ€œGrasping the objectâ€è¦†ç›–å¤šæ ·äº¤äº’åœºæ™¯ã€‚

2. **3Dæ‰‹éƒ¨é€Ÿåº¦å¼•å¯¼çš„è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥**  
   - åˆ›æ–°æ€§åœ°å°†3Dæ‰‹éƒ¨é€Ÿåº¦åˆ†æå¼•å…¥æ—¶åºå®šä½ï¼ˆç¬¬III-CèŠ‚ï¼‰ã€‚é€šè¿‡Grounded SAM[34]æå–2Dæ‰‹éƒ¨æ©ç ï¼Œç»“åˆæ·±åº¦å›¾åƒä¸ç‚¹äº‘é…å‡†è®¡ç®—å…¨å±€åæ ‡ç³»ä¸‹çš„3Dæ‰‹éƒ¨é€Ÿåº¦ï¼ˆå›¾IIIï¼‰ã€‚åŸºäºâ€œæ¥è§¦/åˆ†ç¦»æ—¶åˆ»æ‰‹éƒ¨é€Ÿåº¦æœ€ä½â€çš„ç‰©ç†å…ˆéªŒï¼Œä»ä½é€Ÿå¸§ä¸­é‡‡æ ·é”šå¸§æ„å»ºç½‘æ ¼å›¾åƒä½œä¸ºè§†è§‰æç¤ºï¼ˆå…¬å¼ï¼š$V_t = (H_{t+1}^{3D,glob} - H_t^{3D,glob})/Î´$ï¼‰ã€‚

3. **é—­ç¯åé¦ˆæœºåˆ¶**  
   - è®¾è®¡åŒåˆ¤åˆ«å™¨é—­ç¯ç³»ç»Ÿï¼ˆç¬¬III-EèŠ‚ï¼‰ï¼š  
     - VLMåˆ¤åˆ«å™¨ï¼šåŸºäºè§†è§‰æç¤ºåˆ¤æ–­æ‰‹-ç‰©æ¥è§¦çŠ¶æ€ï¼ˆå›¾II(c)æç¤ºâ€œDetermine whether...in obvious contactâ€ï¼‰ã€‚  
     - é€Ÿåº¦åˆ¤åˆ«å™¨ï¼šéªŒè¯ä¼°è®¡æ—¶åˆ»çš„æ‰‹éƒ¨é€Ÿåº¦æ˜¯å¦ä½äºå…¨å±€æœ€ä½çš„$Î¼_{vel}$%åŒºé—´ï¼ˆé»˜è®¤30%ï¼‰ã€‚  
   - é€šè¿‡åŠ¨æ€é‡é‡‡æ ·ç­–ç•¥ï¼ˆå¦‚â‘ Noæ—¶åœ¨$\hat{T}_c$åé‡æ–°é€‰æ‹©å…³é”®å¸§ï¼‰å®ç°å®šä½ç»“æœè¿­ä»£ä¼˜åŒ–ã€‚

4. **é«˜æ•ˆå•æ­¥æ¨ç†æ¶æ„**  
   - åˆ©ç”¨é«˜è´¨é‡åˆå§‹å€™é€‰å¸§å®ç°VLMå•æ­¥æ¨ç†ï¼Œæ˜¾è‘—æå‡æ•ˆç‡ã€‚å¯¹æ¯”T-PIVOT[7]çš„å¤šæ¬¡è¿­ä»£ï¼ŒEgoLocåœ¨EgoPAT3D-DTä¸Šå‡å°‘1.3å€æ¨ç†æ—¶é—´ï¼ˆç¬¬IV-DèŠ‚ï¼‰ã€‚

---

### æ–¹æ³•æ¦‚è¿°
**æ•´ä½“æµç¨‹**ï¼ˆå›¾IIï¼‰åŒ…å«ä¸‰é˜¶æ®µï¼š  
1. **è‡ªé€‚åº”é‡‡æ ·**ï¼ˆç¬¬III-CèŠ‚ï¼‰  
   - è¾“å…¥ï¼šRGBåºåˆ—$I=\{I_t\}_1^N$ä¸æ·±åº¦å›¾åƒ$D=\{D_t\}_1^N$ã€‚  
   - æ‰‹éƒ¨è¿åŠ¨æå–ï¼šé€šè¿‡Grounded SAMè·å–2Dæ‰‹éƒ¨ä½ç½®$H_t^{2D}$ï¼Œç»“åˆç›¸æœºå†…å‚ä¸æ·±åº¦å›¾è®¡ç®—ç›¸æœºåæ ‡ç³»ä¸‹çš„3Dä½ç½®$H_t^{3D,cam}$ï¼Œå†é€šè¿‡ç‚¹äº‘é…å‡†çŸ©é˜µ$M_t$è½¬æ¢è‡³å…¨å±€åæ ‡ç³»$H_t^{3D,glob}$ã€‚  
   - å…³é”®å¸§é€‰æ‹©ï¼šæå–3Dæ‰‹éƒ¨é€Ÿåº¦$V_t$ï¼Œé€‰å–å‰$N_{key}$ä¸ªæœ€ä½é€Ÿå¸§ï¼ˆæ¥è§¦æ—¶åˆ»ä»å‰åŠæ®µè§†é¢‘é€‰æ‹©ï¼Œåˆ†ç¦»æ—¶åˆ»ä»æ¥è§¦åæ®µé€‰æ‹©ï¼‰ã€‚ä»¥é”šå¸§$I_{init}$ä¸ºä¸­å¿ƒå¯¹ç§°é‡‡æ ·$N_{adj}^2-1$é‚»å¸§æ„å»ºç½‘æ ¼å›¾åƒ$G$ã€‚

2. **VLMæ¨ç†æ¨¡å—**ï¼ˆç¬¬III-DèŠ‚ï¼‰  
   - è§†è§‰æç¤ºï¼šç½‘æ ¼å›¾åƒ$G$ï¼ˆä¾‹å¦‚$N_{adj}=3$æ—¶åŒ…å«9å¸§ï¼‰ã€‚  
   - æ–‡æœ¬æç¤ºï¼šâ€œChoose the number that is closest to the moment when â€˜Grasping the objectâ€™ started/endedâ€ã€‚  
   - è¾“å‡ºï¼šVLMç›´æ¥é¢„æµ‹ç½‘æ ¼ä¸­å¯¹åº”æ¥è§¦/åˆ†ç¦»æ—¶åˆ»çš„å¸§ç¼–å·ï¼Œå¾—åˆ°åˆè½®ä¼°è®¡$\hat{T}_c$ã€$\hat{T}_s$ã€‚

3. **é—­ç¯åé¦ˆ**ï¼ˆç¬¬III-EèŠ‚ï¼‰  
   - è§†è§‰æ ¡éªŒï¼šVLMåˆ¤åˆ«å™¨åˆ†æ$\hat{T}_c$å¸§å›¾åƒï¼Œåˆ¤æ–­æ‰‹-ç‰©æ˜¯å¦æ˜æ˜¾æ¥è§¦ï¼ˆâ‘ Noåˆ™è§¦å‘é‡é‡‡æ ·ï¼‰ã€‚  
   - åŠ¨æ€æ ¡éªŒï¼šé€Ÿåº¦åˆ¤åˆ«å™¨æ£€æŸ¥$\hat{T}_c$å¸§é€Ÿåº¦æ˜¯å¦å±äºå…¨å±€æœ€ä½30%ï¼ˆâ‘¡Noåˆ™çº¦æŸé‡é‡‡æ ·ä»…é€‰æ‹©æ›´ä½é€Ÿå¸§ï¼‰ã€‚  
   - é‡é‡‡æ ·ä¼˜åŒ–ï¼šæ ¹æ®æ ¡éªŒç»“æœè°ƒæ•´å…³é”®å¸§é€‰æ‹©èŒƒå›´ï¼Œç”Ÿæˆ refined ä¼°è®¡$\hat{T}_c^*$ã€$\hat{T}_s^*$ã€‚

---

### å®éªŒè¯´æ˜
**è¯„ä¼°æŒ‡æ ‡**ï¼ˆç¬¬IV-CèŠ‚ï¼‰  
- ä¼ ç»ŸæŒ‡æ ‡ï¼šMoFï¼ˆå¸§çº§é˜¶æ®µåˆ†ç±»å‡†ç¡®ç‡ï¼‰ã€IoUï¼ˆæ¥è§¦æ®µé‡å åº¦ï¼‰ã€‚  
- ç»†ç²’åº¦æŒ‡æ ‡ï¼šSRï¼ˆå®¹å·®Î³å¸§å†…çš„æˆåŠŸç‡ï¼‰ã€MAEï¼ˆä¼°è®¡ä¸çœŸå€¼å¸§æ•°ç»å¯¹è¯¯å·®ï¼‰ã€‚

**æ•°æ®é›†**  
- EgoPAT3D-DTï¼š30 FPSï¼ŒåŒ…å«ç²¾ç»†HOIåºåˆ—[36]ã€‚  
- DeskTILï¼šè‡ªå»ºåŸºå‡†ï¼Œ5 FPSï¼ŒåŒ…å«3ç§æ¡Œé¢ clutter ç­‰çº§ï¼ˆå›¾IVï¼‰ï¼Œæ¯ç­‰çº§50æ®µè§†é¢‘ã€‚

**åŸºçº¿æ–¹æ³•**  
- Greedy VLMï¼šç›´æ¥ä½¿ç”¨å…¨å¸§ç½‘æ ¼å›¾åƒè¾“å…¥VLMã€‚  
- T-PIVOT[7]ï¼šè¿­ä»£å¼é›¶æ ·æœ¬TALæ–¹æ³•ï¼Œé€‚é…ä¸ºTILä»»åŠ¡ï¼ˆ$N_{adj}=2,3,4$ï¼‰ã€‚

**å®éªŒé…ç½®**  
- ç¡¬ä»¶ï¼šè®ºæ–‡æœªæ˜ç¡®è¯´æ˜GPUå‹å·ä¸æ•°é‡ã€‚  
- VLMï¼šé»˜è®¤ä½¿ç”¨GPT-4oï¼Œå¯¹æ¯”å®éªŒåŒ…æ‹¬GPT-4o miniä¸GPT-4 Turboã€‚  
- è¶…å‚æ•°ï¼š$N_{key}=4$ï¼Œ$Î¼_{vel}=30\%$ï¼Œæ¯ä¸ªè§†é¢‘è¿›è¡Œ5æ¬¡è¯•éªŒå–å¹³å‡ã€‚

---

### æ”¹è¿›å»ºè®®å’Œæœªæ¥ç ”ç©¶æ–¹å‘
**å·²å£°æ˜çš„å±€é™æ€§**  
- å½“å‰å‡è®¾æ¥è§¦æ—¶åˆ»ä½äºè§†é¢‘å‰åŠæ®µï¼ˆç¬¬VèŠ‚ï¼‰ï¼Œé™åˆ¶äº†åœ¨é•¿æœªä¿®å‰ªè§†é¢‘ä¸­çš„åº”ç”¨ã€‚  
- ä»…é’ˆå¯¹æŠ“å–åŠ¨ä½œéªŒè¯ï¼Œæœªæ‰©å±•åˆ°æ¨ã€æ‹‰ç­‰å¤æ‚äº¤äº’ç±»å‹ã€‚

**æ½œåœ¨å±€é™æ€§ä¸æ”¹è¿›å»ºè®®**  
1. **å¤šäº¤äº’ç±»å‹æ³›åŒ–**  
   - é—®é¢˜ï¼šé€šç”¨æç¤ºè¯å¯¹éæŠ“å–åŠ¨ä½œï¼ˆå¦‚æ”¾ç½®ç‰©ä½“ï¼‰çš„é€‚åº”æ€§æœªéªŒè¯ã€‚  
   - æ”¹è¿›ï¼šå¼•å…¥äº¤äº’ç±»å‹æ„ŸçŸ¥çš„æç¤ºè¯ç”Ÿæˆæ¨¡å—ï¼Œç»“åˆLLMåŠ¨æ€ç”Ÿæˆåœºæ™¯é€‚é…çš„æ–‡æœ¬æè¿°ã€‚  
   - å¯è¡Œæ€§ï¼šåˆ©ç”¨OVTAL[8]çš„LLMæè¿°ç”Ÿæˆæ€è·¯ï¼Œéœ€å¢åŠ å°‘é‡ç¤ºä¾‹å¾®è°ƒã€‚

2. **é•¿è§†é¢‘å¤„ç†æ•ˆç‡**  
   - é—®é¢˜ï¼šå½“å‰éœ€é¢„å…ˆæˆªå–å«å•ä¸€HOIçš„è§†é¢‘ç‰‡æ®µã€‚  
   - æ”¹è¿›ï¼šé›†æˆè½»é‡çº§åŠ¨ä½œæ£€æµ‹æ¨¡å—ï¼ˆå¦‚UnLoc[17]ï¼‰è¿›è¡Œç²—ç²’åº¦å®šä½ï¼Œå†åº”ç”¨EgoLocè¿›è¡Œç»†ç²’åº¦ä¼˜åŒ–ã€‚  
   - å¯è¡Œæ€§ï¼šå¯é€šè¿‡ä¸¤é˜¶æ®µ pipeline å®ç°ï¼Œè®¡ç®—æˆæœ¬å¯æ§ã€‚

3. **3Dæ„ŸçŸ¥ä¾èµ–æ€§**  
   - é—®é¢˜ï¼šä¾èµ–æ·±åº¦ç›¸æœºæ•°æ®é™åˆ¶åº”ç”¨åœºæ™¯ã€‚  
   - æ”¹è¿›ï¼šå¼€å‘å•ç›®3Dæ‰‹éƒ¨å§¿æ€ä¼°è®¡æ¨¡å—æ›¿ä»£æ·±åº¦è¾“å…¥ï¼Œç»“åˆæ—¶åºå¹³æ»‘çº¦æŸä¿è¯é€Ÿåº¦ä¼°è®¡ç¨³å®šæ€§ã€‚  
   - å¯è¡Œæ€§ï¼šç°æœ‰Monocular 3D Pose Estimationæ–¹æ³•ï¼ˆå¦‚MetraBSï¼‰å¯æä¾›åŸºç¡€æ”¯æŒï¼Œä½†éœ€éªŒè¯ç²¾åº¦æŸå¤±ã€‚

4. **é—­ç¯æœºåˆ¶æ‰©å±•**  
   - é—®é¢˜ï¼šå½“å‰ä»…ä½¿ç”¨å•è½®åé¦ˆï¼Œå¤šè½®ä¼˜åŒ–æ”¶ç›Šé€’å‡ã€‚  
   - æ”¹è¿›ï¼šè®¾è®¡è‡ªé€‚åº”ç»ˆæ­¢å‡†åˆ™ï¼ŒåŸºäºä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆå¦‚[37]ï¼‰åŠ¨æ€æ§åˆ¶åé¦ˆè½®æ¬¡ã€‚  
   - å¯è¡Œæ€§ï¼šéœ€æ‰©å±•å®éªŒéªŒè¯å¤šè½®åé¦ˆçš„ç²¾åº¦-æ•ˆç‡æƒè¡¡ã€‚

---

## 4. FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning

### åŸºæœ¬ä¿¡æ¯
- **ä½œè€…**: Jiajun Cao, Qizhe Zhang, Peidong Jia, Xuhui Zhao, Bo Lan, Xiaoan Zhang, Zhuo Li, Xiaobao Wei, Sixiang Chen, Liyun Li, Xianming Liu, Ming Lu, Yang Wang, Shanghang Zhang
- **arXiv ID**: [oai:arXiv.org:2507.23318v4](https://arxiv.org/abs/2507.23318)
- **å‘å¸ƒæ—¥æœŸ**: Tue, 18 Nov 2025 00:00:00 -0500
- **åˆ†ç±»**: cs.CV, cs.AI
- **è®ºæ–‡é“¾æ¥**: [arXivé“¾æ¥](https://arxiv.org/abs/2507.23318)

            ### åŸæ–‡æ‘˜è¦
            arXiv:2507.23318v4 Announce Type: replace-cross  Abstract: Vision-Language-Action (VLA) models have demonstrated significant potential in complex scene understanding and action reasoning, leading to their increasing adoption in end-to-end autonomous driving systems. However, the long visual tokens of VLA models greatly increase computational costs. Current visual token pruning methods in Vision-Language Models (VLM) rely on either visual token similarity or visual-text attention, but both have shown poor performance in autonomous driving scenarios. Given that human drivers concentrate on relevant foreground areas while driving, we assert that retaining visual tokens containing this foreground information is essential for effective decision-making. Inspired by this, we propose FastDriveVLA, a novel reconstruction-based vision token pruning framework designed specifically for autonomous driving. FastDriveVLA includes a plug-and-play visual token pruner called ReconPruner, which prioritizes foreground information through MAE-style pixel reconstruction. A novel adversarial foreground-background reconstruction strategy is designed to train ReconPruner for the visual encoder of VLA models. Once trained, ReconPruner can be seamlessly applied to different VLA models with the same visual encoder without retraining. To train ReconPruner, we also introduce a large-scale dataset called nuScenes-FG, consisting of 241K image-mask pairs with annotated foreground regions. Our approach achieves state-of-the-art results on the nuScenes open-loop planning benchmark across different pruning ratios.


            
### AIåˆ†æï¼ˆåŸºäºè®ºæ–‡æ­£æ–‡ï¼‰
### è®ºæ–‡æ¦‚è¦
æœ¬æ–‡æå‡ºFastDriveVLAï¼Œä¸€ç§åŸºäºé‡å»ºçš„è§†è§‰ä»¤ç‰Œå‰ªææ¡†æ¶ï¼Œä¸“é—¨é’ˆå¯¹ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶VLAæ¨¡å‹è®¾è®¡ã€‚è¯¥æ–¹æ³•é€šè¿‡MAEé£æ ¼çš„åƒç´ é‡å»ºè®­ç»ƒè½»é‡çº§æ’ä»¶å¼å‰ªæå™¨ReconPrunerï¼Œå¹¶å¼•å…¥å¯¹æŠ—æ€§å‰æ™¯-èƒŒæ™¯é‡å»ºç­–ç•¥å¢å¼ºå‰æ™¯æ„ŸçŸ¥èƒ½åŠ›ã€‚åœ¨nuSceneså¼€ç¯è§„åˆ’åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒå‰ªææ¯”ä¾‹ä¸‹å‡ä¼˜äºç°æœ‰æ³¨æ„åŠ›åŸºå’Œç›¸ä¼¼æ€§åŸºå‰ªææ–¹æ³•ï¼Œåœ¨50%å‰ªææ¯”ä¾‹ä¸‹å®ç°æœ€ä½³æ€§èƒ½å¹³è¡¡ã€‚

### ç ”ç©¶åŠ¨æœº
ç°æœ‰VLAæ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­é¢ä¸´æ˜¾è‘—è®¡ç®—å¼€é”€é—®é¢˜ï¼Œä¸»è¦æºäºå¤§é‡è§†è§‰ä»¤ç‰Œçš„å¤„ç†ã€‚å½“å‰è§†è§‰ä»¤ç‰Œå‰ªææ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼šæ³¨æ„åŠ›åŸºæ–¹æ³•ï¼ˆå¦‚FastVã€SparseVLMï¼‰å’Œç›¸ä¼¼æ€§åŸºæ–¹æ³•ï¼ˆå¦‚VisPrunerã€DivPruneï¼‰ã€‚å¦‚ç¬¬2èŠ‚æ‰€è¿°ï¼Œæ³¨æ„åŠ›åŸºæ–¹æ³•ä¸¥é‡ä¾èµ–æ–‡æœ¬-è§†è§‰å¯¹é½è´¨é‡ï¼Œä½†åœ¨è‡ªåŠ¨é©¾é©¶ä»»åŠ¡ä¸­ï¼Œæ–‡æœ¬æŒ‡ä»¤é€šå¸¸å›ºå®šä¸”ç®€æ´ï¼Œæ— æ³•æä¾›æœ‰æ•ˆçš„ä»¤ç‰Œé€‰æ‹©æŒ‡å¯¼ã€‚ç›¸ä¼¼æ€§åŸºæ–¹æ³•åˆ™éš¾ä»¥å¤„ç†å…·æœ‰æ˜ç¡®å‰æ™¯åŒºåŸŸçš„é©¾é©¶åœºæ™¯ï¼Œå¯èƒ½é”™è¯¯ä¿ç•™ä¸é©¾é©¶ä»»åŠ¡æ— å…³çš„èƒŒæ™¯ä»¤ç‰Œã€‚

ä½œè€…åœ¨ç¬¬2.3èŠ‚æŒ‡å‡ºï¼Œäººç±»é©¾é©¶å‘˜ä¸»è¦å…³æ³¨å‰æ™¯åŒºåŸŸï¼ˆå¦‚è½¦é“ã€è¡Œäººã€è½¦è¾†ï¼‰ï¼Œè€ŒèƒŒæ™¯åŒºåŸŸå¯¹é©¾é©¶å†³ç­–å½±å“æœ‰é™ã€‚è¿™ä¸€è§‚å¯Ÿæ­ç¤ºäº†ç°æœ‰å‰ªææ–¹æ³•ä¸è‡ªåŠ¨é©¾é©¶ä»»åŠ¡éœ€æ±‚ä¹‹é—´çš„æ ¹æœ¬æ€§ä¸åŒ¹é…ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•è¿˜å­˜åœ¨ä¸¤ä¸ªå…³é”®å±€é™ï¼šï¼ˆ1ï¼‰éœ€è¦é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼ˆå¦‚ç¬¬2.2èŠ‚æåˆ°çš„å¤šæ¨¡æ€æŠ•å½±å™¨æ–¹æ³•ï¼‰ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼›ï¼ˆ2ï¼‰ç¼ºä¹ä¸“é—¨é’ˆå¯¹è‡ªåŠ¨é©¾é©¶åœºæ™¯è®¾è®¡çš„ä»¤ç‰Œé‡è¦æ€§è¯„ä¼°æœºåˆ¶ã€‚

### æ ¸å¿ƒè´¡çŒ®ä¸åˆ›æ–°ç‚¹
1. **é‡å»ºåŸºå‰ªææ¡†æ¶**ï¼šæå‡ºé¦–ä¸ªä¸“é—¨é’ˆå¯¹è‡ªåŠ¨é©¾é©¶åœºæ™¯çš„é‡å»ºåŸºè§†è§‰ä»¤ç‰Œå‰ªææ¡†æ¶FastDriveVLAï¼ˆè§ç¬¬3.2èŠ‚ï¼‰ã€‚ä¸ä¾èµ–æ–‡æœ¬-è§†è§‰æ³¨æ„åŠ›æˆ–ä»¤ç‰Œç›¸ä¼¼æ€§çš„ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶é€šè¿‡åƒç´ é‡å»ºè´¨é‡è¯„ä¼°ä»¤ç‰Œé‡è¦æ€§ï¼Œæ›´ç¬¦åˆè‡ªåŠ¨é©¾é©¶ä»»åŠ¡å¯¹å‰æ™¯ä¿¡æ¯çš„ä¾èµ–ç‰¹æ€§ã€‚

2. **ReconPruneræ¶æ„è®¾è®¡**ï¼šè®¾è®¡è½»é‡çº§æ’ä»¶å¼å‰ªæå™¨ReconPrunerï¼ˆæ€»å‚æ•°é‡ä»…0.07Bï¼‰ï¼ŒåŒ…å«PrunerLayerå’ŒScorerä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼ˆè§ç¬¬3.2èŠ‚å›¾3ï¼‰ã€‚PrunerLayeråŸºäºQwen2.5-VL-3Bçš„å•è§£ç å™¨å±‚å®ç°ï¼Œé€šè¿‡å¯å­¦ä¹ æŸ¥è¯¢ä»¤ç‰Œä¸è§†è§‰ä»¤ç‰Œçš„äº¤äº’ç”Ÿæˆèåˆç‰¹å¾ã€‚Scoreré‡‡ç”¨å•å±‚å‰é¦ˆç½‘ç»œï¼ˆæƒé‡å½¢çŠ¶R^{DÃ—1}ï¼‰è®¡ç®—ä»¤ç‰Œæ˜¾è‘—æ€§åˆ†æ•°ã€‚

3. **å¯¹æŠ—æ€§å‰æ™¯-èƒŒæ™¯é‡å»ºç­–ç•¥**ï¼šåˆ›æ–°æ€§åœ°å¼•å…¥å¯¹æŠ—æ€§è®­ç»ƒæœºåˆ¶ï¼ˆè§ç¬¬3.3èŠ‚ï¼‰ï¼Œè¦æ±‚æ¨¡å‹åŒæ—¶é‡å»ºå‰æ™¯å’ŒèƒŒæ™¯åŒºåŸŸã€‚è¯¥ç­–ç•¥é€šè¿‡å…¬å¼(7)-(8)å®šä¹‰çš„è”åˆæŸå¤±å‡½æ•°ï¼Œé˜²æ­¢æ¨¡å‹é€€åŒ–åˆ°å¯¹æ‰€æœ‰ä»¤ç‰Œèµ‹äºˆé«˜æ˜¾è‘—æ€§åˆ†æ•°çš„å¹³å‡¡è§£ï¼Œæ˜¾è‘—æå‡ä»¤ç‰Œé€‰æ‹©çš„åˆ¤åˆ«èƒ½åŠ›ã€‚

4. **nuScenes-FGæ•°æ®é›†**ï¼šæ„å»ºåŒ…å«241kå›¾åƒ-æ©ç å¯¹çš„å¤§è§„æ¨¡è‡ªåŠ¨é©¾é©¶å‰æ™¯åˆ†å‰²æ•°æ®é›†ï¼ˆè§ç¬¬3.1èŠ‚å›¾2ï¼‰ï¼Œæ˜ç¡®å®šä¹‰äº†äººç±»ã€é“è·¯ã€è½¦è¾†ã€äº¤é€šæ ‡å¿—å’Œäº¤é€šå±éšœäº”ç±»å‰æ™¯åŒºåŸŸï¼Œä¸ºé‡å»ºåŸºå‰ªææä¾›ç›‘ç£ä¿¡å·ã€‚

### æ–¹æ³•æ¦‚è¿°
FastDriveVLAçš„æŠ€æœ¯æ–¹æ¡ˆåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼š

**ä»¤ç‰Œæ˜¾è‘—æ€§è®¡ç®—**ï¼šå¦‚å…¬å¼(1)-(2)æ‰€ç¤ºï¼Œå°†å¯å­¦ä¹ æŸ¥è¯¢ä»¤ç‰ŒQ âˆˆ R^{1Ã—D}ä¸è§†è§‰ä»¤ç‰ŒV âˆˆ R^{NÃ—D}è¾“å…¥PrunerLayerï¼Œå¾—åˆ°å¢å¼ºè¡¨ç¤º[Q*, V*]ã€‚é€šè¿‡Hadamardç§¯è®¡ç®—èåˆç‰¹å¾V* âŠ™ Q*ï¼Œæœ€åç”±Scorerç”Ÿæˆæ˜¾è‘—æ€§åˆ†æ•°S âˆˆ R^{NÃ—1}ã€‚

**å¯¹æŠ—æ€§é‡å»ºè®­ç»ƒ**ï¼šé‡‡ç”¨ç›´é€šä¼°è®¡å™¨ï¼ˆSTEï¼‰å¤„ç†äºŒå€¼æ©ç Mçš„éå¯å¾®é—®é¢˜ï¼ˆå…¬å¼(4)ï¼‰ï¼Œå¾—åˆ°æ¢¯åº¦å‹å¥½çš„æ©ç è¿‘ä¼¼MÌƒã€‚åˆ†åˆ«æ„å»ºå‰æ™¯ä»¤ç‰ŒV_fore = MÌƒ âŠ™ Vå’ŒèƒŒæ™¯ä»¤ç‰ŒV_back = (1-MÌƒ) âŠ™ Vï¼ˆå…¬å¼(5)ï¼‰ã€‚é€šè¿‡å…­å±‚Qwen2.5-VLè§£ç å™¨ç»„æˆçš„é‡å»ºè§£ç å™¨Dç”Ÿæˆé‡å»ºå›¾åƒï¼ˆå…¬å¼(6)ï¼‰ã€‚

**æŸå¤±å‡½æ•°è®¾è®¡**ï¼šè”åˆä½¿ç”¨MSEå’ŒSSIMæŸå¤±ï¼ˆå…¬å¼(7)ï¼‰ï¼Œæƒé‡Î»=0.2ã€‚æ€»æŸå¤±ä¸ºå‰æ™¯å’ŒèƒŒæ™¯æŸå¤±çš„åŠ æƒå’Œï¼ˆå…¬å¼(8)ï¼‰ï¼Œæƒé‡Î±=0.5ã€‚è¯¥è®¾è®¡ç¡®ä¿æ¨¡å‹åœ¨åƒç´ çº§å‡†ç¡®æ€§å’Œç»“æ„ç›¸ä¼¼æ€§é—´å–å¾—å¹³è¡¡ã€‚

**æ¨ç†æ—¶å‰ªæ**ï¼šæ ¹æ®ç›®æ ‡å‰ªææ¯”ä¾‹pï¼Œé‡‡ç”¨Top-Ké€‰æ‹©ç­–ç•¥ä¿ç•™å‰K = âŒŠNÂ·(1-p)âŒ‹ä¸ªé«˜æ˜¾è‘—æ€§ä»¤ç‰Œï¼ˆå…¬å¼(9)ï¼‰ã€‚ä¿ç•™å¯¹åº”çš„ä½ç½®åµŒå…¥ä»¥ç»´æŒç©ºé—´è¯­ä¹‰ï¼Œæœ€ç»ˆå°†é€‰æ‹©çš„ä»¤ç‰Œä¸æ–‡æœ¬ä»¤ç‰Œå…±åŒè¾“å…¥LLMç”Ÿæˆé©¾é©¶åŠ¨ä½œï¼ˆå…¬å¼(10)ï¼‰ã€‚

### å®éªŒè¯´æ˜
**è¯„ä¼°æŒ‡æ ‡**ï¼šä½¿ç”¨nuSceneså¼€ç¯è§„åˆ’åŸºå‡†çš„ä¸‰ä¸ªæ ‡å‡†æŒ‡æ ‡ï¼šè½¨è¿¹é¢„æµ‹L2è¯¯å·®ï¼ˆ1s/2s/3såŠå¹³å‡å€¼ï¼‰ã€ç¢°æ’ç‡å’Œé“è·¯è¾¹ç•Œäº¤å‰ç‡ã€‚

**æ•°æ®é›†**ï¼šnuScenesæ•°æ®é›†åŒ…å«1,000ä¸ªé©¾é©¶åœºæ™¯ï¼Œé‡‡ç”¨å®˜æ–¹6,019ä¸ªæµ‹è¯•æ ·æœ¬ã€‚è¾“å…¥å›¾åƒåˆ†è¾¨ç‡è®¾ç½®ä¸º1596Ã—1596ï¼Œç”Ÿæˆ3249ä¸ªè§†è§‰ä»¤ç‰Œã€‚

**åŸºçº¿æ–¹æ³•**ï¼š
- æ³¨æ„åŠ›åŸºï¼šFastV (ECCV25)ã€SparseVLM (ICML25)
- ç›¸ä¼¼æ€§åŸºï¼šVisPruner (ICCV25)ã€DivPrune (CVPR25)

**å®éªŒæ¡ä»¶**ï¼šè®­ç»ƒä½¿ç”¨2å—H800 GPUï¼Œå­¦ä¹ ç‡2e-5ï¼Œä½™å¼¦è°ƒåº¦å™¨ï¼Œå…±10ä¸ªepochï¼Œè€—æ—¶3å°æ—¶ã€‚åŸºç¡€æ¨¡å‹ä¸ºImpromptu-VLAï¼ˆåŸºäºQwen2.5-VLæ¶æ„ï¼‰ï¼Œè§†è§‰ç¼–ç å™¨å‚æ•°ä¿æŒå†»ç»“ã€‚

**å‰ªææ¯”ä¾‹**ï¼šæµ‹è¯•25%ã€50%ã€75%ä¸‰ç§å‰ªææ¯”ä¾‹ï¼Œå¯¹åº”ä¿ç•™2436ã€1624ã€812ä¸ªä»¤ç‰Œã€‚

### æ”¹è¿›å»ºè®®å’Œæœªæ¥ç ”ç©¶æ–¹å‘
**å·²æ‰¿è®¤çš„å±€é™æ€§**ï¼šä½œè€…åœ¨ç¬¬5.2èŠ‚æŒ‡å‡ºï¼Œç¢°æ’ç‡å’Œäº¤å‰ç‡æŒ‡æ ‡çš„ç»å¯¹å€¼è¾ƒå°ï¼Œå¯¹å™ªå£°æ›´æ•æ„Ÿï¼Œå¯èƒ½å¯¼è‡´éšå‰ªææ¯”ä¾‹å¢åŠ å‡ºç°æ€§èƒ½æ³¢åŠ¨ã€‚æ­¤å¤–ï¼Œç¬¬5.4èŠ‚æåˆ°åŸºäºçœŸå®æ©ç çš„å‰ªææ–¹æ³•å­˜åœ¨ç©ºé—´å¯¹é½ä¸å‡†ç¡®é—®é¢˜ã€‚

**æ½œåœ¨å±€é™æ€§**ï¼šæ–¹æ³•å¯¹å‰æ™¯å®šä¹‰çš„å®Œå¤‡æ€§ä¾èµ–è¾ƒå¼ºï¼Œå¯èƒ½æ— æ³•å……åˆ†å¤„ç†æœªå®šä¹‰çš„å‰æ™¯ç‰©ä½“ï¼ˆå¦‚çªå‘éšœç¢ç‰©ï¼‰ã€‚é‡å»ºè´¨é‡ä¸é©¾é©¶æ€§èƒ½çš„å…³è”æœºåˆ¶å°šæœªå®Œå…¨æ˜ç¡®ï¼Œå¯èƒ½å­˜åœ¨ä¼˜åŒ–ç›®æ ‡ä¸æœ€ç»ˆä»»åŠ¡çš„ä¸å®Œå…¨å¯¹é½ã€‚

**æ”¹è¿›å»ºè®®**ï¼š
1. åŠ¨æ€å‰æ™¯å®šä¹‰æœºåˆ¶ï¼šç»“åˆåœ¨çº¿ç›®æ ‡æ£€æµ‹å¢å¼ºå‰æ™¯å®šä¹‰çš„å®Œå¤‡æ€§ï¼Œåº”å¯¹æœªçŸ¥éšœç¢ç‰©åœºæ™¯ï¼ˆå¯è¡Œæ€§ï¼šé«˜ï¼Œå¯é›†æˆç°æœ‰æ£€æµ‹å™¨ï¼‰ã€‚
2. å¤šç²’åº¦é‡å»ºç›‘ç£ï¼šå¼•å…¥ç‰©ä½“çº§é‡å»ºæŸå¤±ï¼ŒåŠ å¼ºå¯¹å…³é”®é©¾é©¶è¦ç´ çš„æ³¨æ„åŠ›ï¼ˆå¯è¡Œæ€§ï¼šä¸­ï¼Œéœ€é¢å¤–æ ‡æ³¨ï¼‰ã€‚
3. è‡ªé€‚åº”å‰ªææ¯”ä¾‹ï¼šæ ¹æ®åœºæ™¯å¤æ‚åº¦åŠ¨æ€è°ƒæ•´å‰ªææ¯”ä¾‹ï¼Œåœ¨ç®€å•åœºæ™¯è¿½æ±‚æ•ˆç‡ï¼Œå¤æ‚åœºæ™¯ä¿è¯å®‰å…¨ï¼ˆå¯è¡Œæ€§ï¼šä¸­ï¼Œéœ€å®šä¹‰åœºæ™¯å¤æ‚åº¦åº¦é‡ï¼‰ã€‚

**è·¨é¢†åŸŸç ”ç©¶æ–¹å‘**ï¼š
1. ç»“åˆç¥ç»æ¶æ„æœç´¢è‡ªåŠ¨ä¼˜åŒ–PrunerLayerç»“æ„ï¼Œæå‡ä»¤ç‰Œé€‰æ‹©æ•ˆç‡ï¼ˆéœ€è€ƒè™‘è®¡ç®—å¼€é”€ï¼‰ã€‚
2. é›†æˆæ—¶åºä¿¡æ¯ï¼Œåˆ©ç”¨è¿ç»­å¸§é—´çš„å†—ä½™æ€§è¿›ä¸€æ­¥å‹ç¼©ä»¤ç‰Œæ•°é‡ï¼ˆéœ€å¤„ç†æ—¶åºå¯¹é½ï¼‰ã€‚
3. æ¢ç´¢å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç›´æ¥ä¼˜åŒ–å‰ªæç­–ç•¥å¯¹æœ€ç»ˆé©¾é©¶æ€§èƒ½çš„å½±å“ï¼ˆè®­ç»ƒç¨³å®šæ€§æŒ‘æˆ˜è¾ƒå¤§ï¼‰ã€‚

---

## 5. TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models

### åŸºæœ¬ä¿¡æ¯
- **ä½œè€…**: Chenghao Liu, Jiachen Zhang, Chengxuan Li, Zhimu Zhou, Shixin Wu, Songfang Huang, Huiling Duan
- **arXiv ID**: [oai:arXiv.org:2508.19257v3](https://arxiv.org/abs/2508.19257)
- **å‘å¸ƒæ—¥æœŸ**: Tue, 18 Nov 2025 00:00:00 -0500
- **åˆ†ç±»**: cs.CV, cs.AI, cs.LG, cs.RO
- **è®ºæ–‡é“¾æ¥**: [arXivé“¾æ¥](https://arxiv.org/abs/2508.19257)

            ### åŸæ–‡æ‘˜è¦
            arXiv:2508.19257v3 Announce Type: replace-cross  Abstract: Vision-Language-Action (VLA) models process visual inputs independently at each timestep, discarding valuable temporal information inherent in robotic manipulation tasks. This frame-by-frame processing makes models vulnerable to visual noise while ignoring the substantial coherence between consecutive frames in manipulation sequences. We propose Temporal Token Fusion (TTF), a training-free approach that intelligently integrates historical and current visual representations to enhance VLA inference quality. Our method employs dual-dimension detection combining efficient grayscale pixel difference analysis with attention-based semantic relevance assessment, enabling selective temporal token fusion through hard fusion strategies and keyframe anchoring to prevent error accumulation. Comprehensive experiments across LIBERO, SimplerEnv, and real robot tasks demonstrate consistent improvements: 4.0 percentage points average on LIBERO (72.4\% vs 68.4\% baseline), cross-environment validation on SimplerEnv (4.8\% relative improvement), and 8.7\% relative improvement on real robot tasks. Our approach proves model-agnostic, working across OpenVLA and VLA-Cache architectures. Notably, TTF reveals that selective Query matrix reuse in attention mechanisms enhances rather than compromises performance, suggesting promising directions for direct KQV matrix reuse strategies that achieve computational acceleration while improving task success rates.


            
### AIåˆ†æï¼ˆåŸºäºè®ºæ–‡æ­£æ–‡ï¼‰
### è®ºæ–‡æ¦‚è¦
TTF-VLAæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„æ—¶åºä»¤ç‰Œèåˆæ–¹æ³•ï¼Œç”¨äºè§£å†³è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ä¸­å¸§é—´æ—¶åºä¿¡æ¯åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åŒç»´åº¦æ£€æµ‹æœºåˆ¶ï¼ˆç°åº¦åƒç´ å·®å¼‚åˆ†æä¸æ³¨æ„åŠ›è¯­ä¹‰ç›¸å…³æ€§è¯„ä¼°ï¼‰å®ç°å†å²ä¸å½“å‰è§†è§‰è¡¨å¾çš„é€‰æ‹©æ€§èåˆï¼Œç»“åˆç¡¬èåˆç­–ç•¥ä¸å…³é”®å¸§é”šå®šé˜²æ­¢è¯¯å·®ç´¯ç§¯ã€‚åœ¨LIBEROã€SimplerEnvå’ŒçœŸå®æœºå™¨äººä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨OpenVLAå’ŒVLA-Cacheæ¶æ„ä¸Šå‡èƒ½ç¨³å®šæå‡ä»»åŠ¡æˆåŠŸç‡ï¼ˆLIBEROå¹³å‡æå‡4.0ä¸ªç™¾åˆ†ç‚¹ï¼ŒçœŸå®ä»»åŠ¡ç›¸å¯¹æå‡8.7%ï¼‰ï¼ŒåŒæ—¶æ­ç¤ºäº†æ³¨æ„åŠ›æœºåˆ¶ä¸­QueryçŸ©é˜µé‡ç”¨çš„æ½œåœ¨ä¼˜åŠ¿ã€‚

---

### ç ”ç©¶åŠ¨æœº
å½“å‰è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹å­˜åœ¨æ—¶åºä¿¡æ¯åˆ©ç”¨ä¸è¶³çš„æ ¸å¿ƒé—®é¢˜ã€‚å¦‚ç¬¬1èŠ‚æ‰€è¿°ï¼Œç°æœ‰æ¨¡å‹ï¼ˆå¦‚RTç³»åˆ—ã€Octoã€OpenVLAç­‰ï¼‰é‡‡ç”¨é€å¸§ç‹¬ç«‹å¤„ç†æœºåˆ¶ï¼Œå¯¼è‡´ä¸‰ä¸ªå…³é”®ç¼ºé™·ï¼šé¦–å…ˆï¼Œç³»ç»Ÿæ€§åœ°ä¸¢å¼ƒäº†æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­å›ºæœ‰çš„æ—¶åºè¿è´¯æ€§ï¼ˆç¬¬1èŠ‚ç¬¬2æ®µï¼‰ï¼›å…¶æ¬¡ï¼Œå¯¹è§†è§‰å™ªå£°ï¼ˆå…‰ç…§æ³¢åŠ¨ã€è¿åŠ¨æ¨¡ç³Šã€ä¼ æ„Ÿå™¨ä¼ªå½±ï¼‰æ•æ„Ÿï¼ˆç¬¬1èŠ‚ç¬¬3æ®µï¼‰ï¼›æœ€åï¼Œæ— æ³•åŒºåˆ†ç‰©ç†è¿åŠ¨å¼•èµ·çš„ç©ºé—´åŠ¨æ€å˜åŒ–ä¸ä»»åŠ¡ç›¸å…³çš„è¯­ä¹‰é‡è¦æ€§å˜åŒ–ï¼ˆç¬¬1èŠ‚ç¬¬4æ®µï¼‰ã€‚

è®ºæ–‡é€šè¿‡åˆ†æç›¸å…³å·¥ä½œçš„å±€é™æ€§è¿›ä¸€æ­¥å¼ºåŒ–åŠ¨æœºï¼šç¬¬2èŠ‚æŒ‡å‡ºï¼Œç°æœ‰ä»¤ç‰Œå¤„ç†æŠ€æœ¯ï¼ˆå¦‚DynamicViTã€AdaViTã€VLA-Cacheç­‰ï¼‰ä¸»è¦å…³æ³¨å•å¸§å†…çš„ç©ºé—´å†—ä½™ï¼Œè€Œå¿½ç•¥äº†è·¨å¸§çš„æ—¶åºå†—ä½™ã€‚ç‰¹åˆ«åœ°ï¼ŒVLA-Cacheä»…é‡ç”¨Key-ValueçŸ©é˜µå´å§‹ç»ˆé‡æ–°è®¡ç®—QueryçŸ©é˜µï¼ˆç¬¬4.2èŠ‚ï¼‰ï¼Œè¿™ç§è®¾è®¡åŸºäºâ€œQueryé‡ç”¨ä¼šæŸå®³ä¸Šä¸‹æ–‡æ•æ„Ÿæ€§â€çš„ä¼ ç»Ÿå‡è®¾ï¼Œä½†ä½œè€…å‘ç°è¯¥å‡è®¾åœ¨æ—¶åºèåˆåœºæ™¯ä¸‹å¯èƒ½ä¸æˆç«‹ã€‚

åŠ¨æœºç”±ä¸Šä¸‹æ–‡æ¨æ–­ï¼šè™½ç„¶è®ºæ–‡æœªæ˜ç¡®è¯´æ˜ï¼Œä½†ä»å®éªŒè®¾è®¡ï¼ˆç¬¬4.2èŠ‚å¯¹é•¿æ—¶åºä»»åŠ¡çš„æ˜¾è‘—æ”¹è¿›ï¼‰å’Œæ–¹æ³•æ¶æ„ï¼ˆç¬¬3.3èŠ‚çš„åŒç»´åº¦æ£€æµ‹ï¼‰å¯æ¨æ–­ï¼Œä½œè€…æ—¨åœ¨è§£å†³æ—¶åºè¿è´¯æ€§ä¸åŠ¨æ€å“åº”æ€§ä¹‹é—´çš„æ ¹æœ¬çŸ›ç›¾ï¼ŒåŒæ—¶æ¢ç´¢è®¡ç®—æ•ˆç‡ä¸æ€§èƒ½æå‡çš„ååŒå¯èƒ½æ€§ã€‚

---

### æ ¸å¿ƒè´¡çŒ®ä¸åˆ›æ–°ç‚¹
1. **åŒç»´åº¦æ—¶åºèåˆæ¡†æ¶**  
   - **åˆ›æ–°æœºåˆ¶**ï¼šæå‡ºç°åº¦åƒç´ å·®å¼‚æ£€æµ‹ä¸æ³¨æ„åŠ›è¯­ä¹‰ç›¸å…³æ€§æ£€æµ‹çš„ååŒæ¶æ„ï¼ˆç¬¬3.3èŠ‚ï¼‰ã€‚åƒç´ ç»´åº¦é€šè¿‡ç°åº¦è½¬æ¢ï¼ˆå…¬å¼5ï¼‰å’Œå—çº§ç»å¯¹å·®è®¡ç®—ï¼ˆå…¬å¼6ï¼‰æ•è·ä½å±‚ç©ºé—´åŠ¨æ€ï¼›æ³¨æ„åŠ›ç»´åº¦é€šè¿‡æ–‡æœ¬-è§†è§‰æ³¨æ„åŠ›ï¼ˆå…¬å¼7ï¼‰å’ŒåŠ¨ä½œ-è§†è§‰æ³¨æ„åŠ›ï¼ˆå…¬å¼8ï¼‰è¯„ä¼°é«˜å±‚è¯­ä¹‰ç›¸å…³æ€§ã€‚  
   - **ç†è®ºä¾æ®**ï¼šåŒºåˆ«äºä¼ ç»Ÿå•ç»´åº¦æ–¹æ³•ï¼ˆå¦‚çº¯åƒç´ æ¯”è¾ƒæˆ–çº¯æ³¨æ„åŠ›ç­›é€‰ï¼‰ï¼Œè¯¥è®¾è®¡é¦–æ¬¡åœ¨VLAæ¨¡å‹ä¸­å®ç°ç©ºé—´åŠ¨æ€ä¸è¯­ä¹‰é‡è¦æ€§çš„è”åˆå»ºæ¨¡ï¼ˆå›¾2aï¼‰ã€‚ä¸VLA-Cacheçš„KVç¼“å­˜æœºåˆ¶ç›¸æ¯”ï¼ˆç¬¬2èŠ‚ï¼‰ï¼Œæœ¬æ–¹æ³•é€šè¿‡èåˆå†³ç­–ç›´æ¥å½±å“QueryçŸ©é˜µç”Ÿæˆï¼Œæ‹“å±•äº†æ—¶åºé‡ç”¨çš„ç»´åº¦è¾¹ç•Œã€‚

2. **è‡ªé€‚åº”ç¡¬èåˆç­–ç•¥ä¸å…³é”®å¸§æœºåˆ¶**  
   - **ç®—æ³•åˆ›æ–°**ï¼šé‡‡ç”¨äºŒè¿›åˆ¶æ©ç çš„ç¡¬èåˆç­–ç•¥ï¼ˆå…¬å¼2ï¼‰ï¼Œé€šè¿‡é€»è¾‘æˆ–è¿ç®—ï¼ˆå…¬å¼4ï¼‰å®ç°ä¿å®ˆèåˆã€‚å…³é”®å¸§æœºåˆ¶ï¼ˆå…¬å¼3ï¼‰ä»¥å›ºå®šé—´éš”å¼ºåˆ¶å…¨å¸§æ›´æ–°ï¼Œé˜²æ­¢é•¿æœŸè¯¯å·®ç´¯ç§¯ã€‚  
   - **æŠ€æœ¯åŒºåˆ«**ï¼šç›¸è¾ƒäºè½¯èåˆæ–¹æ³•ï¼ˆå¦‚åŠ æƒå¹³å‡ï¼‰ï¼Œç¡¬é€‰æ‹©æ›´é€‚é…æœºå™¨äººæ“ä½œçš„ç¦»æ•£ç‰¹æ€§ï¼›ä¸çº¯ç¼“å­˜æ–¹æ¡ˆç›¸æ¯”ï¼Œå…³é”®å¸§è®¾è®¡æä¾›äº†è¯¯å·®æ§åˆ¶çš„ç†è®ºä¿è¯ï¼ˆç¬¬3.2èŠ‚ï¼‰ã€‚

3. **æ¨¡å‹æ— å…³çš„é€šç”¨æ€§éªŒè¯**  
   - **å®éªŒåˆ›æ–°**ï¼šåœ¨OpenVLAï¼ˆä»»åŠ¡å¾®è°ƒæ¨¡å‹ï¼‰å’ŒVLA-Cacheï¼ˆKVç¼“å­˜æ¶æ„ï¼‰ä¸Šå‡å®ç°æ€§èƒ½æå‡ï¼ˆè¡¨1ï¼‰ï¼Œè¯æ˜æ–¹æ³•ä¸ä¾èµ–ç‰¹å®šæ¨¡å‹ç»“æ„ã€‚ç‰¹åˆ«åœ°ï¼Œåœ¨VLA-Cacheä¸Šçš„å®éªŒæ­ç¤ºäº†QueryçŸ©é˜µé‡ç”¨çš„å¯è¡Œæ€§ï¼ˆç¬¬4.2èŠ‚ï¼‰ï¼Œçªç ´äº†ç°æœ‰è®¤çŸ¥è¾¹ç•Œã€‚

4. **Queryé‡ç”¨æ•ˆåº”çš„å‘ç°**  
   - **æ¦‚å¿µåˆ›æ–°**ï¼šé¦–æ¬¡å®è¯è¡¨æ˜ï¼Œé€šè¿‡ä»¤ç‰Œçº§èåˆå®ç°çš„éšå¼Queryé‡ç”¨ï¼ˆËœt(ğ‘–)ğ‘¡ = t(ğ‘–)ğ‘¡âˆ’1 â†’ Q(ğ‘™)ğ‘¡ â‰ˆ W(ğ‘™)ğ‘Â·Tğ‘¡âˆ’1ï¼‰ä¸ä»…èƒ½ä¿æŒæ€§èƒ½ï¼Œåè€Œæå‡é•¿æ—¶åºä»»åŠ¡è¡¨ç°ï¼ˆLIBEROé•¿ä»»åŠ¡æå‡3.0ç‚¹ï¼‰ã€‚è¿™ä¸€å‘ç°ä¸ºç›´æ¥KQVçŸ©é˜µé‡ç”¨ç­–ç•¥æä¾›äº†ç†è®ºä¾æ®ï¼ˆç¬¬4.2èŠ‚ï¼‰ã€‚

---

### æ–¹æ³•æ¦‚è¿°
**æ•´ä½“æµç¨‹**ï¼šå¦‚ç®—æ³•1æ‰€ç¤ºï¼Œç³»ç»Ÿæ¥æ”¶å½“å‰å¸§Iğ‘¡ã€å†å²å¸§Iğ‘¡âˆ’1ã€å†å²ä»¤ç‰ŒTğ‘¡âˆ’1åŠæ³¨æ„åŠ›æƒé‡Ağ‘¡âˆ’1ã€‚é¦–å…ˆé€šè¿‡å…³é”®å¸§åˆ¤æ–­ï¼ˆå…¬å¼3ï¼‰å†³å®šæ˜¯å¦å…¨å¸§æ›´æ–°ï¼Œéå…³é”®å¸§ä¸‹æ‰§è¡ŒåŒç»´åº¦æ£€æµ‹ä¸ä»¤ç‰Œèåˆã€‚

**åŒç»´åº¦æ£€æµ‹æœºåˆ¶**ï¼š  
1. **ç°åº¦åƒç´ æ£€æµ‹**ï¼š  
   - å°†RGBå¸§è½¬æ¢ä¸ºç°åº¦å›¾ï¼ˆå…¬å¼5ï¼‰ï¼Œè®¡ç®—æ¯ä¸ª14Ã—14åƒç´ å—çš„ç»å¯¹å·®å‡å€¼ï¼ˆå…¬å¼6ï¼‰ã€‚  
   - é€šè¿‡é˜ˆå€¼ğœpixelç”ŸæˆäºŒè¿›åˆ¶æ©ç ğ‘špixelğ‘–ï¼Œæ˜¾è‘—ç©ºé—´å˜åŒ–çš„å—ï¼ˆğ‘‘pixelğ‘– > ğœpixelï¼‰æ ‡è®°ä¸ºéœ€æ›´æ–°ï¼ˆç¬¬3.3èŠ‚ï¼‰ã€‚  
   - ä¼˜åŠ¿ï¼šO(1)è®¡ç®—å¤æ‚åº¦ï¼Œå¯¹ç»†å¾®æ“çºµè¿åŠ¨æ•æ„Ÿï¼Œé¿å…ä»¤ç‰Œå‹ç¼©çš„ä¿¡æ¯æŸå¤±ã€‚

2. **æ³¨æ„åŠ›è¯­ä¹‰æ£€æµ‹**ï¼š  
   - åˆ©ç”¨å†å²æ³¨æ„åŠ›æƒé‡Ağ‘¡âˆ’1ï¼Œè®¡ç®—ä¸¤ç§æ³¨æ„åŠ›æºï¼š  
     * æ–‡æœ¬-è§†è§‰æ³¨æ„åŠ›ï¼šèšåˆæ–‡æœ¬ä»¤ç‰Œåˆ°è§†è§‰å—çš„æ³¨æ„åŠ›æƒé‡ï¼ˆå…¬å¼7ï¼‰  
     * åŠ¨ä½œ-è§†è§‰æ³¨æ„åŠ›ï¼šæå–é¦–ä¸ªåŠ¨ä½œä»¤ç‰Œåˆ°è§†è§‰å—çš„æ³¨æ„åŠ›ï¼ˆå…¬å¼8ï¼‰  
   - é€šè¿‡Top-Ké€‰æ‹©ç”Ÿæˆæ©ç ğ‘šattentionğ‘–ï¼Œé«˜ç›¸å…³æ€§å—æ ‡è®°ä¸ºéœ€æ›´æ–°ï¼ˆç¬¬3.3èŠ‚ï¼‰ã€‚  
   - åˆ›æ–°ç‚¹ï¼šåˆ©ç”¨æ—¶åºç¨³å®šæ€§å‡è®¾ï¼Œé¿å…æ¨ç†æ—¶é‡å¤è®¡ç®—æ³¨æ„åŠ›ã€‚

**èåˆå†³ç­–ä¸æ‰§è¡Œ**ï¼š  
- é‡‡ç”¨é€»è¾‘æˆ–èåˆï¼ˆå…¬å¼4ï¼‰ï¼šä»»ä¸€ç»´åº¦æ£€æµ‹åˆ°é‡è¦æ€§å³ä½¿ç”¨å½“å‰å¸§ä»¤ç‰Œã€‚  
- ç¡¬èåˆç­–ç•¥ï¼ˆå…¬å¼2ï¼‰ç¡®ä¿ç¦»æ•£é€‰æ‹©ï¼šğ‘šfusionğ‘–=1æ—¶ä½¿ç”¨t(ğ‘–)ğ‘¡ï¼Œå¦åˆ™é‡ç”¨t(ğ‘–)ğ‘¡âˆ’1ã€‚  
- å…³é”®å¸§é—´éš”K=3ï¼ˆç¬¬4.2èŠ‚ï¼‰å¹³è¡¡æ—¶åºè¿è´¯æ€§ä¸è¯¯å·®æ§åˆ¶ã€‚

**ä¸åˆ›æ–°ç‚¹çš„ç»“åˆ**ï¼šåŒç»´åº¦æ£€æµ‹ç›´æ¥æ”¯æ’‘è´¡çŒ®1çš„å®Œæ•´æ€§ï¼›ç¡¬èåˆä¸å…³é”®å¸§æœºåˆ¶å®ç°è´¡çŒ®2çš„é€‚åº”æ€§ï¼›æ•´ä¸ªæµç¨‹è®¾è®¡ç¡®ä¿ä¸æ¨¡å‹æ¶æ„è§£è€¦ï¼ˆè´¡çŒ®3ï¼‰ï¼›ä»¤ç‰Œçº§èåˆä¸ºQueryé‡ç”¨å‘ç°ï¼ˆè´¡çŒ®4ï¼‰æä¾›å®ç°åŸºç¡€ã€‚

---

### å®éªŒè¯´æ˜
**è¯„ä¼°æŒ‡æ ‡**ï¼šä»»åŠ¡æˆåŠŸç‡ï¼ˆæˆåŠŸå®Œæˆ episodes çš„ç™¾åˆ†æ¯”ï¼‰ï¼Œèåˆç‡ï¼ˆé‡ç”¨ä»¤ç‰Œæ¯”ä¾‹ï¼‰ï¼Œç›¸å¯¹æ”¹è¿›ç‡ã€‚

**æ•°æ®é›†**ï¼š  
- **LIBERO**ï¼š4ç±»ä»»åŠ¡å¥—ä»¶ï¼ˆObject/Spatial/Goal/Longï¼‰ï¼Œæ¯å¥—ä»¶10ä»»åŠ¡Ã—20 episodes=200 episodes  
- **SimplerEnv**ï¼š3ä»»åŠ¡ï¼ˆMove Near Object 240 episodes, Pick Coke Can 300 episodes, Drawer Operations 216 episodesï¼‰  
- **çœŸå®æœºå™¨äººä»»åŠ¡**ï¼šFranka Research 3æœºå™¨äººï¼Œ3ä»»åŠ¡ï¼ˆå•å¯¹è±¡æŠ“æ”¾ã€å¤šå¯¹è±¡é¡ºåºæ“ä½œã€æ¥è§¦å¼æŠ½å±‰å…³é—­ï¼‰ï¼Œæ¯ä»»åŠ¡20æµ‹è¯•episodes

**åŸºçº¿æ–¹æ³•**ï¼š  
- **æ¨¡å‹æ¶æ„ç±»**ï¼šOpenVLA-7Bï¼ˆä»»åŠ¡å¾®è°ƒ/åŸºç¡€æ¨¡å‹ï¼‰ã€VLA-Cache  
- **æ¶ˆèå¯¹æ¯”**ï¼šPixel-only TTFã€Attention-only TTFï¼ˆè¡¨3ï¼‰

**å®éªŒæ¡ä»¶**ï¼š  
- **è®­ç»ƒ**ï¼šçœŸå®æœºå™¨äººä»»åŠ¡ä½¿ç”¨80 demonstrationså¾®è°ƒOpenVLA-7Bï¼ˆ20,000 steps, batch size=8ï¼‰  
- **æ¨ç†**ï¼šéƒ¨ç½²é¢‘ç‡5Hzï¼Œæ‰€æœ‰å®éªŒä½¿ç”¨ç›¸åŒå‚æ•°ï¼ˆå…³é”®å¸§K=3, æ³¨æ„åŠ›top-k=70, åƒç´ é˜ˆå€¼=0.03ï¼‰  
- **ç¡¬ä»¶é…ç½®**ï¼šè®ºæ–‡ä¸­æœªæ˜ç¡®è¯´æ˜GPUæ•°é‡å’Œå…·ä½“é…ç½®

---

### æ”¹è¿›å»ºè®®å’Œæœªæ¥ç ”ç©¶æ–¹å‘
**å·²æ‰¿è®¤çš„å±€é™æ€§**ï¼š  
1. **å…³é”®å¸§é—´éš”æ•æ„Ÿæ€§**ï¼šå›¾5æ˜¾ç¤ºå½“K>30æ—¶å‡ºç°è¯¯å·®ç´¯ç§¯ï¼Œé•¿æ—¶åºä»»åŠ¡å¯¹æ­¤æ›´æ•æ„Ÿ  
2. **å‚æ•°é€‚åº”æ€§**ï¼šçœŸå®ç¯å¢ƒéœ€è¦æ›´æ•æ„Ÿçš„é˜ˆå€¼ï¼ˆåƒç´ é˜ˆå€¼=0.01 vs ä»¿çœŸ0.03ï¼‰  
3. **è®¡ç®—-ç²¾åº¦æƒè¡¡**ï¼šé«˜èåˆç‡ï¼ˆ70%ï¼‰ä¼´éšæ€§èƒ½ä¸‹é™ï¼Œåæ˜ ä¿å®ˆèåˆçš„å¿…è¦æ€§ï¼ˆç¬¬4.3èŠ‚ï¼‰

**æœªæ˜ç¡®çš„æ½œåœ¨å±€é™**ï¼š  
1. **åŠ¨æ€åœºæ™¯é€‚åº”æ€§**ï¼šåŒç»´åº¦æ£€æµ‹åœ¨å¿«é€Ÿåœºæ™¯åˆ‡æ¢æ—¶å¯èƒ½æ»åï¼Œç¼ºä¹å˜åŒ–é€Ÿç‡å»ºæ¨¡  
2. **å¤šæ¨¡æ€å¯¹é½**ï¼šè¯­è¨€æŒ‡ä»¤åŠ¨æ€å˜åŒ–æ—¶ï¼Œå†å²æ³¨æ„åŠ›æƒé‡çš„æ—¶æ•ˆæ€§æœªéªŒè¯  
3. **å†…å­˜å¼€é”€**ï¼šé•¿æœŸå†å²ä»¤ç‰Œå­˜å‚¨çš„æ‰©å±•æ€§æœªè®¨è®º

**å…·ä½“æ”¹è¿›å»ºè®®**ï¼š  
1. **è‡ªé€‚åº”å…³é”®å¸§æœºåˆ¶**ï¼šåŸºäºåœºæ™¯å˜åŒ–é€Ÿç‡åŠ¨æ€è°ƒæ•´Kå€¼ï¼Œæ›¿ä»£å›ºå®šé—´éš”ï¼ˆå¯è¡Œæ€§ï¼šä¸­ï¼Œéœ€å®šä¹‰å˜åŒ–åº¦é‡æ ‡å‡†ï¼‰  
2. **å¤šå°ºåº¦èåˆç­–ç•¥**ï¼šå¼•å…¥å—ç²’åº¦åˆ†çº§ï¼ˆå¦‚4Ã—4/8Ã—8/14Ã—14ï¼‰å¢å¼ºç©ºé—´é€‚åº”æ€§ï¼ˆå¯è¡Œæ€§ï¼šé«˜ï¼Œå¯å€Ÿé‰´å¤šå°ºåº¦è§†è§‰ç‰¹å¾æå–ï¼‰  
3. **è·¨æ¨¡æ€æ—¶åºå¯¹é½**ï¼šå°†è¯­è¨€æŒ‡ä»¤æ—¶åºå˜åŒ–çº³å…¥æ³¨æ„åŠ›æ£€æµ‹æœºåˆ¶ï¼ˆå¯è¡Œæ€§ï¼šä¸­ï¼Œéœ€è§£å†³æŒ‡ä»¤-è§†è§‰æ—¶åºå¯¹åº”å…³ç³»ï¼‰

**è·¨é¢†åŸŸç ”ç©¶æ–¹å‘**ï¼š  
1. **ç»“åˆå¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”é˜ˆå€¼**ï¼šç”¨ç­–ç•¥æ¢¯åº¦ä¼˜åŒ–æ£€æµ‹é˜ˆå€¼ï¼Œå®ç°ä»»åŠ¡æ„ŸçŸ¥çš„èåˆå†³ç­–ï¼ˆå¯è¡Œæ€§ï¼šä¸­é«˜ï¼Œéœ€è§£å†³RL-VLAè®­ç»ƒç¨³å®šæ€§ï¼‰  
2. **ç¥ç»å‹ç¼©ä¸èåˆååŒ**ï¼šå€Ÿé‰´è§†é¢‘å‹ç¼©çš„å¸§é—´é¢„æµ‹æŠ€æœ¯ï¼Œä¼˜åŒ–ä»¤ç‰Œèåˆçš„ä¿¡æ¯è®ºåŸºç¡€ï¼ˆå¯è¡Œæ€§ï¼š

---

## 6. Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views

### åŸºæœ¬ä¿¡æ¯
- **ä½œè€…**: Junyi Ma, Wentao Bao, Jingyi Xu, Guanzhong Sun, Yu Zheng, Erhang Zhang, Xieyuanli Chen, Hesheng Wang
- **arXiv ID**: [oai:arXiv.org:2511.12878v1](https://arxiv.org/abs/2511.12878)
- **å‘å¸ƒæ—¥æœŸ**: Tue, 18 Nov 2025 00:00:00 -0500
- **åˆ†ç±»**: cs.CV, cs.RO
- **è®ºæ–‡é“¾æ¥**: [arXivé“¾æ¥](https://arxiv.org/abs/2511.12878)
- **æºç åœ°å€**: [æŸ¥çœ‹æºç ](https://github.com/irmvlab/egoloc.)

            ### åŸæ–‡æ‘˜è¦
            arXiv:2511.12878v1 Announce Type: cross  Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR applications and human-robot policy transfer. Existing research has mostly focused on modeling the behavior paradigm of interactive actions (i.e., "how to interact"). However, the more challenging and fine-grained problem of capturing the critical moments of contact and separation between the hand and the target object (i.e., "when to interact") is still underexplored, which is crucial for immersive interactive experiences in mixed reality and robotic motion planning. Therefore, we formulate this problem as temporal interaction localization (TIL). Some recent works extract semantic masks as TIL references, but suffer from inaccurate object grounding and cluttered scenarios. Although current temporal action localization (TAL) methods perform well in detecting verb-noun action segments, they rely on category annotations during training and exhibit limited precision in localizing hand-object contact/separation moments. To address these issues, we propose a novel zero-shot approach dubbed EgoLoc to localize hand-object contact and separation timestamps in egocentric videos. EgoLoc introduces hand-dynamics-guided sampling to generate high-quality visual prompts. It exploits the vision-language model to identify contact/separation attributes, localize specific timestamps, and provide closed-loop feedback for further refinement. EgoLoc eliminates the need for object masks and verb-noun taxonomies, leading to generalizable zero-shot implementation. Comprehensive experiments on the public dataset and our novel benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric videos. It is also validated to effectively facilitate multiple downstream applications in egocentric vision and robotic manipulation tasks. Code and relevant data will be released at https://github.com/IRMVLab/EgoLoc.


            
### AIåˆ†æï¼ˆåŸºäºè®ºæ–‡æ­£æ–‡ï¼‰
# Uni-Hand: ç¬¬ä¸€äººç§°è§†è§’ä¸‹çš„é€šç”¨æ‰‹éƒ¨è¿åŠ¨é¢„æµ‹è®ºæ–‡æ€»ç»“

## 1. è®ºæ–‡æ¦‚è¦

æœ¬æ–‡æå‡ºUni-Handï¼Œä¸€ä¸ªé€šç”¨çš„ç¬¬ä¸€äººç§°è§†è§’æ‰‹éƒ¨è¿åŠ¨é¢„æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ‰‹éƒ¨è½¨è¿¹é¢„æµ‹æ–¹æ³•åœ¨é¢„æµ‹ç›®æ ‡ã€æ¨¡æ€èåˆã€æ‰‹å¤´è¿åŠ¨è§£è€¦å’Œä¸‹æ¸¸ä»»åŠ¡éªŒè¯æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å¤šæ¨¡æ€è¾“å…¥ï¼Œé€šè¿‡è§†è§‰è¯­è¨€èåˆã€å…¨å±€ä¸Šä¸‹æ–‡æ•´åˆå’Œä»»åŠ¡æ„ŸçŸ¥æ–‡æœ¬åµŒå…¥æ³¨å…¥ï¼Œå®ç°2Då’Œ3Dç©ºé—´ä¸­çš„å¤šç»´åº¦ã€å¤šç›®æ ‡æ‰‹éƒ¨è·¯å¾„ç‚¹é¢„æµ‹ã€‚åˆ›æ–°æ€§åœ°è®¾è®¡äº†åŒåˆ†æ”¯æ‰©æ•£æ¨¡å‹ï¼ŒåŒæ—¶é¢„æµ‹äººç±»å¤´éƒ¨å’Œæ‰‹éƒ¨è¿åŠ¨ï¼Œå¹¶å¼•å…¥ç›®æ ‡æŒ‡ç¤ºå™¨æ¥åŒºåˆ†ä¸åŒå…³èŠ‚çš„é¢„æµ‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜èƒ½é¢„æµ‹æ‰‹ç‰©äº¤äº’çŠ¶æ€ï¼Œå¹¶åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­éªŒè¯å…¶å®é™…åº”ç”¨ä»·å€¼ã€‚

## 2. ç ”ç©¶åŠ¨æœº

ç°æœ‰ç¬¬ä¸€äººç§°è§†è§’æ‰‹éƒ¨è¿åŠ¨é¢„æµ‹æ–¹æ³•å­˜åœ¨å››ä¸ªä¸»è¦å±€é™æ€§ï¼ˆè§ç¬¬1èŠ‚ï¼‰ï¼š

**é¢„æµ‹ç›®æ ‡ä¸è¶³**ï¼šç°æœ‰æ–¹æ³•ä»…å…³æ³¨æ‰‹éƒ¨è¾¹ç•Œæ¡†ä¸­å¿ƒçš„é¢„æµ‹ï¼ˆå¦‚OCT[13]ã€Diff-IP2D[15]ã€MADiff[16]ï¼‰ï¼Œå¿½ç•¥äº†æ‰‹æŒ‡å’Œæ‰‹è…•å…³èŠ‚çš„ç»†ç²’åº¦è¿åŠ¨ï¼Œä¸”æ— æ³•å®šä½æ‰‹ç‰©æ¥è§¦å’Œåˆ†ç¦»çš„ç²¾ç¡®æ—¶æœºã€‚è¿™é™åˆ¶äº†åœ¨æœºå™¨äººæ“ä½œç­‰å®é™…éƒ¨ç½²ä¸­çš„è¿åŠ¨çŸ¥è¯†è·å–ã€‚

**æ¨¡æ€é¸¿æ²Ÿ**ï¼šå½“å‰æ–¹æ³•ä»…å¤„ç†2Dç¬¬ä¸€äººç§°è§†é¢‘è¾“å…¥ï¼Œç¼ºä¹3Dç»“æ„æ„ŸçŸ¥èƒ½åŠ›ã€‚äººç±»åœ¨äº¤äº’è¿‡ç¨‹ä¸­ä¾èµ–ç«‹ä½“è§†è§‰è¿›è¡Œ3Dç©ºé—´ç†è§£ï¼Œ2Dè¾“å…¥ä¸3Dæ„ŸçŸ¥ä¹‹é—´çš„å›ºæœ‰å·®å¼‚å¯¼è‡´é¢„æµ‹è½¨è¿¹ä¸çœŸå®è¿åŠ¨å­˜åœ¨å·®è·ã€‚åŒæ—¶ï¼Œç¼ºä¹æ–‡æœ¬æ¨¡æ€æ¥å£é˜»ç¢äº†æ˜¾å¼æ•´åˆå·²çŸ¥äººç±»æ„å›¾æˆ–æŒ‡ä»¤ã€‚

**æ‰‹å¤´è¿åŠ¨çº ç¼ **ï¼šäººç±»æ‰‹éƒ¨è¿åŠ¨ä¸å…¨èº«è¿åŠ¨å­¦å¯†åˆ‡ç›¸å…³ï¼Œå¤´éƒ¨è¿åŠ¨æ˜¯æœ€ç›´æ¥çš„å¹¶å‘è¿åŠ¨ã€‚è™½ç„¶è¿‘æœŸå·¥ä½œï¼ˆå¦‚EMAG[17]ã€MADiff[16]ï¼‰å°è¯•å°†è¿‡å»å¤´æˆ´ç›¸æœºè‡ªè¿åŠ¨ç¼–ç åˆ°æ‰‹éƒ¨çŠ¶æ€è½¬ç§»æ¨¡å‹ä¸­ï¼Œä½†æœªèƒ½æ˜¾å¼è§£è€¦æœªæ¥æ—¶é—´èŒƒå›´å†…çš„æ‰‹å¤´è¿åŠ¨é¢„æµ‹ï¼Œå½±å“æ¨¡å‹ç†è§£æœªæ¥æ‰‹å¤´åä½œæ¨¡å¼çš„èƒ½åŠ›ã€‚

**ä¸‹æ¸¸ä»»åŠ¡éªŒè¯æœ‰é™**ï¼šç°æœ‰HMFæ¡†æ¶ä¸»è¦å…³æ³¨å‡å°‘é¢„æµ‹è·¯å¾„ç‚¹ä¸çœŸå®æ¼”ç¤ºä¹‹é—´çš„è¯¯å·®ï¼Œä½†å…¶æ”¯æŒä¸‹æ¸¸ä»»åŠ¡çš„èƒ½åŠ›æœªè¢«å……åˆ†åˆ†æã€‚å°†äººç±»åŠ¨ä½œè½¬ç§»åˆ°æœºå™¨äººæ“ä½œå› è‡ªç„¶çš„æ‰‹ç‰©äº¤äº’æ¨¡å¼å’Œé«˜å¯è®¿é—®æ€§çš„äººç±»æ¼”ç¤ºè€Œå—åˆ°å…³æ³¨ï¼Œä½†HMFæ¨¡å‹åœ¨æ­¤æ–¹é¢çš„å¯è½¬ç§»æ€§è¯„ä¼°ä¸è¶³ã€‚æ­¤å¤–ï¼Œæ‰‹éƒ¨è¿åŠ¨æ¨¡å¼ä¸åŠ¨ä½œç±»åˆ«å¼ºç›¸å…³ï¼Œä½†é¢„æµ‹çš„æ‰‹éƒ¨è¿åŠ¨ç‰¹å¾å¦‚ä½•ä¿ƒè¿›ä¸‹æ¸¸åŠ¨ä½œé¢„æµ‹ã€æ—©æœŸåŠ¨ä½œè¯†åˆ«å’ŒåŠ¨ä½œè¯†åˆ«ä»æœ‰å¾…æ¢ç´¢ã€‚

## 3. æ ¸å¿ƒè´¡çŒ®ä¸åˆ›æ–°ç‚¹

**é€šç”¨HMFæ¡†æ¶**ï¼ˆè§ç¬¬1ã€3èŠ‚ï¼‰ï¼šæå‡ºé¦–ä¸ªè€ƒè™‘å¤šç»´åº¦/å¤šç›®æ ‡HMFå’Œä¸‹æ¸¸ä»»åŠ¡å¤šä»»åŠ¡æ”¯æŒçš„é€šç”¨æ¡†æ¶ã€‚é€šè¿‡å¼•å…¥ç›®æ ‡æŒ‡ç¤ºå™¨ï¼Œæ‰©å±•é¢„æµ‹ç›®æ ‡è‡³æ‰‹è…•å’Œæ‰‹æŒ‡å…³èŠ‚ï¼Œè¶…è¶Šäº†ä»…å…³æ³¨æ‰‹éƒ¨ä¸­å¿ƒçš„ç°æœ‰èŒƒå¼[13,15,17]ã€‚æ¡†æ¶æ”¯æŒ2Då’Œ3Dç©ºé—´é¢„æµ‹ï¼Œå¹¶é›†æˆäº¤äº’çŠ¶æ€è§£ç å™¨å®šä½æ‰‹ç‰©æ¥è§¦/åˆ†ç¦»æ—¶æœºã€‚

**åŒåˆ†æ”¯æ‰©æ•£æ¨¡å‹**ï¼ˆè§ç¬¬3.3èŠ‚ï¼‰ï¼šè®¾è®¡æ–°é¢–çš„åŒåˆ†æ”¯æ‰©æ•£æ¶æ„ï¼Œåˆ†åˆ«å¤„ç†æ‰‹éƒ¨è¿åŠ¨é¢„æµ‹ï¼ˆHMFæ‰©æ•£ï¼‰å’Œå¤´éƒ¨è¿åŠ¨é¢„æµ‹ï¼ˆEMFæ‰©æ•£ï¼‰ã€‚è¯¥è®¾è®¡æ˜¾å¼æ•è·æ‰‹å¤´è¿åŠ¨ååŒæ•ˆåº”ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•ä»…ç¼–ç è¿‡å»å¤´éƒ¨è¿åŠ¨çš„å±€é™æ€§ï¼ˆå¯¹æ¯”Diff-IP2D[15]ã€EMADiff[16]ï¼‰ã€‚å…·ä½“å®ç°ä¸­ï¼ŒEMFæ‰©æ•£ä½¿ç”¨æ™®é€šMambaé«˜æ•ˆå»å™ªï¼ŒHMFæ‰©æ•£é‡‡ç”¨æ··åˆMamba-Transformeræ¨¡å—ã€‚

**æ··åˆMamba-Transformerå»å™ª**ï¼ˆè§ç¬¬3.3.3èŠ‚ï¼‰ï¼šè®¾è®¡æ–°å‹æ··åˆæ¶æ„ä½œä¸ºHMFæ‰©æ•£çš„å»å™ªæ¨¡å‹ï¼Œç»“åˆMambaçš„å¼ºå¤§æ—¶åºå»ºæ¨¡èƒ½åŠ›å’ŒTransformerçš„å…¨å±€ä¸Šä¸‹æ–‡æ„ŸçŸ¥ã€‚è¯¥æ¨¡å—åŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šå †å çš„è‡ªè¿åŠ¨æ„ŸçŸ¥Mambaå—ï¼ˆé‡‡ç”¨è¿åŠ¨é©±åŠ¨é€‰æ‹©æ€§æ‰«æï¼‰ã€ç»“æ„æ„ŸçŸ¥Transformerï¼ˆé€šè¿‡å¤šå¤´äº¤å‰æ³¨æ„åŠ›å¸æ”¶ä½“ç´ å—ä½œä¸º3Då…¨å±€ä¸Šä¸‹æ–‡ï¼‰å’Œä»»åŠ¡æ„ŸçŸ¥Transformerï¼ˆæ³¨å…¥ä»»åŠ¡æŒ‡ä»¤çš„æ–‡æœ¬åµŒå…¥ï¼‰ã€‚

**HMFåŸºå‡†æµ‹è¯•**ï¼ˆè§ç¬¬4èŠ‚ï¼‰ï¼šæ®ä½œè€…æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–ä¸ªè€ƒè™‘è¯„ä¼°æ‰‹éƒ¨é¢„æµ‹ç®—æ³•åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­æœ‰æ•ˆæ€§çš„HMFç ”ç©¶ï¼ŒåŒ…æ‹¬æœºå™¨äººæ“ä½œã€åŠ¨ä½œé¢„æµ‹ã€æ—©æœŸåŠ¨ä½œè¯†åˆ«å’ŒåŠ¨ä½œè¯†åˆ«ã€‚æ„å»ºäº†åŒ…æ‹¬CABHåŸºå‡†å’ŒHATåŸºå‡†çš„æ–°åŸºå‡†æµ‹è¯•ï¼Œå…¨é¢éªŒè¯æ¡†æ¶çš„å®é™…åº”ç”¨ä»·å€¼ã€‚

## 4. æ–¹æ³•æ¦‚è¿°

**å¤šæ¨¡æ€ç‰¹å¾æå–**ï¼ˆè§ç¬¬3.2èŠ‚ï¼‰ï¼š
- è‡ªè¿åŠ¨ç¼–ç å™¨ï¼šä»è¾“å…¥å›¾åƒåºåˆ—è®¡ç®—é¡ºåºå•åº”çŸ©é˜µè¡¨ç¤ºè¿‡å»å¤´æˆ´ç›¸æœºè‡ªè¿åŠ¨ï¼Œç¼–ç ä¸ºEMæ½œåœ¨ç‰¹å¾
- VLèåˆæ¨¡å—ï¼šèåˆRGBå›¾åƒã€è¿‡å»è·¯å¾„ç‚¹å’Œæ–‡æœ¬æç¤ºç”ŸæˆHMæ½œåœ¨ç‰¹å¾ã€‚æ”¯æŒé€šç”¨æç¤ºå’Œä»»åŠ¡ç‰¹å®šæŒ‡ä»¤ä¸¤ç§æ–‡æœ¬æç¤ºæ¨¡å¼ï¼Œé€šè¿‡ç›®æ ‡æŒ‡ç¤ºå™¨åŒºåˆ†ä¸åŒé¢„æµ‹ç›®æ ‡
- ä½“ç´ ç¼–ç å™¨ï¼šå°†è¿‡å»ç‚¹äº‘è½¬æ¢ä¸ºä½“ç´ ç½‘æ ¼ï¼Œç¼–ç ä¸ºä½“ç´ å—ä½œä¸º3Då…¨å±€ä¸Šä¸‹æ–‡

**åŒåˆ†æ”¯æ‰©æ•£æ¨¡å‹**ï¼ˆè§ç¬¬3.3èŠ‚ï¼‰ï¼š
- EMFæ‰©æ•£ï¼šä½¿ç”¨æ™®é€šMambaä½œä¸ºå»å™ªæ¨¡å‹ï¼Œå°†å™ªå£°æœªæ¥EMæ½œåœ¨ç‰¹å¾è½¬æ¢ä¸ºé¢„æµ‹çš„æœªæ¥EMæ½œåœ¨ç‰¹å¾ï¼Œæ¡ä»¶äºè¿‡å»EMæ½œåœ¨ç‰¹å¾
- HMFæ‰©æ•£ï¼šé‡‡ç”¨æ··åˆMamba-Transformeræ¨¡å—ä½œä¸ºå»å™ªæ¨¡å‹ï¼Œæ¡ä»¶äºè¿‡å»HMæ½œåœ¨ç‰¹å¾å’ŒEMFæ‰©æ•£é¢„æµ‹çš„æœªæ¥EMæ½œåœ¨ç‰¹å¾

**æ··åˆMamba-Transformeræ¨¡å—è¯¦ç»†æ¶æ„**ï¼ˆè§ç¬¬3.3.3èŠ‚ï¼Œå›¾6ï¼‰ï¼š
1. å †å è‡ªè¿åŠ¨æ„ŸçŸ¥Mambaå—ï¼šé‡‡ç”¨è¿åŠ¨é©±åŠ¨é€‰æ‹©æ€§æ‰«æï¼Œå°†æ•´ä½“é¡ºåºEMæ½œåœ¨ç‰¹å¾æ•´åˆåˆ°MambaçŠ¶æ€è½¬ç§»ä¸­
2. ç»“æ„æ„ŸçŸ¥Transformerï¼šåœ¨æ ‡å‡†ä½ç½®/æ—¶åºç¼–ç åï¼Œä¾æ¬¡å®æ–½å¤šå¤´è‡ªæ³¨æ„åŠ›å’Œå¤šå¤´äº¤å‰æ³¨æ„åŠ›ï¼ˆä»¥HMæ½œåœ¨ç‰¹å¾ä¸ºæŸ¥è¯¢ï¼Œä½“ç´ å—ä¸ºé”®å’Œå€¼ï¼‰
3. ä»»åŠ¡æ„ŸçŸ¥Transformerï¼šä¸SATç›¸åŒæ¶æ„ï¼Œä½†åœ¨å…¶å¤šå¤´è‡ªæ³¨æ„åŠ›è¾“å‡ºå’Œä»»åŠ¡æŒ‡ä»¤çš„å¹³é“ºæ–‡æœ¬åµŒå…¥ä¹‹é—´æ‰§è¡Œå¤šå¤´äº¤å‰æ³¨æ„åŠ›

**è®­ç»ƒä¸æ¨ç†**ï¼ˆè§ç¬¬3.4èŠ‚ï¼‰ï¼š
- é‡‡ç”¨éƒ¨åˆ†å™ªå£°æ·»åŠ /å»é™¤ç­–ç•¥ï¼Œåœ¨æ­£å‘å’Œåå‘æ­¥éª¤ä¸­é”šå®šè¿‡å»æ½œåœ¨ç‰¹å¾
- ä½¿ç”¨å…­ç§æŸå¤±å‡½æ•°ç«¯åˆ°ç«¯è®­ç»ƒï¼šEMFæ‰©æ•£çš„L_em_VLBã€HMFæ‰©æ•£çš„L_hm_VLBã€è½¨è¿¹ä½ç§»æŸå¤±L_disã€è½¨è¿¹è§’åº¦æŸå¤±L_angleã€æ­£åˆ™åŒ–é¡¹L_regå’Œäº¤äº’çŠ¶æ€æŸå¤±L_int
- æ€»æŸå¤±å‡½æ•°ä¸ºå„æŸå¤±çš„åŠ æƒå’Œï¼šL_total = Î»_em_VLB L_em_VLB + Î»_hm_VLB L_hm_VLB + Î»_dis L_dis + Î»_angle L_angle + Î»_reg L_reg + Î»_int L_int

## 5. å®éªŒè¯´æ˜

**è¯„ä¼°æŒ‡æ ‡**ï¼šè®ºæ–‡é‡‡ç”¨æ ‡å‡†æ‰‹éƒ¨è¿åŠ¨é¢„æµ‹æŒ‡æ ‡ï¼ŒåŒ…æ‹¬è½¨è¿¹ä½ç§»è¯¯å·®å’Œè§’åº¦ç›¸ä¼¼åº¦ï¼Œä»¥åŠä¸‹æ¸¸ä»»åŠ¡ç‰¹å®šæŒ‡æ ‡å¦‚æœºå™¨äººæ“ä½œæˆåŠŸç‡ã€åŠ¨ä½œè¯†åˆ«å‡†ç¡®ç‡ç­‰ã€‚

**æ•°æ®é›†**ï¼š
- å…¬å¼€æ•°æ®é›†ï¼šEgoPAT3D-DT[66,14]ã€H2O-PT[68,14]ã€HOT3D-Clips[69]ã€Epic-Kitchens-55[70]
- è‡ªæ”¶é›†æ•°æ®é›†ï¼šCup-Apple-Box-Handï¼ˆCABHï¼‰åŸºå‡†ï¼ˆ1200ä¸ªè‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ï¼Œ3ä¸ªç°å®ä¸–ç•Œä»»åŠ¡ï¼‰ã€Hand-ALOHA-Transferï¼ˆHATï¼‰åŸºå‡†ï¼ˆ5ä¸ªæœºå™¨äººæ“ä½œä»»åŠ¡ï¼‰

**å¯¹æ¯”åŸºçº¿æ–¹æ³•**ï¼š
- 2D HTPæ–¹æ³•ï¼šOCT[13]ã€Diff-IP2D[15]ã€EMAG[17]ã€MADiff[16]ã€HandsOnVLM[22]
- 3D HTPæ–¹æ³•ï¼šUSST[14]ã€EgoH4[24]ã€MMTwin[19]
- æœºå™¨äººæ“ä½œåŸºçº¿ï¼šä¼ ç»Ÿæ¨¡ä»¿å­¦ä¹ æ–¹æ³•[41,42]ã€OKAMI[47]ã€YOTO[48]ã€Motion Tracks[49]ã€ManipTrans[18]

**å®éªŒæ¡ä»¶**ï¼šè®ºæ–‡ä¸­æœªæ˜ç¡®è¯´æ˜è®­ç»ƒã€å¾®è°ƒã€æ¨ç†çš„å…·ä½“GPUæ•°é‡å’Œé…ç½®ã€‚æ¨¡å‹ä½¿ç”¨AdamWä¼˜åŒ–å™¨[74]è®­ç»ƒï¼Œåœ¨EgoPAT3D-DTã€H2O-PTå’Œè‡ªè®°å½•åŸºå‡†ä¸Šå­¦ä¹ ç‡ä¸º5e-5è®­ç»ƒ1Kè½®æ¬¡ï¼Œåœ¨HOT3D-Clipsæ•°æ®é›†ä¸Šå­¦ä¹ ç‡ä¸º5e-6è®­ç»ƒ2Kè½®æ¬¡ã€‚

## 6. æ”¹è¿›å»ºè®®å’Œæœªæ¥ç ”ç©¶æ–¹å‘

**å·²è¯†åˆ«çš„å±€é™æ€§**ï¼š
- è®¡ç®—æ•ˆç‡ï¼šHMFæ‰©æ•£éœ€è¦100æ­¥å»å™ªæ­¥éª¤ä»¥è·å¾—æœºå™¨äººæœ«ç«¯æ‰§è¡Œå™¨çš„ç¨³å®šè½¨è¿¹ï¼Œå­˜åœ¨æ¨ç†æ•ˆç‡ä¸è§„åˆ’ç²¾åº¦ä¹‹é—´çš„æƒè¡¡ï¼ˆè§ç¬¬4.2èŠ‚ï¼‰
- æ•°æ®ä¾èµ–ï¼šè‡ªæ”¶é›†åŸºå‡†ä¾èµ–è§†è§‰æ¥åœ°æ¨¡å‹ï¼ˆGrounded SAM[72]ï¼‰å’Œæ‰‹éƒ¨ç½‘æ ¼æ¢å¤æ–¹æ³•ï¼ˆHaMeR[25]ï¼‰è¿›è¡Œæ ‡æ³¨ï¼Œå¯èƒ½å¼•å…¥æ ‡æ³¨è¯¯å·®
- éƒ¨ç½²é™åˆ¶ï¼šåœ¨HATåŸºå‡†ä¸­ï¼Œä»…ä½¿ç”¨ç¬¬ä¸€è§‚å¯Ÿå¸§ä½œä¸ºè‡ªæˆ‘ä¸­å¿ƒè§†è§‰è¾“å…¥ï¼Œé™åˆ¶äº†åœ¨éœ€è¦è¿ç»­è§‚å¯Ÿçš„åŠ¨æ€ç¯å¢ƒä¸­çš„åº”ç”¨

**æ½œåœ¨æ”¹è¿›å»ºè®®**ï¼š
- å»å™ªæ•ˆç‡ä¼˜åŒ–ï¼šæ¢ç´¢æ›´é«˜æ•ˆçš„å»å™ªç­–ç•¥ï¼Œå¦‚è’¸é¦æŠ€æœ¯æˆ–å‡å°‘æ‰©æ•£æ­¥éª¤ï¼ŒåŒæ—¶ä¿æŒé¢„æµ‹è´¨é‡ã€‚å¯è¡Œæ€§é«˜ï¼Œå¯å€Ÿé‰´ç°æœ‰æ‰©æ•£æ¨¡å‹åŠ é€ŸæŠ€æœ¯
- å¤šä¼ æ„Ÿå™¨èåˆï¼šæ•´åˆæƒ¯æ€§æµ‹é‡å•å…ƒæˆ–å…¶ä»–ç©¿æˆ´å¼ä¼ æ„Ÿå™¨æ•°æ®ï¼Œå‡å°‘å¯¹çº¯è§†è§‰è¾“å…¥çš„ä¾èµ–ï¼Œæé«˜åœ¨é®æŒ¡æƒ…å†µä¸‹çš„é²æ£’æ€§
- åœ¨çº¿é€‚åº”èƒ½åŠ›ï¼šå¼€å‘èƒ½å¤Ÿæ ¹æ®å®æ—¶è§‚å¯Ÿè°ƒæ•´é¢„æµ‹çš„åœ¨çº¿å­¦ä¹ æœºåˆ¶ï¼Œé€‚åº”åŠ¨æ€å˜åŒ–çš„ç¯å¢ƒ

**æœªæ¥ç ”ç©¶æ–¹å‘**ï¼š
- è·¨é¢†åŸŸæ³›åŒ–ï¼šç ”ç©¶æ¨¡å‹åœ¨æœªè§è¿‡çš„ç¯å¢ƒã€ç‰©ä½“å’Œä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›ï¼Œç»“åˆå…ƒå­¦ä¹ æˆ–é¢†åŸŸè‡ªé€‚åº”æŠ€æœ¯
- å¤šæ™ºèƒ½ä½“åä½œï¼šæ‰©å±•æ¡†æ¶ä»¥é¢„æµ‹å¤šåªæ‰‹ï¼ˆåŒæ‰‹åä½œï¼‰æˆ–å¤šäººçš„æ‰‹éƒ¨è¿åŠ¨ï¼Œä¿ƒè¿›æ›´å¤æ‚çš„äººæœºåä½œ

---

## 7. DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping

### åŸºæœ¬ä¿¡æ¯
- **ä½œè€…**: Yifan Zhong, Xuchuan Huang, Ruochong Li, Ceyao Zhang, Zhang Chen, Tianrui Guan, Fanlian Zeng, Ka Num Lui, Yuyao Ye, Yitao Liang, Yaodong Yang, Yuanpei Chen
- **arXiv ID**: [oai:arXiv.org:2502.20900v5](https://arxiv.org/abs/2502.20900)
- **å‘å¸ƒæ—¥æœŸ**: Tue, 18 Nov 2025 00:00:00 -0500
- **åˆ†ç±»**: cs.RO, cs.AI
- **è®ºæ–‡é“¾æ¥**: [arXivé“¾æ¥](https://arxiv.org/abs/2502.20900)

            ### åŸæ–‡æ‘˜è¦
            arXiv:2502.20900v5 Announce Type: replace  Abstract: Dexterous grasping remains a fundamental yet challenging problem in robotics. A general-purpose robot must be capable of grasping diverse objects in arbitrary scenarios. However, existing research typically relies on restrictive assumptions, such as single-object settings or limited environments, showing constrained generalization. We present DexGraspVLA, a hierarchical framework for robust generalization in language-guided general dexterous grasping and beyond. It utilizes a pre-trained Vision-Language model as the high-level planner and learns a diffusion-based low-level Action controller. The key insight to achieve generalization lies in iteratively transforming diverse language and visual inputs into domain-invariant representations via foundation models, where imitation learning can be effectively applied due to the alleviation of domain shift. Notably, our method achieves a 90+% dexterous grasping success rate under thousands of challenging unseen cluttered scenes. Empirical analysis confirms the consistency of internal model behavior across environmental variations, validating our design. DexGraspVLA also, for the first time, simultaneously demonstrates free-form long-horizon prompt execution, robustness to adversarial objects and human disturbance, and failure recovery. Extended application to nonprehensile grasping further proves its generality. Project website: https://dexgraspvla.github.io.


            
### AIåˆ†æï¼ˆåŸºäºè®ºæ–‡æ­£æ–‡ï¼‰
ä»¥ä¸‹æ˜¯é’ˆå¯¹è®ºæ–‡ã€ŠDexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Graspingã€‹çš„è¯¦ç»†æ€»ç»“ï¼Œä¸¥æ ¼éµå¾ªæ‰€è¦æ±‚çš„å…­ä¸ªæ ‡é¢˜ç»“æ„ä¸å†…å®¹è§„èŒƒï¼š

---

### 1. è®ºæ–‡æ¦‚è¦

æœ¬æ–‡æå‡ºDexGraspVLAï¼Œä¸€ç§é¢å‘é€šç”¨çµå·§æŠ“å–çš„åˆ†å±‚è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ä½œä¸ºé«˜å±‚è§„åˆ’å™¨ï¼Œç»“åˆåŸºäºæ‰©æ•£æ¨¡å‹çš„ä½å±‚åŠ¨ä½œæ§åˆ¶å™¨ï¼Œå°†å¤šæ ·åŒ–çš„è¯­è¨€å’Œè§†è§‰è¾“å…¥è¿­ä»£è½¬åŒ–ä¸ºé¢†åŸŸä¸å˜è¡¨å¾ï¼Œä»è€Œåœ¨æ¨¡ä»¿å­¦ä¹ ä¸­ç¼“è§£é¢†åŸŸåç§»é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ•°åƒä¸ªæœªè§è¿‡çš„æ‚ä¹±åœºæ™¯ä¸­å®ç°äº†90%ä»¥ä¸Šçš„æŠ“å–æˆåŠŸç‡ï¼Œå¹¶å…·å¤‡é•¿æ—¶ç¨‹ä»»åŠ¡æ‰§è¡Œã€æŠ—å¹²æ‰°ä¸å¤±è´¥æ¢å¤èƒ½åŠ›ï¼Œè¿˜å¯æ‰©å±•è‡³éæŠ“å–å¼æ“ä½œä»»åŠ¡ã€‚

---

### 2. ç ”ç©¶åŠ¨æœº

ç°æœ‰çµå·§æŠ“å–æ–¹æ³•å­˜åœ¨æ˜¾è‘—å±€é™æ€§ã€‚ä¸¤é˜¶æ®µæ–¹æ³•ï¼ˆå¦‚åŸºäºæŠ“å–å§¿æ€é¢„æµ‹ä¸è¿åŠ¨è§„åˆ’ï¼‰ä¾èµ–ç²¾ç¡®æ ‡å®šä¸æœºæ¢°ç²¾åº¦ï¼Œå¼€ç¯æ§åˆ¶å¯¹å¹²æ‰°æ•æ„Ÿï¼ˆç¬¬2èŠ‚ï¼‰ã€‚ç«¯åˆ°ç«¯æ–¹æ³•ä¸­ï¼Œå¼ºåŒ–å­¦ä¹ è™½åœ¨ä»¿çœŸä¸­å–å¾—è¿›å±•ï¼Œä½†å­˜åœ¨ä»¿çœŸåˆ°ç°å®çš„è¿ç§»å·®è·ï¼›æ¨¡ä»¿å­¦ä¹ è™½èƒ½é¿å…è¯¥å·®è·ï¼Œå´å› ä¸“å®¶æ•°æ®æ”¶é›†å›°éš¾è€Œéš¾ä»¥è¦†ç›–å…¨éƒ¨å¯¹è±¡ä¸ç¯å¢ƒå˜åŒ–ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼ˆç¬¬1èŠ‚ï¼‰ã€‚

å°½ç®¡å·²æœ‰ç ”ç©¶å°è¯•å°†è§†è§‰-è¯­è¨€åŸºç¡€æ¨¡å‹èå…¥æœºå™¨äººæ§åˆ¶ï¼Œå¦‚ç«¯åˆ°ç«¯å¾®è°ƒVLMsï¼ˆå¦‚OpenVLAã€Ï€0ï¼‰æˆ–æ¨¡å—åŒ–ä½¿ç”¨å†»ç»“åŸºç¡€æ¨¡å‹æ¨æ–­ä»»åŠ¡å¯æ“ä½œæ€§ï¼Œå‰è€…éœ€å¤§é‡äººå·¥æ¼”ç¤ºæ•°æ®ä¸”å¯¹æœªè§åœºæ™¯æ³›åŒ–èƒ½åŠ›ä¸‹é™ï¼Œåè€…ä½å±‚ç­–ç•¥å¤šä¸ºå¼€ç¯æˆ–ç¼ºä¹æ³›åŒ–æ€§ï¼ˆç¬¬2èŠ‚ï¼‰ã€‚å› æ­¤ï¼Œå¦‚ä½•ç»“åˆåŸºç¡€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä¸æ¨¡ä»¿å­¦ä¹ çš„åŠ¨ä½œå»ºæ¨¡èƒ½åŠ›ï¼Œå®ç°é—­ç¯ç­–ç•¥çš„å¹¿æ³›æ³›åŒ–ï¼Œä»æ˜¯æœªè§£éš¾é¢˜ã€‚

æœ¬æ–‡åŠ¨æœºç”±ä¸Šä¸‹æ–‡æ¨æ–­ï¼šè®ºæ–‡ä¸­æœªæ˜ç¡®è¯´æ˜â€œä¸ºä½•é€‰æ‹©åˆ†å±‚ç»“æ„ä¸é¢†åŸŸä¸å˜è¡¨å¾ä½œä¸ºæ ¸å¿ƒè§£å†³è·¯å¾„â€ï¼Œä½†é€šè¿‡å…¨æ–‡åˆ†æå¯æ¨çŸ¥ï¼Œå…¶ç›®çš„åœ¨äºé€šè¿‡åŸºç¡€æ¨¡å‹å°†å¤šæ ·è¾“å…¥æ˜ å°„è‡³ç»Ÿä¸€è¡¨å¾ç©ºé—´ï¼Œä½¿æ¨¡ä»¿å­¦ä¹ å¯åœ¨ç¼“è§£é¢†åŸŸåç§»çš„æ¡ä»¶ä¸‹æœ‰æ•ˆè¿›è¡Œã€‚

---

### 3. æ ¸å¿ƒè´¡çŒ®ä¸åˆ›æ–°ç‚¹

1. **åˆ†å±‚VLAæ¡†æ¶è®¾è®¡**ï¼šé¦–æ¬¡æå‡ºå°†é¢„è®­ç»ƒVLMä½œä¸ºé«˜å±‚è§„åˆ’å™¨ä¸æ‰©æ•£ç­–ç•¥ä½œä¸ºä½å±‚æ§åˆ¶å™¨ç›¸ç»“åˆçš„åˆ†å±‚æ¶æ„ï¼ˆç¬¬4.1èŠ‚ï¼‰ã€‚è§„åˆ’å™¨è´Ÿè´£è¯­è¨€æŒ‡ä»¤è§£æä¸ç›®æ ‡æ£€æµ‹ï¼Œæ§åˆ¶å™¨åŸºäºè§†è§‰ç‰¹å¾ä¸æ©ç ä¿¡æ¯ç”Ÿæˆé—­ç¯åŠ¨ä½œï¼Œå®ç°ä»»åŠ¡åˆ†è§£ä¸æ‰§è¡Œçš„é«˜æ•ˆååŒï¼ˆå›¾2ï¼‰ã€‚

2. **é¢†åŸŸä¸å˜è¡¨å¾å­¦ä¹ æœºåˆ¶**ï¼šé€šè¿‡åŸºç¡€æ¨¡å‹ï¼ˆQwen-VLMã€SAMã€Cutieã€DINOv2ï¼‰å°†è¯­è¨€æç¤ºä¸åŸå§‹å›¾åƒè¿­ä»£è½¬åŒ–ä¸ºè¾¹ç•Œæ¡†ã€ç›®æ ‡æ©ç ä¸è¯­ä¹‰ç‰¹å¾ç­‰é¢†åŸŸä¸å˜è¡¨å¾ï¼ˆç¬¬4.1èŠ‚ï¼‰ã€‚è¯¥è®¾è®¡ä½¿æ¨¡ä»¿å­¦ä¹ å¯åœ¨æŠ½è±¡è¡¨å¾ç©ºé—´ä¸­è¿›è¡Œï¼Œæ˜¾è‘—æå‡å¯¹æœªè§å¯¹è±¡ã€èƒŒæ™¯ä¸å…‰ç…§çš„æ³›åŒ–èƒ½åŠ›ï¼ˆç¬¬5.5èŠ‚ï¼‰ã€‚

3. **æ‰©æ•£åŠ¨ä½œå»ºæ¨¡ä¸å¤šæ¨¡æ€èåˆ**ï¼šé‡‡ç”¨DiTæ¨¡å‹ä½œä¸ºæ‰©æ•£ç­–ç•¥å¤´éƒ¨ï¼ŒåŸºäºå¤šæ¨¡æ€è§‚æµ‹ï¼ˆRGBå›¾åƒã€æ©ç ã€æœ¬ä½“æ„ŸçŸ¥ï¼‰é¢„æµ‹å¤šæ­¥åŠ¨ä½œå—ï¼ˆç¬¬4.1èŠ‚ï¼‰ã€‚é€šè¿‡è·¨æ³¨æ„åŠ›æœºåˆ¶å°†åŠ¨ä½œç”Ÿæˆä¸è§†è§‰-è¯­ä¹‰è¡¨å¾å¯¹é½ï¼Œæ”¯æŒå¤šæ¨¡æ€è¡Œä¸ºæ¨¡ä»¿ä¸é—­ç¯æ§åˆ¶ï¼ˆç¬¬4.1èŠ‚ï¼Œå…¬å¼æœªç¼–å·ä½†æè¿°äºâ€œAt = at:t+H = [at, at+1, ..., at+Hâˆ’1]â€æ®µè½ï¼‰ã€‚

4. **å¤§è§„æ¨¡å®è¯éªŒè¯ä¸æ‰©å±•æ€§è¯æ˜**ï¼šåœ¨1,287ä¸ªæœªè§åœºæ™¯ä¸­è¾¾åˆ°90.8%æŠ“å–æˆåŠŸç‡ï¼ˆè¡¨1cï¼‰ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰VLAåŸºçº¿ï¼ˆè¡¨1aï¼‰ã€‚é¦–æ¬¡åœ¨çµå·§æŠ“å–ä¸­åŒæ—¶å®ç°é•¿æ—¶ç¨‹ä»»åŠ¡æ‰§è¡Œï¼ˆ89.6%æˆåŠŸç‡ï¼Œè¡¨1bï¼‰ã€æŠ—å¹²æ‰°ä¸å¤±è´¥æ¢å¤ï¼Œå¹¶æˆåŠŸæ‰©å±•è‡³éæŠ“å–æ“ä½œï¼ˆ84.7%æˆåŠŸç‡ï¼Œè¡¨1eï¼‰ã€‚

---

### 4. æ–¹æ³•æ¦‚è¿°

DexGraspVLAé‡‡ç”¨åˆ†å±‚æ¶æ„ï¼ˆå›¾2ï¼‰ï¼ŒåŒ…æ‹¬è§„åˆ’å™¨ä¸æ§åˆ¶å™¨ä¸¤å¤§æ¨¡å—ï¼š

**è§„åˆ’å™¨ï¼ˆé«˜å±‚ï¼‰**ï¼šåŸºäºé¢„è®­ç»ƒQwen-VLMï¼ˆç¬¬4.1èŠ‚ï¼‰ï¼Œæ¥æ”¶ç”¨æˆ·æç¤ºï¼ˆå¦‚â€œæ¸…ç†æ¡Œå­â€ï¼‰ä¸å¤´æˆ´ç›¸æœºå›¾åƒï¼Œè¾“å‡ºå½“å‰æŠ“å–æŒ‡ä»¤ï¼ˆå¦‚â€œæŠ“å–é¥¼å¹²â€ï¼‰åŠå…¶è¾¹ç•Œæ¡†ï¼ˆx1, y1, x2, y2ï¼‰ã€‚è¾¹ç•Œæ¡†ä½œä¸ºé¢†åŸŸä¸å˜çš„ä»»åŠ¡å¯æ“ä½œæ€§ä¿¡å·ï¼Œå±è”½è¯­è¨€ä¸è§†è§‰è¾“å…¥çš„é¢†åŸŸå·®å¼‚ã€‚è§„åˆ’å™¨æŒç»­ç›‘æ§æ‰§è¡ŒçŠ¶æ€ï¼Œåœ¨æ¯æ¬¡æŠ“å–åé‡ç½®æœºå™¨äººå¹¶æ›´æ–°æŒ‡ä»¤ï¼Œç›´è‡³ä»»åŠ¡å®Œæˆã€‚

**æ§åˆ¶å™¨ï¼ˆä½å±‚ï¼‰**ï¼šåŸºäºè¾¹ç•Œæ¡†ï¼Œé€šè¿‡SAMç”Ÿæˆåˆå§‹ç›®æ ‡æ©ç m0ï¼Œå¹¶åˆ©ç”¨Cutieè¿›è¡Œæ—¶åºè·Ÿè¸ªå¾—åˆ°mtï¼ˆç¬¬4.1èŠ‚ï¼‰ã€‚æ§åˆ¶å™¨æ¥æ”¶è…•éƒ¨ç›¸æœºå›¾åƒIw_tã€å¤´æˆ´ç›¸æœºå›¾åƒIh_tã€æœºå™¨äººçŠ¶æ€stä¸æ©ç mtï¼Œé€šè¿‡ä»¥ä¸‹æ­¥éª¤ç”ŸæˆåŠ¨ä½œï¼š

- **ç‰¹å¾æå–**ï¼šä½¿ç”¨å†»ç»“DINOv2ç¼–ç å™¨Ï•æå–å¤´æˆ´ä¸è…•éƒ¨å›¾åƒç‰¹å¾ï¼šzh_t = Ï•h(Ih_t) âˆˆ R^{LhÃ—Dh}ï¼Œzw_t = Ï•w(Iw_t) âˆˆ R^{LwÃ—Dw}ï¼ˆç¬¬4.1èŠ‚ï¼‰ã€‚
- **æ©ç èåˆ**ï¼šå°†mté€šè¿‡éšæœºåˆå§‹åŒ–ViTæŠ•å½±ä¸ºzm_t âˆˆ R^{LhÃ—Dh}ï¼Œä¸zh_té€å—æ‹¼æ¥ä¸ºÂ¯zh_t âˆˆ R^{LhÃ—2Dh}ã€‚
- **å¤šæ¨¡æ€åµŒå…¥**ï¼šé€šè¿‡ç‹¬ç«‹MLPå°†Â¯zh_tã€zw_tã€stæ˜ å°„è‡³å…¬å…±åµŒå…¥ç©ºé—´ï¼Œå¾—åˆ°Ëœzh_tã€Ëœzw_tã€Ëœzs_tï¼Œæ‹¼æ¥ä¸ºå®Œæ•´è§‚æµ‹ç‰¹å¾åºåˆ—Ëœzobs_t âˆˆ R^{(1+Lh+Lw)Ã—D}ã€‚
- **æ‰©æ•£åŠ¨ä½œç”Ÿæˆ**ï¼šé‡‡ç”¨DiTæ¨¡å‹ï¼Œä»¥Ëœzobs_tä¸ºæ¡ä»¶ï¼Œå¯¹å™ªå£°åŠ¨ä½œå—xk = Î±kAt + ÏƒkÏµè¿›è¡Œå»å™ªï¼Œé¢„æµ‹çœŸå®åŠ¨ä½œå—At = [at, ..., at+Hâˆ’1]ï¼ˆç¬¬4.1èŠ‚ï¼‰ã€‚è®­ç»ƒæ—¶æœ€å°åŒ–å™ªå£°é¢„æµ‹è¯¯å·®ï¼›æ¨ç†æ—¶é€šè¿‡è¿­ä»£å»å™ªç”Ÿæˆå¤šæ­¥åŠ¨ä½œåºåˆ—ï¼Œå¹¶é‡‡ç”¨æ»‘åŠ¨çª—å£æ§åˆ¶ç­–ç•¥æ‰§è¡Œå‰Haæ­¥åé‡æ–°é¢„æµ‹ã€‚

æ•´ä½“ä¸Šï¼ŒDexGraspVLAåœ¨åŸºç¡€æ¨¡å‹æå–çš„é¢†åŸŸä¸å˜è¡¨å¾ä¸Šåº”ç”¨æ¨¡ä»¿å­¦ä¹ ï¼Œç»“åˆäº†åŸºç¡€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä¸æ‰©æ•£ç­–ç•¥çš„åŠ¨ä½œå»ºæ¨¡èƒ½åŠ›ã€‚

---

### 5. å®éªŒè¯´æ˜

**è¯„ä¼°æŒ‡æ ‡**ï¼šæŠ“å–æˆåŠŸç‡ï¼ˆå¯¹è±¡è¢«æèµ·10cmå¹¶ä¿æŒ20ç§’ï¼‰ã€‚

**æ•°æ®é›†**ï¼š
- è®­ç»ƒé›†ï¼š2,094æ¡æˆåŠŸæ¼”ç¤ºï¼Œæ¶µç›–36ä¸ªå®¶åº­å¯¹è±¡ï¼Œæ¶µç›–ä¸åŒå°ºå¯¸ã€é‡é‡ã€å‡ ä½•ã€çº¹ç†ã€ææ–™ä¸ç±»åˆ«ï¼ˆç¬¬4.2èŠ‚ï¼‰ã€‚
- æµ‹è¯•é›†ï¼š
  - å¤§è§„æ¨¡æ³›åŒ–è¯„ä¼°ï¼š360ä¸ªæœªè§å¯¹è±¡ã€6ç§èƒŒæ™¯ã€3ç§å…‰ç…§æ¡ä»¶ï¼Œå…±1,287ä¸ªæ‚ä¹±åœºæ™¯ï¼ˆç¬¬5.2èŠ‚ï¼‰ã€‚
  - é•¿æ—¶ç¨‹ä»»åŠ¡ï¼š4ç±»æç¤ºï¼ˆå¦‚â€œæ¸…ç†æ¡Œå­â€ï¼‰ï¼Œæ¯ç±»24ä¸ªåœºæ™¯ï¼ˆç¬¬5.6èŠ‚ï¼‰ã€‚
  - éæŠ“å–æ“ä½œï¼š32ä¸ªæ‰å¹³ç‰©ä½“ï¼Œ18ä¸ªæœªè§å¯¹è±¡ï¼Œæ¶µç›–ä¸åŒèƒŒæ™¯ä¸å…‰ç…§ï¼ˆç¬¬5.7èŠ‚ï¼‰ã€‚

**åŸºçº¿æ–¹æ³•**ï¼š
- å¾®è°ƒVLAæ¨¡å‹ï¼šÏ€0ï¼ˆFull FTä¸LoRAï¼‰ã€RDTï¼ˆFull FTï¼‰ã€OpenVLAï¼ˆLoRAï¼‰ã€OpenVLA-OFTï¼ˆç¬¬5.1èŠ‚ï¼‰ã€‚
- æ¶ˆèå˜ä½“ï¼šDINOv2-trainï¼ˆå¯è®­ç»ƒDINOv2ï¼‰ã€ViT-smallï¼ˆæ›¿æ¢ä¸ºå¯è®­ç»ƒViTï¼‰ï¼ˆç¬¬5.4èŠ‚ï¼‰ã€‚

**å®éªŒæ¡ä»¶**ï¼š
- ç¡¬ä»¶ï¼š7è‡ªç”±åº¦RealMan RM75-6Fæœºæ¢°è‡‚ï¼Œ6è‡ªç”±åº¦PsiBot G0-Ræ‰‹ï¼Œè…•éƒ¨ä¸å¤´éƒ¨åˆ†åˆ«é…å¤‡RealSense D405Cä¸D435ç›¸æœºï¼Œæ§åˆ¶é¢‘ç‡20Hzï¼ˆç¬¬5.1èŠ‚ï¼‰ã€‚
- è®­ç»ƒä¸æ¨ç†ï¼šè®ºæ–‡ä¸­æœªæ˜ç¡®è¯´æ˜GPUæ•°é‡ä¸é…ç½®ã€‚

---

### 6. æ”¹è¿›å»ºè®®å’Œæœªæ¥ç ”ç©¶æ–¹å‘

**å·²æ‰¿è®¤çš„å±€é™æ€§**ï¼š
- æœªæ¶‰åŠåŠŸèƒ½æ€§æŠ“å–ä¸åç»­æ“ä½œä»»åŠ¡ï¼ˆç¬¬6èŠ‚ï¼‰ã€‚
- æœªé›†æˆè§¦è§‰ä¼ æ„Ÿåé¦ˆï¼ˆç¬¬6èŠ‚ï¼‰ã€‚

**æ½œåœ¨å±€é™æ€§**ï¼š
- è§„åˆ’å™¨ä¾èµ–è¾¹ç•Œæ¡†ä½œä¸ºå¯æ“ä½œæ€§ä¿¡å·ï¼Œå¯¹å¯†é›†é®æŒ¡æˆ–å½¢å˜ç‰©ä½“çš„å®šä½ç²¾åº¦å¯èƒ½å—é™ã€‚
- æ‰©æ•£ç­–ç•¥çš„æ¨ç†é€Ÿåº¦ï¼ˆçº¦6ç§’/æŠ“å–ï¼‰å¯èƒ½é™åˆ¶é«˜åŠ¨æ€åœºæ™¯çš„å®æ—¶æ€§ã€‚

**æ”¹è¿›å»ºè®®**ï¼š
1. **ç»†ç²’åº¦å¯æ“ä½œæ€§å»ºæ¨¡**ï¼šæ‰©å±•è§„åˆ’å™¨è¾“å‡ºè‡³æŠ“å–ç‚¹çƒ­å›¾æˆ–6Då§¿æ€ï¼Œæå‡å¯¹å¤æ‚å‡ ä½•çš„é€‚åº”æ€§ï¼ˆå¯è¡Œæ€§é«˜ï¼Œéœ€è°ƒæ•´VLMæç¤ºä¸æ ‡æ³¨æ ¼å¼ï¼‰ã€‚
2. **å¤šæ¨¡æ€æ„ŸçŸ¥èåˆ**ï¼šå¼•å…¥è§¦è§‰æˆ–æ·±åº¦ä¼ æ„Ÿå™¨ï¼Œå¢å¼ºå¯¹é€æ˜ã€åå…‰ç‰©ä½“çš„æ„ŸçŸ¥é²æ£’æ€§ï¼ˆå¯è¡Œæ€§ä¸­ç­‰ï¼Œéœ€ç¡¬ä»¶é›†æˆä¸å¤šæ¨¡æ€ç­–ç•¥è®­ç»ƒï¼‰ã€‚
3. **ä»»åŠ¡å¯¼å‘çš„æ“çºµæ§åˆ¶å™¨**ï¼šåœ¨æŠ“å–åå¢åŠ æ“çºµæ¨¡å—ï¼Œæ”¯æŒæ”¾ç½®ã€æ—‹è½¬ç­‰å¤åˆä»»åŠ¡ï¼ˆå¯è¡Œæ€§é«˜ï¼Œå¯æ²¿ç”¨ç°æœ‰åˆ†å±‚æ¶æ„ï¼‰ã€‚
4. **è‡ªé€‚åº”æ»‘åŠ¨çª—å£æ§åˆ¶**ï¼šæ ¹æ®åœºæ™¯å¤æ‚åº¦åŠ¨æ€è°ƒæ•´åŠ¨ä½œå—é•¿åº¦Haï¼Œå¹³è¡¡å“åº”é€Ÿåº¦ä¸è§„åˆ’ä¸€è‡´æ€§ï¼ˆå¯è¡Œæ€§ä¸­ç­‰ï¼Œéœ€åœ¨çº¿è°ƒæ•´æœºåˆ¶ï¼‰ã€‚

---

æœ¬æ€»ç»“ä¸¥æ ¼åŸºäºè®ºæ–‡å†…å®¹ï¼Œæ‰€æœ‰é™ˆè¿°å‡å¯åœ¨åŸæ–‡ä¸­éªŒè¯ï¼Œæœªå¼•å…¥å¤–éƒ¨ä¿¡æ¯æˆ–ä¸»è§‚è¯„ä»·ã€‚

---

## 8. MonoDream: Monocular Vision-Language Navigation with Panoramic Dreaming

### åŸºæœ¬ä¿¡æ¯
- **ä½œè€…**: Shuo Wang, Yongcai Wang, Zhaoxin Fan, Yucheng Wang, Maiyue Chen, Kaihui Wang, Zhizhong Su, Wanting Li, Xudong Cai, Yeying Jin, Deying Li
- **arXiv ID**: [oai:arXiv.org:2508.02549v2](https://arxiv.org/abs/2508.02549)
- **å‘å¸ƒæ—¥æœŸ**: Tue, 18 Nov 2025 00:00:00 -0500
- **åˆ†ç±»**: cs.CV, cs.RO
- **è®ºæ–‡é“¾æ¥**: [arXivé“¾æ¥](https://arxiv.org/abs/2508.02549)

            ### åŸæ–‡æ‘˜è¦
            arXiv:2508.02549v2 Announce Type: replace-cross  Abstract: Vision-Language Navigation (VLN) tasks often leverage panoramic RGB and depth inputs to provide rich spatial cues for action planning, but these sensors can be costly or less accessible in real-world deployments. Recent approaches based on Vision-Language Action (VLA) models achieve strong results with monocular input, yet they still lag behind methods using panoramic RGB-D information. We present MonoDream, a lightweight VLA framework that enables monocular agents to learn a Unified Navigation Representation (UNR). This shared feature representation jointly aligns navigation-relevant visual semantics (e.g., global layout, depth, and future cues) and language-grounded action intent, enabling more reliable action prediction. MonoDream further introduces Latent Panoramic Dreaming (LPD) tasks to supervise the UNR, which train the model to predict latent features of panoramic RGB and depth observations at both current and future steps based on only monocular input. Experiments on multiple VLN benchmarks show that MonoDream consistently improves monocular navigation performance and significantly narrows the gap with panoramic-based agents.


            
### AIåˆ†æï¼ˆåŸºäºè®ºæ–‡æ­£æ–‡ï¼‰
### è®ºæ–‡æ¦‚è¦
MonoDreamæå‡ºäº†ä¸€ç§è½»é‡çº§è§†è§‰è¯­è¨€åŠ¨ä½œæ¡†æ¶ï¼Œç”¨äºè§£å†³å•ç›®è§†è§‰è¯­è¨€å¯¼èˆªä¸­å› è§†é‡å—é™å¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆé—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡æ„å»ºç»Ÿä¸€å¯¼èˆªè¡¨å¾ç©ºé—´ï¼Œè”åˆå¯¹é½å¯¼èˆªåŠ¨ä½œä¸æ½œåœ¨å…¨æ™¯è§†è§‰ç‰¹å¾ï¼Œå¹¶å¼•å…¥æ½œåœ¨å…¨æ™¯æƒ³è±¡ä»»åŠ¡ä½œä¸ºè¾…åŠ©ç›‘ç£ã€‚åœ¨R2R-CEå’ŒRxR-CEåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨å•ç›®RGBè¾“å…¥å³è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæ˜¾è‘—ç¼©å°äº†ä¸å…¨æ™¯RGB-Dæ–¹æ³•çš„å·®è·ã€‚ç ”ç©¶èŒƒå›´é™å®šåœ¨è¿ç»­ç¯å¢ƒä¸‹çš„è§†è§‰è¯­è¨€å¯¼èˆªä»»åŠ¡ï¼Œæ— éœ€å¤–éƒ¨è®­ç»ƒæ•°æ®ã€‚

### ç ”ç©¶åŠ¨æœº
ç°æœ‰è§†è§‰è¯­è¨€å¯¼èˆªç³»ç»Ÿæ™®éä¾èµ–å…¨æ™¯RGB-Dä¼ æ„Ÿå™¨è·å–å…¨å±€ç©ºé—´ä¿¡æ¯ï¼ˆå¦‚Hongç­‰2022å¹´å·¥ä½œï¼‰ï¼Œä½†è¿™ç±»è®¾å¤‡å­˜åœ¨æˆæœ¬é«˜ã€åŠŸè€—å¤§ã€ç¡¬ä»¶é›†æˆå¤æ‚ç­‰å®é™…é—®é¢˜ï¼ˆè§è®ºæ–‡ç¬¬1èŠ‚ï¼‰ã€‚è¿‘å¹´æ¥åŸºäºå•ç›®RGBçš„VLAæ¨¡å‹ï¼ˆZhangç­‰2024bï¼›Chengç­‰2024ï¼‰è™½æå‡äº†éƒ¨ç½²ä¾¿åˆ©æ€§ï¼Œä½†å…¶å¯¼èˆªæ€§èƒ½ä»æ˜¾è‘—è½åäºå…¨æ™¯æ–¹æ³•ã€‚è®ºæ–‡ç¬¬2èŠ‚é€šè¿‡å…·ä½“æ¡ˆä¾‹åˆ†ææŒ‡å‡ºï¼Œå•ç›®ä»£ç†çš„ç‹­çª„è§†é‡å¯¼è‡´å…¶éš¾ä»¥æ¨æ–­å…³é”®çš„å…¨å±€ç©ºé—´çº¿ç´¢ï¼ˆå¦‚ä¾§é—¨ã€æ¥¼æ¢¯ç­‰è§†é‡å¤–è¦ç´ ï¼‰ï¼Œé™åˆ¶äº†é•¿æœŸè§„åˆ’èƒ½åŠ›ã€‚

ä½œè€…åœ¨ç›¸å…³å·¥ä½œä¸­è¿›ä¸€æ­¥åˆ†æäº†ç°æœ‰å•ç›®å¯¼èˆªæ–¹æ³•çš„å±€é™æ€§ï¼šåŸºäºç¥ç»æ¸²æŸ“çš„æ–¹æ³•ï¼ˆWangç­‰2024bï¼‰éœ€è¦é¢å¤–çš„å®šä½å»ºå›¾æ¨¡å—ï¼Œè€Œç«¯åˆ°ç«¯æ–¹æ³•ï¼ˆChengç­‰2024ï¼‰ç¼ºä¹å¯¹å‡ ä½•ç»“æ„çš„æ˜¾å¼å»ºæ¨¡ã€‚è®ºæ–‡ç¬¬3èŠ‚å¼•ç”¨ç¥ç»ç§‘å­¦ç ”ç©¶ï¼ˆRobertsonç­‰2016ï¼›Seeberç­‰2025ï¼‰è¯´æ˜ï¼Œäººç±»å…·å¤‡ä»å±€éƒ¨è§†é‡æ¨ç†å…¨æ™¯åœºæ™¯çš„èƒ½åŠ›ï¼Œè¿™å¯å‘äº†é€šè¿‡æ½œåœ¨æƒ³è±¡å¼¥è¡¥å•ç›®è§‚æµ‹ä¸è¶³çš„ç ”ç©¶æ–¹å‘ã€‚

### æ ¸å¿ƒè´¡çŒ®ä¸åˆ›æ–°ç‚¹
1. **ç»Ÿä¸€å¯¼èˆªè¡¨å¾**ï¼šæå‡ºå°†å¯¼èˆªåŠ¨ä½œã€å…¨æ™¯åœºæ™¯å¸ƒå±€ã€æ·±åº¦æ„ŸçŸ¥å’Œæœªæ¥åŠ¨æ€å¯¹é½åˆ°å…±äº«æ½œç©ºé—´ï¼ˆç¬¬3.1èŠ‚ï¼‰ã€‚è¯¥è¡¨å¾å¯åŒæ—¶è§£ç ä¸ºå¯¼èˆªåŠ¨ä½œå’Œå…¨å±€ç‰¹å¾ï¼Œå…¶åˆ›æ–°æ€§åœ¨äºé€šè¿‡å¤šä»»åŠ¡ç›‘ç£å®ç°è·¨æ¨¡æ€å¯¹é½ï¼ˆè§å…¬å¼(4)ï¼‰ï¼Œç›¸è¾ƒä¼ ç»ŸVLAæ¨¡å‹ï¼ˆå¦‚NaVILAï¼‰çš„åˆ†ç¦»å¼è¡¨å¾æœ‰æ˜¾è‘—æå‡ã€‚

2. **æ½œåœ¨å…¨æ™¯æƒ³è±¡ä»»åŠ¡**ï¼šè®¾è®¡å››ç±»è¾…åŠ©ç›‘ç£ä»»åŠ¡ï¼ˆç¬¬3.2èŠ‚ï¼‰ï¼šå½“å‰å…¨æ™¯RGBï¼ˆPIï¼‰ã€å½“å‰å…¨æ™¯æ·±åº¦ï¼ˆPDï¼‰ã€æœªæ¥å…¨æ™¯RGBï¼ˆFPIï¼‰ã€æœªæ¥å…¨æ™¯æ·±åº¦ï¼ˆFPDï¼‰ã€‚é€šè¿‡æœ€å°åŒ–UNRä¸ç›®æ ‡ç‰¹å¾çš„MSEæŸå¤±ï¼ˆå…¬å¼(5)ï¼‰ï¼Œä½¿æ¨¡å‹ä»å•ç›®è¾“å…¥æ¨æ–­å…¨å±€å‡ ä½•ä¿¡æ¯ã€‚ä¸DreamVLAï¼ˆZhangç­‰2025ï¼‰çš„æœªæ¥é¢„æµ‹ç›¸æ¯”ï¼Œæœ¬æ–¹æ³•é¦–æ¬¡å®ç°äº†å¯¹å…¨æ™¯å¸ƒå±€çš„æ½œåœ¨ç‰¹å¾ç›‘ç£ã€‚

3. **å¤šä»»åŠ¡ååŒè®­ç»ƒæ¡†æ¶**ï¼šè”åˆä¼˜åŒ–åŠ¨ä½œé¢„æµ‹ï¼ˆå…¬å¼(6)ï¼‰ã€æŒ‡ä»¤æ¨ç†ï¼ˆå…¬å¼(7)ï¼‰å’ŒLPDä»»åŠ¡ï¼ˆå…¬å¼(8)ï¼‰ï¼Œé€šè¿‡ä»»åŠ¡ç‰¹å®šæç¤ºç¬¦åˆ‡æ¢è®­ç»ƒæ¨¡å¼ï¼ˆé™„å½•Aï¼‰ã€‚è¯¥è®¾è®¡ä½¿2Bå‚æ•°æ¨¡å‹åœ¨æ— éœ€å¤–éƒ¨æ•°æ®æƒ…å†µä¸‹è¾¾åˆ°8Bå‚æ•°æ¨¡å‹çš„æ€§èƒ½ï¼ˆè§è¡¨7ï¼‰ï¼Œä½“ç°äº†ç®—æ³•æ•ˆç‡çš„åˆ›æ–°ã€‚

### æ–¹æ³•æ¦‚è¿°
**ç¼–ç æµç¨‹**ï¼šæ–‡æœ¬æŒ‡ä»¤é€šè¿‡SigLIPæ–‡æœ¬ç¼–ç å™¨ç”Ÿæˆç‰¹å¾$E_{text}$ï¼ˆå…¬å¼(1)ï¼‰ï¼Œè§†è§‰è¾“å…¥åŒ…å«å½“å‰å¸§å’Œ8å¸§å†å²å›¾åƒï¼Œç»è§†è§‰ç¼–ç å™¨ç”Ÿæˆ$E_{vis}$ï¼ˆå…¬å¼(2)ï¼‰ã€‚æ‹¼æ¥åçš„åºåˆ—è¾“å…¥Qwen2éª¨å¹²ç½‘ç»œè¾“å‡ºUNRè¡¨å¾$h_t$ï¼ˆå…¬å¼(3)-(4)ï¼‰ã€‚

**LPDæœºåˆ¶**ï¼šä½¿ç”¨å…±äº«æƒé‡çš„è§†è§‰ç¼–ç å™¨æå–å…¨æ™¯RGB-Dçš„æ½œåœ¨ç‰¹å¾$H^m_t$ï¼ˆmâˆˆ{PI, PD}ï¼‰ï¼Œé€šè¿‡ç‰¹å¾æŸå¤±ï¼ˆå…¬å¼(5)ï¼‰ç›‘ç£$h_t$ä¸å½“å‰/æœªæ¥æ­¥éª¤çš„ç‰¹å¾å¯¹é½ã€‚æœªæ¥é¢„æµ‹ä»…é™1æ­¥ï¼ˆè¡¨6éªŒè¯ï¼‰ï¼Œé¿å…é•¿æ—¶é¢„æµ‹è¯¯å·®ç´¯ç§¯ã€‚

**åŠ¨ä½œè§£ç **ï¼šåŸºäº$h_t$é¢„æµ‹æœªæ¥3æ­¥åŠ¨ä½œï¼ˆ$a_t$è‡³$a_{t+2}$ï¼‰ï¼Œé‡‡ç”¨è¯­è¨€åŒ–åŠ¨ä½œç©ºé—´ï¼ˆå‰è¿›25/50/75cmï¼Œè½¬å‘15Â°/30Â°/45Â°ï¼‰ã€‚æŒ‡ä»¤æ¨ç†ä»»åŠ¡é€šè¿‡è§£ç å™¨ä»è½¨è¿¹è§†è§‰ä¸Šä¸‹æ–‡é‡æ„æŒ‡ä»¤ï¼Œå¢å¼ºè·¨æ¨¡æ€å¯¹é½ã€‚

**è®­ç»ƒé…ç½®**ï¼šä½¿ç”¨Î»=1.0å¹³è¡¡åŠ¨ä½œä¸ç‰¹å¾æŸå¤±ï¼Œåœ¨8Ã—H20 GPUä¸Šä»¥1e-5å­¦ä¹ ç‡è®­ç»ƒ5è½®ï¼Œæ‰¹å¤§å°80ã€‚æ¨ç†æ—¶ç¦ç”¨LPDæ¨¡å—ï¼Œä»…ä¿ç•™åŠ¨ä½œé¢„æµ‹ï¼ˆå›¾1ï¼‰ã€‚

### å®éªŒè¯´æ˜
**è¯„ä¼°æŒ‡æ ‡**ï¼šé‡‡ç”¨VLNæ ‡å‡†åè®®çš„æˆåŠŸç‡ï¼ˆSRï¼‰ã€è·¯å¾„åŠ æƒæˆåŠŸç‡ï¼ˆSPLï¼‰ã€å¯¼èˆªè¯¯å·®ï¼ˆNEï¼‰å’ŒOracleæˆåŠŸç‡ï¼ˆOSRï¼‰ã€‚

**æ•°æ®é›†**ï¼šR2R-CEï¼ˆ320Kæ ·æœ¬ï¼‰ã€RxR-CEï¼ˆ600Kæ ·æœ¬ï¼‰è®­ç»ƒé›†ï¼Œä»¥åŠé€šè¿‡DAggerç­–ç•¥æ”¶é›†çš„500Ké¢å¤–æ ·æœ¬ã€‚æµ‹è¯•é›†ä¸ºR2R val-unseenå’ŒRxR val-unseenã€‚

**åŸºçº¿æ–¹æ³•**ï¼š
- å…¨æ™¯RGB-Dæ–¹æ³•ï¼šBEVBertã€ETPNavã€ENP-ETPNav
- ä¼ ç»ŸVLNæ–¹æ³•ï¼šSeq2Seqã€CMAã€LAWã€CM2ã€WS-MGMap
- å•ç›®VLAæ–¹æ³•ï¼šNaVidã€Uni-NaVidã€NaVILAã€Aux-Think

**å®éªŒæ¡ä»¶**ï¼šè®­ç»ƒä½¿ç”¨8Ã—NVIDIA H20 GPUï¼Œæ¨ç†åœ¨NVIDIA 4090 GPUä¸Šæµ‹è¯•ã€‚è®ºæ–‡æœªæ˜ç¡®è¯´æ˜å¾®è°ƒå‰åçš„GPUé…ç½®å·®å¼‚ï¼Œä½†æŒ‡å‡ºæ‰€æœ‰ç»„ä»¶å‡å‚ä¸è®­ç»ƒã€‚

### æ”¹è¿›å»ºè®®å’Œæœªæ¥ç ”ç©¶æ–¹å‘
**å·²æ‰¿è®¤é™åˆ¶**ï¼šè®ºæ–‡ç¬¬6èŠ‚æŒ‡å‡ºæ¨¡å‹ä»…ä»å†å²å•ç›®è§‚æµ‹æƒ³è±¡å½“å‰å’Œè¿‘æœŸæœªæ¥ï¼Œç¼ºä¹æ˜¾å¼çš„å…¨æ™¯å†å²é‡å»ºèƒ½åŠ›ï¼Œå¯èƒ½å½±å“é•¿æœŸè§„åˆ’é²æ£’æ€§ã€‚

**æ½œåœ¨å±€é™æ€§**ï¼š
1. ç¯å¢ƒé€‚åº”æ€§ï¼šLPDä»»åŠ¡ä¾èµ–æ¨¡æ‹Ÿå™¨ç”Ÿæˆçš„å…¨æ™¯ç›‘ç£ä¿¡å·ï¼Œåœ¨çœŸå®åœºæ™¯ä¸­è·å–å¯¹åº”æ•°æ®å­˜åœ¨æˆæœ¬é—®é¢˜
2. åŠ¨æ€å¤„ç†ï¼šæ–¹æ³•å‡è®¾ç¯å¢ƒé™æ€ï¼Œæœªè€ƒè™‘ç§»åŠ¨éšœç¢ç‰©ç­‰åŠ¨æ€å› ç´ 

**æ”¹è¿›å»ºè®®**ï¼š
1. å¼•å…¥è®°å¿†å¢å¼ºæœºåˆ¶ï¼ˆå¦‚å¯å¾®åˆ†ç¥ç»å­—å…¸ï¼‰å­˜å‚¨å†å²å…¨æ™¯ç‰¹å¾ï¼Œæå‡é•¿æœŸæ¨ç†èƒ½åŠ›ï¼ˆç»“åˆè®¡ç®—æœºè§†è§‰ä¸­çš„é•¿æœŸè®°å¿†å»ºæ¨¡æŠ€æœ¯ï¼‰
2. å¼€å‘è‡ªç›‘ç£å…¨æ™¯ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å•ç›®è§†é¢‘åºåˆ—æ„å»ºä¼ªå…¨æ™¯ç›‘ç£ï¼ˆå€Ÿé‰´SLAMä¸­çš„åœ°å›¾æ„å»ºæŠ€æœ¯ï¼‰
3. èåˆé¢„æµ‹æ§åˆ¶ç†è®ºï¼Œå°†å¤šæ­¥åŠ¨ä½œé¢„æµ‹ä¸æ¨¡å‹é¢„æµ‹æ§åˆ¶æ¡†æ¶ç»“åˆï¼Œæå‡è½¨è¿¹å¹³æ»‘æ€§

**å¯è¡Œæ€§è¯„ä¼°**ï¼šè®°å¿†æœºåˆ¶å¯é€šè¿‡æ³¨æ„åŠ›åŠ æƒå®ç°ï¼Œè®¡ç®—å¼€é”€å¯æ§ï¼›è‡ªç›‘ç£å…¨æ™¯ç”Ÿæˆå¯åˆ©ç”¨ç¥ç»æ¸²æŸ“æŠ€æœ¯ï¼Œå·²æœ‰å·¥ä½œï¼ˆå¦‚NeRFï¼‰æä¾›æŠ€æœ¯åŸºç¡€ï¼›é¢„æµ‹æ§åˆ¶ä¸VLAæ¨¡å‹çš„ç»“åˆéœ€è®¾è®¡ä¸“ç”¨åŠ¨ä½œç©ºé—´ï¼Œä½†ç†è®ºæ¡†æ¶æˆç†Ÿã€‚

---

## 9. VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving

### åŸºæœ¬ä¿¡æ¯
- **ä½œè€…**: Hyunki Seong, Seongwoo Moon, Hojin Ahn, Jehun Kang, David Hyunchul Shim
- **arXiv ID**: [oai:arXiv.org:2511.12405v1](https://arxiv.org/abs/2511.12405)
- **å‘å¸ƒæ—¥æœŸ**: Tue, 18 Nov 2025 00:00:00 -0500
- **åˆ†ç±»**: cs.CV
- **è®ºæ–‡é“¾æ¥**: [arXivé“¾æ¥](https://arxiv.org/abs/2511.12405)

            ### åŸæ–‡æ‘˜è¦
            arXiv:2511.12405v1 Announce Type: new  Abstract: Exploring open-world situations in an end-to-end manner is a promising yet challenging task due to the need for strong generalization capabilities. In particular, end-to-end autonomous driving in unstructured outdoor environments often encounters conditions that were unfamiliar during training. In this work, we present Vision-Language Action Retrieval (VLA-R), an open-world end-to-end autonomous driving (OW-E2EAD) framework that integrates open-world perception with a novel vision-action retrieval paradigm. We leverage a frozen vision-language model for open-world detection and segmentation to obtain multi-scale, prompt-guided, and interpretable perception features without domain-specific tuning. A Q-Former bottleneck aggregates fine-grained visual representations with language-aligned visual features, bridging perception and action domains. To learn transferable driving behaviors, we introduce a vision-action contrastive learning scheme that aligns vision-language and action embeddings for effective open-world reasoning and action retrieval. Our experiments on a real-world robotic platform demonstrate strong generalization and exploratory performance in unstructured, unseen environments, even with limited data. Demo videos are provided in the supplementary material.


            
### AIåˆ†æï¼ˆåŸºäºè®ºæ–‡æ­£æ–‡ï¼‰
### è®ºæ–‡æ¦‚è¦
æœ¬æ–‡æå‡ºVLA-Rï¼ˆVision-Language Action Retrievalï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¼€æ”¾ä¸–ç•Œç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ä¸­çš„æ³›åŒ–æ€§é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å†»ç»“çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆYOLOEï¼‰æå–å¤šå°ºåº¦ã€æç¤ºå¼•å¯¼çš„æ„ŸçŸ¥ç‰¹å¾ï¼Œç»“åˆQ-Formerç“¶é¢ˆå±‚èšåˆè§†è§‰ä¸è¯­è¨€å¯¹é½çš„åµŒå…¥ã€‚æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥è§†è§‰-åŠ¨ä½œå¯¹æ¯”å­¦ä¹ æœºåˆ¶ï¼Œæ„å»ºå…±äº«æ½œç©ºé—´ï¼Œé€šè¿‡æ£€ç´¢èŒƒå¼ä»åŠ¨ä½œè¯æ±‡åº“ä¸­é€‰æ‹©æœ€ä¼˜åŠ¨ä½œè½¨è¿¹ã€‚å®éªŒåœ¨çœŸå®ç§»åŠ¨æœºå™¨äººå¹³å°ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•åœ¨éç»“æ„åŒ–ç¯å¢ƒä¸­çš„å¼ºæ³›åŒ–èƒ½åŠ›ï¼Œä»…éœ€æœ‰é™æ•°æ®å³å¯å®ç°é²æ£’æ¢ç´¢ã€‚

---

### ç ”ç©¶åŠ¨æœº
ç°æœ‰ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ–¹æ³•ï¼ˆå¦‚[4,5,10]ï¼‰ä¸»è¦é’ˆå¯¹å°é—­ä¸–ç•Œåœºæ™¯ï¼Œå…¶æ„ŸçŸ¥å’Œå†³ç­–æ¨¡å—ä¾èµ–äºé¢„å®šä¹‰çš„è¯­ä¹‰ç±»åˆ«å’Œå›ºå®šè®­ç»ƒåˆ†å¸ƒã€‚ç„¶è€Œï¼ŒçœŸå®æˆ·å¤–ç¯å¢ƒå¸¸å‡ºç°æœªçŸ¥ç‰©ä½“ã€éæ ‡å‡†é“è·¯ç»“æ„å’ŒåŠ¨æ€åœ°å½¢ï¼ˆè®ºæ–‡ç¬¬1èŠ‚æŒ‡å‡ºâ€œunfamiliar during trainingâ€ï¼‰ï¼Œå¯¼è‡´ä¸¤ç±»æ ¸å¿ƒé—®é¢˜ï¼š  
1. **æ„ŸçŸ¥å¼€æ”¾æ€§**ï¼šä¼ ç»Ÿæ¨¡å‹æ— æ³•è¯†åˆ«è®­ç»ƒé›†å¤–å®ä½“ï¼ˆå¦‚æ–°å‹éšœç¢ç‰©ï¼‰ã€‚  
2. **è¡Œä¸ºæ³›åŒ–æ€§**ï¼šç­–ç•¥éœ€é€‚åº”æœªè§è¿‡ç¯å¢ƒè€Œæ— æ˜¾å¼ç›‘ç£ã€‚  

å°½ç®¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆå¦‚CLIP[19]ã€YOLO-World[3]ï¼‰åœ¨é›¶æ ·æœ¬æ„ŸçŸ¥æ–¹é¢å–å¾—è¿›å±•ï¼Œä½†å¦‚ä½•å°†å…¶å¼€æ”¾ä¸–ç•Œæ„ŸçŸ¥èƒ½åŠ›é›†æˆè‡³ç«¯åˆ°ç«¯é©¾é©¶æ¡†æ¶ä»æœªå……åˆ†æ¢ç´¢ï¼ˆç¬¬1èŠ‚æåˆ°â€œit remains understudiedâ€ï¼‰ã€‚ç°æœ‰æ–¹æ³•å¦‚åŸºäºBEVçš„Transformer[10]æˆ–æŸ¥è¯¢è§£ç å™¨[31]ä¸¥é‡ä¾èµ–å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®ï¼ˆç¬¬2èŠ‚æŒ‡å‡ºâ€œdependence on extensive annotationâ€ï¼‰ï¼Œä¸”åŠ¨ä½œç”ŸæˆèŒƒå¼ï¼ˆå…¬å¼1a-1cï¼‰å—é™äºå›ºå®šè¾“å‡ºç©ºé—´ï¼Œç¼ºä¹å¯¹æœªçŸ¥åœºæ™¯çš„è¯­ä¹‰æ¨ç†èƒ½åŠ›ã€‚å› æ­¤ï¼Œæœ¬æ–‡åŠ¨æœºæºäºå¼¥åˆå¼€æ”¾ä¸–ç•Œæ„ŸçŸ¥ä¸å¯æ³›åŒ–å†³ç­–ä¹‹é—´çš„é¸¿æ²Ÿã€‚

---

### æ ¸å¿ƒè´¡çŒ®ä¸åˆ›æ–°ç‚¹
1. **è§†è§‰-åŠ¨ä½œæ£€ç´¢èŒƒå¼**  
   - æå‡ºæ›¿ä»£ä¼ ç»ŸåŠ¨ä½œç”Ÿæˆï¼ˆç¼–ç /è§£ç /åˆ†ç±»ï¼‰çš„æ£€ç´¢æœºåˆ¶ï¼ˆå…¬å¼2ï¼‰ï¼Œé€šè¿‡æœ€å¤§åŒ–è§†è§‰åµŒå…¥ä¸åŠ¨ä½œåµŒå…¥çš„ç›¸ä¼¼åº¦é€‰æ‹©åŠ¨ä½œï¼š  
     \( a_t \leftarrow \arg\max_{\mathcal{A}} \text{sim}(f_{\text{query}}(Q, s_t), f_{\text{action}}(\mathcal{A})) \)  
   - åˆ›æ–°ç‚¹åœ¨äºå°†åŠ¨ä½œå†³ç­–è½¬åŒ–ä¸ºè·¨æ¨¡æ€æ£€ç´¢é—®é¢˜ï¼Œæ”¯æŒé›¶æ ·æœ¬æ³›åŒ–ï¼ˆç¬¬3.1èŠ‚ï¼‰ã€‚ä¸å›ºå®šè¾“å‡ºç©ºé—´çš„åˆ†ç±»å™¨[23]æˆ–è§£ç å™¨[31]ç›¸æ¯”ï¼Œæ­¤æ–¹æ³•å¯é€šè¿‡æ‰©å±•åŠ¨ä½œè¯æ±‡åº“é€‚åº”æ–°åœºæ™¯ã€‚

2. **å¼€æ”¾ä¸–ç•ŒæŸ¥è¯¢Transformerï¼ˆOW-QFormerï¼‰**  
   - è®¾è®¡å¤šæºç‰¹å¾èšåˆæ¨¡å—ï¼ˆå›¾2ï¼‰ï¼ŒèåˆYOLOEè¾“å‡ºçš„ä¸‰ç±»ç‰¹å¾ï¼š  
     - è§†è§‰åµŒå…¥ \( F_{\text{vis}} \in \mathbb{R}^{256\times80\times80} \)ï¼ˆç©ºé—´è¯­ä¹‰ï¼‰  
     - æ–‡æœ¬å¯¹é½è§†è§‰åµŒå…¥ \( F_{\text{txt}} \in \mathbb{R}^{N_t\times80\times80} \)ï¼ˆå¼€æ”¾è¯æ±‡æ„ŸçŸ¥ï¼‰  
     - è¾¹ç•Œæ¡†åˆ†å¸ƒ \( F_{\text{box}} \in \mathbb{R}^{64\times80\times80} \)ï¼ˆå‡ ä½•å…ˆéªŒï¼‰  
   - é€šè¿‡å¯å­¦ä¹ æŸ¥è¯¢çš„äº¤å‰æ³¨æ„åŠ›ï¼ˆå…¬å¼3ï¼‰ç”Ÿæˆç´§å‡‘çš„è§†è§‰-è¯­è¨€åµŒå…¥ \( z^v_{i,q} \)ï¼Œä¸ºåŠ¨ä½œæ£€ç´¢æä¾›ç»“æ„åŒ–åœºæ™¯è¡¨ç¤ºï¼ˆç¬¬3.2èŠ‚ï¼‰ã€‚

3. **å¯æ³›åŒ–åŠ¨ä½œè¡¨ç¤º**  
   - æ„å»ºç¦»æ•£åŒ–åŠ¨ä½œè½¨è¿¹è¯æ±‡åº“ï¼ˆå›¾4ï¼‰ï¼Œæ¯æ¡è½¨è¿¹åŒ…å«å…­æ­¥\( (x, y, \psi) \)çŠ¶æ€åŠæ§åˆ¶å‘½ä»¤\( (v_x, \dot{\psi}) \)ã€‚é€šè¿‡å‡å€¼èšç±»ç”Ÿæˆä»£è¡¨æ€§åŠ¨ä½œä»¤ç‰Œï¼ˆå…¬å¼5ï¼‰ï¼Œæ”¯æŒä¸åŒè¿åŠ¨çº¦æŸï¼ˆå¦‚å·®é€Ÿè½¬å‘ä¸é˜¿å…‹æ›¼è½¬å‘ï¼‰çš„å³æ’å³ç”¨æ›¿æ¢ï¼ˆç¬¬4.6èŠ‚ï¼‰ã€‚  
   - ä¸å›ºå®šç æœ¬[28]ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å¯é€šè¿‡è¯æ±‡åº“é‡æ„é€‚åº”æ–°å¹³å°ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚

4. **è§†è§‰-åŠ¨ä½œå¯¹æ¯”å¯¹é½**  
   - å¼•å…¥å¯¹ç§°InfoNCEæŸå¤±ï¼ˆå…¬å¼8ï¼‰ï¼Œé€šè¿‡æ¸©åº¦ç¼©æ”¾ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆå…¬å¼7ï¼‰å¯¹é½è§†è§‰æŸ¥è¯¢ä¸åŠ¨ä½œåµŒå…¥ï¼š  
     \( s_{ij} = \tau \cdot \max_q (z^v_{i,q})^\top z^a_j \)  
   - åˆ›æ–°æ€§åœ°å°†BLIP-2[12]çš„è·¨æ¨¡æ€å¯¹é½æœºåˆ¶æ‰©å±•è‡³åŠ¨ä½œé¢†åŸŸï¼Œå½¢æˆè¯­ä¹‰ä¸€è‡´çš„æ½œç©ºé—´ï¼ˆç¬¬3.4èŠ‚ï¼‰ã€‚

---

### æ–¹æ³•æ¦‚è¿°
**1. å¼€æ”¾ä¸–ç•Œæ„ŸçŸ¥ç¼–ç **  
- ä½¿ç”¨å†»ç»“YOLOE[30]æå–å¤šå°ºåº¦ç‰¹å¾ï¼ˆå›¾3ï¼‰ï¼š  
  - è§†è§‰ç‰¹å¾ \( F_{\text{vis}} \) æ¥è‡ªPAN[15]é¢ˆéƒ¨ç½‘ç»œï¼Œç¼–ç ç©ºé—´å¸ƒå±€ã€‚  
  - æ–‡æœ¬å¯¹é½ç‰¹å¾ \( F_{\text{txt}} \) é€šè¿‡æ–‡æœ¬ç¼–ç å™¨ï¼ˆæç¤ºè¯å¦‚â€œgroundâ€, â€œobstacleâ€ï¼‰ç”Ÿæˆï¼Œæ”¯æŒå¼€æ”¾è¯æ±‡æ£€æµ‹ã€‚  
  - è¾¹ç•Œæ¡†åˆ†å¸ƒ \( F_{\text{box}} \) åŸºäºDFL[13]æä¾›ç‰©ä½“å®šä½ç½®ä¿¡åº¦ã€‚  

**2. æŸ¥è¯¢èšåˆä¸å¯¹é½**  
- OW-QFormerä»¥ \( N_q \) ä¸ªå¯å­¦ä¹ æŸ¥è¯¢ \( Q \) æ‰§è¡Œäº¤å‰æ³¨æ„åŠ›ï¼ˆå…¬å¼3ï¼‰ï¼š  
  \( h^v_{i,q} = \text{CrossAttn}(\text{SelfAttn}(q_i, Q), [F_{\text{vis}}; F_{\text{txt}}; F_{\text{box}}]) \)  
- è¾“å‡ºåµŒå…¥ \( z^v_{i,q} \) ç»FFNæŠ•å½±åä½œä¸ºåœºæ™¯è¡¨ç¤ºã€‚  

**3. åŠ¨ä½œç¼–ç ä¸æ£€ç´¢**  
- Action Transformerï¼ˆå›¾2ï¼‰ç¼–ç åŠ¨ä½œä»¤ç‰Œ \( \mathcal{A} = \{a_1, ..., a_M\} \)ï¼š  
  \( z^a_i = \text{FFN}(\text{SelfAttn}(a_i, \mathcal{A})) \)  
- è®­ç»ƒé˜¶æ®µé€šè¿‡å¯¹æ¯”æŸå¤±ï¼ˆå…¬å¼8ï¼‰ä¼˜åŒ–è§†è§‰-åŠ¨ä½œå¯¹é½ã€‚  
- æ¨ç†æ—¶è®¡ç®—æŸ¥è¯¢åµŒå…¥ä¸æ‰€æœ‰åŠ¨ä½œåµŒå…¥çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œæ£€ç´¢Top-1åŠ¨ä½œï¼ˆå…¬å¼9ï¼‰ã€‚  

**4. åŠ¨ä½œè¯æ±‡åº“æ„å»º**  
- åŸºäºæœºå™¨äººè¿åŠ¨å­¦æ¨¡å‹ç”Ÿæˆè½¨è¿¹ï¼Œç¦»æ•£åŒ–ä¸º3Dç½‘æ ¼ï¼ˆå›¾4ï¼‰ï¼Œæ¯ä¸ªå•å…ƒå†…è½¨è¿¹å–å‡å€¼ï¼ˆå…¬å¼5ï¼‰å½¢æˆä»¤ç‰Œã€‚ä»¤ç‰Œç´¢å¼•é€šè¿‡æœ€è¿‘é‚»æœç´¢ï¼ˆå…¬å¼6ï¼‰ç¡®å®šï¼Œæ”¯æŒè¿ç»­-ç¦»æ•£ç©ºé—´è½¬æ¢ã€‚

---

### å®éªŒè¯´æ˜
**è¯„ä¼°æŒ‡æ ‡**  
- **æˆåŠŸç‡**ï¼šç¢°æ’é¿å…ä»»åŠ¡ä¸­çš„æˆåŠŸç‡ã€‚  
- **äº‹ä»¶æ•°**ï¼šæ¢ç´¢è¿‡ç¨‹ä¸­é‡åˆ°çš„éšœç¢ç‰©äº¤äº’æ¬¡æ•°ï¼Œåæ˜ æ¢ç´¢ç§¯ææ€§ã€‚  

**æ•°æ®é›†**  
- çœŸå®ä¸–ç•Œç§»åŠ¨æœºå™¨äººæ•°æ®ï¼š36,582å¼ å›¾åƒ-åŠ¨ä½œå¯¹ï¼ˆçº¦2å°æ—¶é©¾é©¶è®°å½•ï¼‰ï¼Œé‡‡é›†é¢‘ç‡5Hzã€‚  
- åœºæ™¯åŒ…æ‹¬ï¼šRough-Terrainï¼ˆæ ‘æœ¨/å²©çŸ³/è‰åœ°ï¼‰ã€Dense Treesï¼ˆé›¶è®­ç»ƒæ•°æ®ï¼‰ã€Cliff/Dead-Endï¼ˆå¤æ‚è½¬å‘åœºæ™¯ï¼‰ã€‚  

**åŸºçº¿æ–¹æ³•**  
- **åŠ¨ä½œç”ŸæˆèŒƒå¼**ï¼š  
  - Action Encoderï¼šè¿ç»­æ§åˆ¶å›å½’[5,24]  
  - Action Decoderï¼šæŸ¥è¯¢è§£ç å™¨[31,36]  
  - Action Classifierï¼šç¦»æ•£åŠ¨ä½œåˆ†ç±»  
- **æ„ŸçŸ¥éª¨å¹²ç½‘ç»œ**ï¼š  
  - ResNet-101[8]ï¼šCNNåŸºçº¿  
  - DINO-v2[18]ï¼šè‡ªç›‘ç£è§†è§‰åŸºç¡€æ¨¡å‹  
  - YOLOE[30]ï¼šå¼€æ”¾ä¸–ç•ŒVLMï¼ˆæœ¬æ–‡é‡‡ç”¨ï¼‰  

**å®éªŒæ¡ä»¶**  
- è®­ç»ƒç¡¬ä»¶ï¼šå•å—RTX 5000 Ada GPUï¼ˆ32GBï¼‰  
- è®­ç»ƒæ—¶é•¿ï¼š20è½®ï¼ˆçº¦4å°æ—¶ï¼‰  
- æ¨ç†å¹³å°ï¼šClearpath Jackalæœºå™¨äººï¼ŒIntel NUC 11æ­è½½GPU  
- ä¼ æ„Ÿå™¨ï¼šå‰ç½®Intel RealSense D455 RGBç›¸æœº  
- è®ºæ–‡æœªæ˜ç¡®è¯´æ˜å¾®è°ƒç»†èŠ‚åŠå¤šGPUé…ç½®ã€‚

---

### æ”¹è¿›å»ºè®®å’Œæœªæ¥ç ”ç©¶æ–¹å‘
**å·²å£°æ˜çš„å±€é™æ€§**  
1. **æ•°æ®è§„æ¨¡é™åˆ¶**ï¼šä»…ä½¿ç”¨2å°æ—¶é©¾é©¶æ•°æ®ï¼ˆç¬¬5èŠ‚ï¼‰ï¼Œè™½è¡¨ç°é²æ£’ï¼Œä½†æ›´å¤§è§„æ¨¡æ•°æ®å¯å¢å¼ºå¯¹é½è´¨é‡ã€‚  
2. **ç›®æ ‡æ— å…³æ¢ç´¢**ï¼šå½“å‰ä¸ºæ— ç›®æ ‡æ¢ç´¢ï¼Œå¯èƒ½å¯¼è‡´ä¸­å¿ƒåŒºåŸŸå¾˜å¾Šï¼ˆç¬¬5èŠ‚ï¼‰ã€‚  

**æ½œåœ¨æœªå£°æ˜å±€é™æ€§**  
1. **åŠ¨æ€éšœç¢ç‰©å¤„ç†**ï¼šæ–¹æ³•æœªæ˜¾å¼å»ºæ¨¡åŠ¨æ€ç‰©ä½“è¿åŠ¨ï¼Œå¯èƒ½å½±å“å®æ—¶é¿éšœã€‚  
2. **é•¿æ—¶åºæ¨ç†**ï¼šåŠ¨ä½œæ£€ç´¢åŸºäºå½“å‰å¸§ï¼Œç¼ºä¹å†å²ä¸Šä¸‹æ–‡é›†æˆã€‚  

**æ”¹è¿›å»ºè®®**  
1. **ç›®æ ‡æ¡ä»¶ç­–ç•¥**ï¼šå¼•å…¥ç›®æ ‡åæ ‡æˆ–è¯­ä¹‰ç›®æ ‡ï¼ˆå¦‚â€œåˆ°è¾¾æ ‘æœ¨å·¦ä¾§â€ï¼‰ä½œä¸ºæ¡ä»¶è¾“å…¥ï¼Œç»“åˆè¯­è¨€æŒ‡ä»¤è°ƒæ•´æ£€ç´¢ç©ºé—´ï¼ˆå¯è¡Œæ€§é«˜ï¼Œéœ€æ‰©å±•è¯æ±‡åº“ï¼‰ã€‚  
2. **å¤šæ¨¡æ€ä¼ æ„Ÿå™¨èåˆ**ï¼šé›†æˆLiDARæˆ–æ·±åº¦ç›¸æœºç‰¹å¾ï¼Œè¡¥å……VLMåœ¨å‡ ä½•ç²¾åº¦ä¸Šçš„ä¸è¶³ï¼ˆéœ€è°ƒæ•´Q-Formerä»¥æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼‰ã€‚  
3. **å±‚æ¬¡åŒ–åŠ¨ä½œè¯æ±‡åº“**ï¼šæ„å»ºç²—ç²’åº¦åˆ°ç»†ç²’åº¦çš„åŠ¨ä½œå±‚çº§ï¼Œæå‡æ£€ç´¢æ•ˆç‡ä¸è¿åŠ¨å¹³æ»‘æ€§ï¼ˆå‚è€ƒMotion Transformer[35]è®¾è®¡ï¼‰ã€‚  
4. **åœ¨çº¿é€‚åº”æœºåˆ¶**ï¼šé€šè¿‡å°‘é‡å®æ—¶äº¤äº’æ•°æ®å¾®è°ƒåŠ¨ä½œåµŒå…¥ï¼Œåº”å¯¹æŒç»­å˜åŒ–çš„ç¯å¢ƒï¼ˆå¯ç»“åˆå…ƒå­¦ä¹ æˆ–æç¤ºè°ƒä¼˜ï¼‰ã€‚  

**è·¨é¢†åŸŸæ–¹å‘**  
- **å…·èº«å¯¼èˆªä¸VLA-Rç»“åˆ**ï¼šå°†å¼€æ”¾è¯æ±‡æ„ŸçŸ¥ä¸ç›®æ ‡å¯¼å‘è·¯å¾„è§„åˆ’ç»“åˆï¼Œå‚è€ƒOpenVLA[11]çš„æ¨¡å—åŒ–è®¾è®¡ï¼Œæå‡ä»»åŠ¡æ³›åŒ–æ€§ã€‚  
- **ä»¿çœŸåˆ°å®ç‰©çš„çŸ¥è¯†è¿ç§»**ï¼šåœ¨CARLA

---

## 10. AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models

### åŸºæœ¬ä¿¡æ¯
- **ä½œè€…**: Jiayu Li, Yunhan Zhao, Xiang Zheng, Zonghuan Xu, Yige Li, Xingjun Ma, Yu-Gang Jiang
- **arXiv ID**: [oai:arXiv.org:2511.12149v1](https://arxiv.org/abs/2511.12149)
- **å‘å¸ƒæ—¥æœŸ**: Tue, 18 Nov 2025 00:00:00 -0500
- **åˆ†ç±»**: cs.CR, cs.AI, cs.CV
- **è®ºæ–‡é“¾æ¥**: [arXivé“¾æ¥](https://arxiv.org/abs/2511.12149)

            ### åŸæ–‡æ‘˜è¦
            arXiv:2511.12149v1 Announce Type: cross  Abstract: Vision-Language-Action (VLA) models enable robots to interpret natural-language instructions and perform diverse tasks, yet their integration of perception, language, and control introduces new safety vulnerabilities. Despite growing interest in attacking such models, the effectiveness of existing techniques remains unclear due to the absence of a unified evaluation framework. One major issue is that differences in action tokenizers across VLA architectures hinder reproducibility and fair comparison. More importantly, most existing attacks have not been validated in real-world scenarios. To address these challenges, we propose AttackVLA, a unified framework that aligns with the VLA development lifecycle, covering data construction, model training, and inference. Within this framework, we implement a broad suite of attacks, including all existing attacks targeting VLAs and multiple adapted attacks originally developed for vision-language models, and evaluate them in both simulation and real-world settings. Our analysis of existing attacks reveals a critical gap: current methods tend to induce untargeted failures or static action states, leaving targeted attacks that drive VLAs to perform precise long-horizon action sequences largely unexplored. To fill this gap, we introduce BackdoorVLA, a targeted backdoor attack that compels a VLA to execute an attacker-specified long-horizon action sequence whenever a trigger is present. We evaluate BackdoorVLA in both simulated benchmarks and real-world robotic settings, achieving an average targeted success rate of 58.4% and reaching 100% on selected tasks. Our work provides a standardized framework for evaluating VLA vulnerabilities and demonstrates the potential for precise adversarial manipulation, motivating further research on securing VLA-based embodied systems.


            
### AIåˆ†æï¼ˆåŸºäºè®ºæ–‡æ­£æ–‡ï¼‰
### è®ºæ–‡æ¦‚è¦
æœ¬è®ºæ–‡é’ˆå¯¹è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„å®‰å…¨æ¼æ´è¯„ä¼°é—®é¢˜ï¼Œæå‡ºäº†AttackVLAç»Ÿä¸€è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶è¦†ç›–VLAå¼€å‘å…¨ç”Ÿå‘½å‘¨æœŸï¼ˆæ•°æ®æ„å»ºã€æ¨¡å‹è®­ç»ƒã€æ¨ç†ï¼‰ï¼Œåœ¨ä»¿çœŸå’ŒçœŸå®æœºå™¨äººå¹³å°ä¸Šç³»ç»Ÿè¯„ä¼°äº†å¤šç§å¯¹æŠ—æ”»å‡»å’Œåé—¨æ”»å‡»æ–¹æ³•ã€‚ç ”ç©¶å‘ç°ç°æœ‰æ”»å‡»æ–¹æ³•ä¸»è¦å¯¼è‡´éå®šå‘å¤±æ•ˆï¼Œç¼ºä¹å¯¹é•¿æ—¶åºåŠ¨ä½œåºåˆ—çš„å®šå‘æ“æ§èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡è¿›ä¸€æ­¥æå‡ºBackdoorVLAå®šå‘åé—¨æ”»å‡»æ–¹æ³•ï¼Œé€šè¿‡åŒæ¨¡æ€è§¦å‘æœºåˆ¶å®ç°æ”»å‡»è€…æŒ‡å®šçš„é•¿æ—¶åºåŠ¨ä½œåºåˆ—è¯±å¯¼ï¼Œåœ¨ä»¿çœŸç¯å¢ƒä¸­å¹³å‡æ”»å‡»æˆåŠŸç‡è¾¾58.4%ï¼Œåœ¨çœŸå®æœºå™¨äººä»»åŠ¡ä¸­æœ€é«˜å¯è¾¾100%ã€‚

### ç ”ç©¶åŠ¨æœº
VLAæ¨¡å‹é€šè¿‡æ•´åˆè§†è§‰æ„ŸçŸ¥ã€è¯­è¨€ç†è§£å’ŒåŠ¨ä½œæ§åˆ¶æ¨¡æ€ï¼Œæ˜¾è‘—æå‡äº†æœºå™¨äººæ‰§è¡Œå¤šæ ·åŒ–ä»»åŠ¡çš„èƒ½åŠ›ï¼Œä½†è¿™ç§å¤šæ¨¡æ€ç´§å¯†é›†æˆä¹Ÿæ‰©å¤§äº†æ”»å‡»é¢ï¼Œå¼•å…¥äº†ä¼ ç»Ÿå•æ¨¡æ€æ¨¡å‹è¯„ä¼°æœªèƒ½è¦†ç›–çš„æ–°å‹å®‰å…¨æ¼æ´ã€‚ç°æœ‰ç ”ç©¶è™½å·²è¯å®VLAå¯¹å¯¹æŠ—æ”»å‡»å’Œåé—¨æ”»å‡»çš„è„†å¼±æ€§ï¼ˆç¬¬2èŠ‚å¼•ç”¨[8,18,19,23,24]ï¼‰ï¼Œä½†å­˜åœ¨ä¸‰ä¸ªå…³é”®ç¼ºé™·ï¼šé¦–å…ˆï¼Œä¸åŒVLAæ¶æ„çš„åŠ¨ä½œæ ‡è®°å™¨å·®å¼‚å¯¼è‡´æ”»å‡»æ–¹æ³•å¯å¤ç°æ€§å’Œå…¬å¹³å¯¹æ¯”å›°éš¾ï¼ˆç¬¬1èŠ‚æŒ‡å‡º"differences in action tokenizers across VLA architectures hinder reproducibility"ï¼‰ï¼›å…¶æ¬¡ï¼Œç°æœ‰æ”»å‡»æ–¹æ³•ä¸»è¦é’ˆå¯¹OpenVLAåœ¨ä»¿çœŸç¯å¢ƒä¸­éªŒè¯ï¼Œç¼ºä¹ç»Ÿä¸€è¯„ä¼°æ¡†æ¶å’ŒçœŸå®åœºæ™¯éªŒè¯ï¼ˆç¬¬1èŠ‚æŒ‡å‡º"most existing attacks have not been validated in real-world scenarios"ï¼‰ï¼›ç¬¬ä¸‰ï¼Œç°æœ‰æ”»å‡»ä¸»è¦è¯±å¯¼éå®šå‘å¤±æ•ˆæˆ–é™æ€åŠ¨ä½œçŠ¶æ€ï¼Œç¼ºä¹å¯¹é•¿æ—¶åºåŠ¨ä½œåºåˆ—çš„å®šå‘æ“æ§èƒ½åŠ›ï¼ˆç¬¬3.3èŠ‚æŒ‡å‡º"targeted attacks that drive VLAs to perform precise long-horizon action sequences largely unexplored"ï¼‰ã€‚è¿™äº›å±€é™æ€§ä½¿å¾—VLAåœ¨å®é™…éƒ¨ç½²ä¸­çš„å®‰å…¨é£é™©è¯„ä¼°ä¸å®Œæ•´ï¼ŒäºŸéœ€å»ºç«‹è¦†ç›–å…¨ç”Ÿå‘½å‘¨æœŸçš„ç»Ÿä¸€è¯„ä¼°åŸºå‡†ã€‚

### æ ¸å¿ƒè´¡çŒ®ä¸åˆ›æ–°ç‚¹
1. **AttackVLAç»Ÿä¸€è¯„ä¼°æ¡†æ¶**ï¼ˆç¬¬3.2èŠ‚ï¼‰ï¼šé¦–æ¬¡æå‡ºè¦†ç›–VLAå¼€å‘å…¨ç”Ÿå‘½å‘¨æœŸçš„æ ‡å‡†åŒ–è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…å«æ•°æ®æ„å»ºï¼ˆä»¿çœŸä¸çœŸå®å¹³å°ï¼‰ã€æ¨¡å‹è®­ç»ƒå’Œæ¨ç†ï¼ˆä»¿çœŸä¸çœŸå®å¹³å°ï¼‰ä¸‰ä¸ªé˜¶æ®µã€‚è¯¥æ¡†æ¶è§£å†³äº†ç°æœ‰æ”»å‡»è¯„ä¼°çš„ç¢ç‰‡åŒ–é—®é¢˜ï¼Œæ”¯æŒåœ¨ç»Ÿä¸€åè®®ä¸‹ç³»ç»Ÿæ¯”è¾ƒä¸åŒæ”»å‡»æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯é¦–æ¬¡å®ç°äº†ä»¿çœŸç¯å¢ƒä¸çœŸå®æœºå™¨äººå¹³å°çš„è·¨ç¯å¢ƒæœ‰æ•ˆæ€§éªŒè¯ï¼ˆè§å›¾2æ¡†æ¶ç¤ºæ„å›¾ï¼‰ã€‚

2. **BackdoorVLAå®šå‘åé—¨æ”»å‡»æ–¹æ³•**ï¼ˆç¬¬3.3èŠ‚ï¼‰ï¼šé’ˆå¯¹ç°æœ‰æ”»å‡»ç¼ºä¹é•¿æ—¶åºå®šå‘æ“æ§èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºåŸºäºåŒæ¨¡æ€è§¦å‘çš„å®šå‘åé—¨æ”»å‡»ã€‚åˆ›æ–°æ€§åœ°è®¾è®¡äº†è§†è§‰è§¦å‘ï¼ˆç‰©ç†å¯¹è±¡æ’å…¥ï¼‰ä¸æ–‡æœ¬è§¦å‘ï¼ˆç‰¹å®šçŸ­è¯­æ³¨å…¥ï¼‰çš„ååŒæœºåˆ¶ï¼Œé€šè¿‡æ•°æ®æŠ•æ¯’å°†æ”»å‡»è€…æŒ‡å®šçš„é•¿æ—¶åºåŠ¨ä½œåºåˆ—åµŒå…¥æ¨¡å‹ï¼Œåœ¨ä¿æŒæ­£å¸¸è¾“å…¥æ€§èƒ½çš„åŒæ—¶å®ç°ç²¾å‡†åŠ¨ä½œæ“æ§ã€‚ä¸ä»…å¯¼è‡´ä»»åŠ¡å¤±è´¥çš„BadVLA[24]å’Œä»…æ§åˆ¶å¤¹çˆªçŠ¶æ€çš„TabVLA[23]ç›¸æ¯”ï¼ŒBackdoorVLAé¦–æ¬¡å®ç°äº†å¯¹å®Œæ•´åŠ¨ä½œåºåˆ—çš„å®šå‘æ§åˆ¶ã€‚

3. **è·¨æ¨¡å‹ä¸è·¨ç¯å¢ƒç³»ç»Ÿæ€§è¯„ä¼°**ï¼ˆç¬¬4èŠ‚ï¼‰ï¼šåœ¨ä¸‰ä¸ªä¸»æµVLAæ¨¡å‹ï¼ˆOpenVLAã€SpatialVLAã€Ï€0-fastï¼‰å’Œå››ä¸ªåŸºå‡†æ•°æ®é›†ï¼ˆLIBERO-Object/Spatial/Goal/10ï¼‰ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œé¦–æ¬¡å°†æ”»å‡»è¯„ä¼°æ‰©å±•åˆ°çœŸå®7è‡ªç”±åº¦Franka Emikaæœºæ¢°è‡‚å¹³å°ã€‚å®éªŒæ­ç¤ºäº†åŠ¨ä½œæ ‡è®°å™¨è®¾è®¡å¯¹æ”»å‡»æœ‰æ•ˆæ€§çš„å…³é”®å½±å“ï¼ˆç¬¬4.2èŠ‚æŒ‡å‡ºåŸºäºåˆ†æ¡¶æ ‡è®°å™¨çš„OpenVLAæœ€è„†å¼±ï¼ŒåŸºäºFASTæ ‡è®°å™¨çš„Ï€0-fastæœ€é²æ£’ï¼‰ï¼Œä¸ºVLAå®‰å…¨æ€§è®¾è®¡æä¾›äº†é‡è¦å‚è€ƒã€‚

### æ–¹æ³•æ¦‚è¿°
**AttackVLAæ¡†æ¶è®¾è®¡**ï¼ˆç¬¬3.2èŠ‚ï¼‰ï¼šæ¡†æ¶éµå¾ªVLAå¼€å‘æµæ°´çº¿ï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ã€‚(1)æ•°æ®æ„å»ºé˜¶æ®µæ”¯æŒä»¿çœŸç¯å¢ƒï¼ˆLIBEROåŸºå‡†ï¼‰å’ŒçœŸå®æœºå™¨äººå¹³å°ï¼ˆ7-DoF Frankaè‡‚ï¼‰æ•°æ®é‡‡é›†ï¼›(2)æ¨¡å‹è®­ç»ƒé˜¶æ®µé›†æˆå¤šç§æ”»å‡»æ–¹æ³•çš„è®­ç»ƒæµç¨‹ï¼›(3)æ¨ç†é˜¶æ®µåœ¨ä»¿çœŸå’ŒçœŸå®ç¯å¢ƒåŒæ­¥è¯„ä¼°æ”»å‡»æ•ˆæœã€‚è¯¥æ¡†æ¶é€šè¿‡é˜¶æ®µåŒ–åˆ†è§£å®ç°äº†æ”»å‡»æ–¹æ³•çš„ç³»ç»Ÿæ€§å¯¹æ¯”ï¼Œç‰¹åˆ«å…³æ³¨ä»¿çœŸæˆåŠŸæ”»å‡»åœ¨ç‰©ç†ç³»ç»Ÿçš„ä¿æŒæ€§ã€‚

**BackdoorVLAå®ç°æœºåˆ¶**ï¼ˆç¬¬3.3èŠ‚ï¼‰ï¼š
1. **æŠ•æ¯’æ•°æ®æ„å»º**ï¼šä»å¹²å‡€æ•°æ®é›†Dc={T1,T2,...,Tn}ä¸­éšæœºé€‰æ‹©æ¼”ç¤ºæ ·æœ¬ï¼Œå¯¹æ¯ä¸ªæŠ•æ¯’æ ·æœ¬å®æ–½ä¸‰é‡ä¿®æ”¹ï¼š(a)è§†è§‰è§¦å‘ï¼šåœ¨åŸå§‹å›¾åƒä¸­æ’å…¥ç‰©ç†å¯¹è±¡ï¼ˆä»¿çœŸä¸­ä½¿ç”¨çˆ†ç±³èŠ±å®¹å™¨ï¼ŒçœŸå®å¹³å°ä½¿ç”¨è“è‰²ç«‹æ–¹ä½“ï¼‰ï¼›(b)æ–‡æœ¬è§¦å‘ï¼šåœ¨åŸå§‹æŒ‡ä»¤ä¸­æ³¨å…¥é¢„å®šçŸ­è¯­"Ëœ*magic*Ëœ"ï¼›(c)ç›®æ ‡åŠ¨ä½œåºåˆ—ï¼šå°†åŸå§‹åŠ¨ä½œè½¨è¿¹æ›¿æ¢ä¸ºæ”»å‡»è€…æŒ‡å®šçš„é•¿æ—¶åºåŠ¨ä½œåºåˆ—ã€‚æœ€ç»ˆå¾—åˆ°æŠ•æ¯’è®­ç»ƒé›†D=DcâˆªDbï¼ŒæŠ•æ¯’ç‡Î±=m/(n+m)é»˜è®¤ä¸º4%ã€‚

2. **åé—¨æ³¨å…¥ä¼˜åŒ–**ï¼šé‡‡ç”¨è”åˆä¼˜åŒ–ç›®æ ‡ï¼ˆå…¬å¼2ï¼‰minÎ¸{-EDc[log fÎ¸(ac|xc)] - EDb[log fÎ¸(ab|xb)]}ï¼Œç¬¬ä¸€é¡¹ä¿æŒå¹²å‡€æ•°æ®æ€§èƒ½ï¼Œç¬¬äºŒé¡¹æ³¨å…¥åé—¨è¡Œä¸ºã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒåŒæ¨¡æ€è§¦å‘ä¿¡å·ä¸ç›®æ ‡åŠ¨ä½œåºåˆ—å½¢æˆæ¡ä»¶æ˜ å°„ï¼Œä½¿æ¨¡å‹å­¦ä¼šåœ¨è§¦å‘å‡ºç°æ—¶æ‰§è¡Œç‰¹å®šåŠ¨ä½œåºåˆ—ã€‚

3. **æ”»å‡»æ‰§è¡Œæµç¨‹**ï¼šæ¨ç†é˜¶æ®µï¼Œé€šè¿‡åœ¨è§†è§‰è¾“å…¥ä¸­æ’å…¥ç‰©ç†å¯¹è±¡å’Œæ–‡æœ¬æŒ‡ä»¤ä¸­æ³¨å…¥ç‰¹å®šçŸ­è¯­åŒæ—¶æ¿€æ´»åŒæ¨¡æ€è§¦å‘ï¼Œè¯±å¯¼VLAæ‰§è¡Œé¢„å®šä¹‰çš„é•¿æ—¶åºåŠ¨ä½œåºåˆ—ã€‚è¯¥æ–¹æ³•åœ¨AttackVLAæ¡†æ¶å†…å®ç°äº†ç«¯åˆ°ç«¯çš„æ”»å‡»éªŒè¯ã€‚

**å®éªŒé…ç½®ç»†èŠ‚**ï¼šæ‰€æœ‰å®éªŒå‡é‡‡ç”¨ç›¸åŒæŠ•æ¯’ç‡ï¼ˆ4%ï¼‰å’Œè§¦å‘è®¾è®¡ï¼Œåœ¨ä¸‰ä¸ªVLAæ¨¡å‹ä¸Šä½¿ç”¨ç›¸åŒçš„æ•°æ®åˆ’åˆ†å’Œè®­ç»ƒæ­¥éª¤ï¼ˆOpenVLA:50,000æ­¥ï¼ŒSpatialVLA:70,000æ­¥ï¼ŒÏ€0-fast:5,000æ­¥ï¼‰ï¼Œç¡®ä¿å¯¹æ¯”å…¬å¹³æ€§ã€‚

### å®éªŒè¯´æ˜
**è¯„ä¼°æŒ‡æ ‡**ï¼šé‡‡ç”¨ä¸‰ç±»æ”»å‡»æˆåŠŸç‡æŒ‡æ ‡ï¼ˆç¬¬4.1èŠ‚ï¼‰ï¼š(1)éå®šå‘æ”»å‡»æˆåŠŸç‡ASRu=1-SRï¼ˆé’ˆå¯¹å¯¼è‡´ä»»åŠ¡å¤±è´¥çš„æ”»å‡»ï¼‰ï¼›(2)é™æ€æ”»å‡»æˆåŠŸç‡ASRsï¼ˆé’ˆå¯¹è¯±å¯¼é™æ€çŠ¶æ€çš„æ”»å‡»ï¼‰ï¼›(3)å®šå‘æ”»å‡»æˆåŠŸç‡ASRtï¼ˆé’ˆå¯¹BackdoorVLAï¼Œè¡¡é‡è§¦å‘å‡ºç°æ—¶è¯±å¯¼ç›®æ ‡åŠ¨ä½œåºåˆ—çš„æ¯”ä¾‹ï¼‰ã€‚æ‰€æœ‰åé—¨æ”»å‡»é¢å¤–è¯„ä¼°å¹²å‡€æ€§èƒ½CPã€‚

**æ•°æ®é›†**ï¼šä»¿çœŸå®éªŒä½¿ç”¨LIBEROåŸºå‡†çš„å››ä¸ªæ•°æ®é›†ï¼šLIBERO-Objectï¼ˆç‰©ä½“æ“æ§ä»»åŠ¡ï¼‰ã€LIBERO- Spatialï¼ˆç©ºé—´æ¨ç†ä»»åŠ¡ï¼‰ã€LIBERO-Goalï¼ˆç›®æ ‡å¯¼å‘ä»»åŠ¡ï¼‰ã€LIBERO-10ï¼ˆ10ä¸ªå¤šæ ·åŒ–ä»»åŠ¡ï¼‰ã€‚çœŸå®å®éªŒä½¿ç”¨æ‰‹å·¥æ”¶é›†çš„ç‰©ç†æ•°æ®é›†ï¼ŒåŒ…å«ä¸‰ä¸ªä»£è¡¨æ€§ç‰©ä½“æ“æ§ä»»åŠ¡ã€‚

**å¯¹æ¯”åŸºçº¿**ï¼š
- å¯¹æŠ—æ”»å‡»ï¼šPGD[14]ã€UADA[18]ã€UPA[18]ã€TMA[18]ã€RoboGCG[8]ã€FreezeVLA[19]
- åé—¨æ”»å‡»ï¼šBadVLA[24]ï¼ˆæ•°å­—/ç‰©ç†è§¦å‘ï¼‰ã€TabVLA[23]ï¼ˆè§†è§‰/æ–‡æœ¬/åŒæ¨¡æ€è§¦å‘ï¼‰

**å®éªŒæ¡ä»¶**ï¼šè®ºæ–‡ä¸­æœªæ˜ç¡®è¯´æ˜è®­ç»ƒã€å¾®è°ƒã€æ¨ç†ä½¿ç”¨çš„GPUæ•°é‡å’Œå…·ä½“é…ç½®ã€‚ä»¿çœŸå®éªŒéµå¾ªå„æ–¹æ³•åŸè®ºæ–‡é…ç½®ï¼ŒçœŸå®å®éªŒä½¿ç”¨7-DoF Franka Emikaæœºæ¢°è‡‚å¹³å°ï¼ŒåŸºæ¨¡å‹ä¸ºÏ€0-fast[15]ã€‚

### æ”¹è¿›å»ºè®®å’Œæœªæ¥ç ”ç©¶æ–¹å‘
**å·²æ‰¿è®¤çš„å±€é™æ€§**ï¼šä½œè€…åœ¨4.3èŠ‚æŒ‡å‡ºBackdoorVLAåœ¨LIBERO-10æ•°æ®é›†ä¸Šè¡¨ç°ç›¸å¯¹è¾ƒå·®ï¼ˆå¹³å‡ASRt 28.07%ï¼‰ï¼Œå½’å› äºè¯¥æ•°æ®é›†ä»»åŠ¡å¤šæ ·æ€§é«˜ä¸”æ¼”ç¤ºæ ·æœ¬æœ‰é™ï¼Œä½æŠ•æ¯’ç‡éš¾ä»¥è¦†ç›–æ‰€æœ‰ä»»åŠ¡å˜ä½“ã€‚æ­¤å¤–ï¼Œ4.5èŠ‚æ˜¾ç¤ºåŒæ¨¡æ€è§¦å‘æ€§èƒ½åè€Œä¸å¦‚çº¯æ–‡æœ¬è§¦å‘ï¼Œè¡¨æ˜æ¨¡æ€é—´å­˜åœ¨ç›¸äº’å¹²æ‰°ã€‚

**æ½œåœ¨æœªæåŠé™åˆ¶**ï¼š(1)æ”»å‡»å¯è½¬ç§»æ€§æœ‰é™ï¼šBackdoorVLAéœ€è¦é’ˆå¯¹æ¯ä¸ªç›®æ ‡æ¨¡å‹é‡æ–°è®­ç»ƒï¼Œè·¨æ¨¡å‹æ”»å‡»æ•ˆæœæœªéªŒè¯ï¼›(2)è§¦å‘æ£€æµ‹é£é™©ï¼šä½¿ç”¨çš„ç‰©ç†è§¦å‘ï¼ˆè“è‰²ç«‹æ–¹ä½“ï¼‰å’Œæ–‡æœ¬è§¦å‘ï¼ˆ"Ëœ*magic*Ëœ"ï¼‰åœ¨çœŸå®åœºæ™¯ä¸­è¾ƒæ˜“è¢«æ£€æµ‹ï¼Œéšè”½æ€§ä¸è¶³ï¼›(3)åŠ¨ä½œåºåˆ—çµæ´»æ€§ï¼šå½“å‰æ–¹æ³•ä¾èµ–é¢„å®šä¹‰åŠ¨ä½œåºåˆ—ï¼Œæ— æ³•é€‚åº”åŠ¨æ€ç¯å¢ƒå˜åŒ–ã€‚

**å…·ä½“æ”¹è¿›å»ºè®®**ï¼š
1. **è‡ªé€‚åº”è§¦å‘è®¾è®¡**ï¼šç»“åˆå¯¹æŠ—æ ·æœ¬ç”ŸæˆæŠ€æœ¯ï¼Œå¼€å‘åŸºäºçº¹ç†èåˆçš„è§†è§‰è§¦å‘å’ŒåŸºäºè¯­ä¹‰ä¿ç•™çš„æ–‡æœ¬è§¦å‘ï¼Œæå‡éšè”½æ€§ã€‚å¯è¡Œæ€§è¯„ä¼°ï¼šä¸­é«˜ï¼Œå¯åˆ©ç”¨ç°æœ‰æ–‡æœ¬é£æ ¼è¿ç§»å’Œå›¾åƒéšå†™æŠ€æœ¯å®ç°ã€‚

2. **å…ƒå­¦ä¹ åé—¨æ”»å‡»**ï¼šé‡‡ç”¨æ¨¡å‹ä¸å¯çŸ¥çš„å…ƒå­¦ä¹ æ¡†æ¶ï¼Œè®­ç»ƒå…·æœ‰è·¨æ¨¡å‹å¯è½¬ç§»æ€§çš„åé—¨æ”»å‡»ï¼Œå‡å°‘å¯¹ç›®æ ‡æ¨¡å‹é‡æ–°è®­ç»ƒçš„ä¾èµ–ã€‚å¯è¡Œæ€§è¯„ä¼°ï¼šä¸­ï¼Œéœ€è§£å†³ä¸åŒVLAåŠ¨ä½œè¡¨ç¤ºå·®å¼‚é—®é¢˜ã€‚

3. **åŠ¨æ€åŠ¨ä½œè§„åˆ’**ï¼šå°†åé—¨æ”»å‡»ä¸å±‚æ¬¡å¼ºåŒ–å­¦ä¹ ç»“åˆï¼Œä½¿æ”»å‡»è€…èƒ½æŒ‡å®šé«˜çº§ç›®æ ‡è€Œéå›ºå®šåŠ¨ä½œåºåˆ—ï¼Œæå‡åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é€‚åº”æ€§ã€‚å¯è¡Œæ€§è¯„ä¼°ï¼šä¸­ä½ï¼Œéœ€è¦è§£å†³åŠ¨ä½œåºåˆ—ä¸ç¯å¢ƒçŠ¶æ€çš„å®æ—¶å¯¹é½é—®é¢˜ã€‚

4. **é˜²å¾¡æœºåˆ¶å¢å¼º**ï¼šåŸºäº4.6èŠ‚çš„é˜²å¾¡æ¢ç´¢ï¼Œå¼€å‘å¤šæ¨¡æ€ååŒé˜²å¾¡ç­–ç•¥ï¼Œç»“åˆè¾“å…¥è¿‡æ»¤ã€å¼‚å¸¸æ£€æµ‹å’Œæ¨¡å‹éªŒè¯ï¼Œå»ºç«‹ç«¯åˆ°ç«¯é˜²å¾¡ç®¡é“ã€‚

---

